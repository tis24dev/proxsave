# ==============================================================================
# Proxsave - Configuration File
# TEMPLATE_VERSION=1.0.0
# ==============================================================================

# ----------------------------------------------------------------------
# General settings
# ----------------------------------------------------------------------
BACKUP_ENABLED=true
ENABLE_GO_BACKUP=true
PROFILING_ENABLED=true         # Enable CPU/heap profiling (pprof) for Go pipeline
USE_COLOR=true
COLORIZE_STEP_LOGS=true      # Highlight "Step N/8" lines (requires USE_COLOR=true)
DEBUG_LEVEL=standard        # standard | advanced | extreme
DRY_RUN=false                # Set to false for real runs

# ----------------------------------------------------------------------
# Security
# ----------------------------------------------------------------------
SECURITY_CHECK_ENABLED=true
AUTO_UPDATE_HASHES=true
AUTO_FIX_PERMISSIONS=true
CONTINUE_ON_SECURITY_ISSUES=false      # Set to true to ignore warnings (default: block the backup)
CHECK_NETWORK_SECURITY=false
CHECK_FIREWALL=false
CHECK_OPEN_PORTS=false
SUSPICIOUS_PORTS="6666 6665 1337 31337 4444 5555 4242 6324 8888 2222 3389 5900"
PORT_WHITELIST=                     # Format: service:port (e.g. sshd:22,nginx:443)

# Process security lists - NOTE: Your values are ADDED to built-in defaults (not replaced)
# SUSPICIOUS_PROCESSES: Add malware/suspicious process names to detect
# Built-in defaults: ncat, cryptominer, xmrig, kdevtmpfsi, kinsing, minerd, mr.sh
SUSPICIOUS_PROCESSES="ncat,cryptominer,xmrig,kdevtmpfsi,kinsing,minerd,mr.sh"

# SAFE_KERNEL_PROCESSES: Add safe kernel process patterns (supports exact, wildcard*, regex:pattern)
# Built-in defaults include: ksgxd, hwrng, usb-storage, vdev_autotrim, kvm-pit*, and ZFS/DRBD patterns
SAFE_KERNEL_PROCESSES="regex:^card[0-9]+-crtc[0-9]+$,regex:^drbd_[wrs]_.+,regex:^kmmpd-drbd[0-9]+$"

# SAFE_BRACKET_PROCESSES: Add safe bracket [process] names
# Built-in defaults include: systemd, cron, sshd:, rsyslogd, dbus-daemon, ZFS processes, NFS processes
# SAFE_BRACKET_PROCESSES=""

# ----------------------------------------------------------------------
# Disk space
# ----------------------------------------------------------------------
MIN_DISK_SPACE_PRIMARY_GB=1
MIN_DISK_SPACE_SECONDARY_GB=1
MIN_DISK_SPACE_CLOUD_GB=1

# ----------------------------------------------------------------------
# Local paths
# ----------------------------------------------------------------------
LOCK_PATH=${BASE_DIR}/lock
SECURE_ACCOUNT=${BASE_DIR}/secure_account

# ----------------------------------------------------------------------
# Backup Compression
# ----------------------------------------------------------------------
COMPRESSION_TYPE=xz			# none | gz | pigz | bz2 | xz | lzma | zst  (aliases accepted: gzip, bzip2, zstd)
COMPRESSION_LEVEL=9			# gzip/pigz/bzip2:1-9, xz/lzma:0-9, zstd:1-22
COMPRESSION_THREADS=0		# 0 = auto, >0 forces a fixed number of threads for pigz/xz/zstd
COMPRESSION_MODE=ultra		# fast | standard | maximum | ultra (maximum/ultra adjust levels/extra flags)

# ----------------------------------------------------------------------
# Advanced optimizations
# ----------------------------------------------------------------------
ENABLE_SMART_CHUNKING=true
ENABLE_DEDUPLICATION=true
ENABLE_PREFILTER=true
CHUNK_THRESHOLD_MB=50
CHUNK_SIZE_MB=10
PREFILTER_MAX_FILE_SIZE_MB=8

# ----------------------------------------------------------------------
# Network preflight (bypass for offline environments)
# ----------------------------------------------------------------------
# When true, skip the connectivity check before using
# features that require outbound access (Telegram, email relay, webhook, cloud/rclone).
# Use only for offline testing: the operation may still fail later.
DISABLE_NETWORK_PREFLIGHT=false

# ----------------------------------------------------------------------
# Collection exclusions (glob patterns separated by spaces/commas)
# ----------------------------------------------------------------------
# Example: *.log, */cache/**, /var/tmp/**
BACKUP_EXCLUDE_PATTERNS= */cache/**, /var/tmp/**

# ----------------------------------------------------------------------
# Primary storage
# ----------------------------------------------------------------------
BACKUP_PATH=${BASE_DIR}/backup # Primary backup storage path
LOG_PATH=${BASE_DIR}/log       # Primary log storage path

# ----------------------------------------------------------------------
# Secondary storage
# ----------------------------------------------------------------------
# IMPORTANT: SECONDARY_PATH must be a filesystem-mounted path (e.g., /mnt/nas-backup)
# It CANNOT be a network address like "192.168.0.10/folder" or "//server/share"
#
# For local network storage (NAS):
# 1. First mount the network share using NFS/CIFS/SMB
# 2. Then set SECONDARY_PATH to the local mount point
#
# Example (NFS):
#   sudo mount 192.168.0.10:/backup /mnt/nas-backup
#   SECONDARY_PATH=/mnt/nas-backup
#
# Example (CIFS/SMB):
#   sudo mount -t cifs //192.168.0.10/backup /mnt/nas-backup -o credentials=/root/.smbcreds
#   SECONDARY_PATH=/mnt/nas-backup
#
# For direct network access without mounting, use CLOUD_REMOTE with rclone instead.
# ----------------------------------------------------------------------
SECONDARY_ENABLED=false			# true-false = enable disable copy backup on secondary path
SECONDARY_PATH=					# Secondary backup storage path
SECONDARY_LOG_PATH=				# Secondary log storage path

# ----------------------------------------------------------------------
# Cloud storage (rclone)
# ----------------------------------------------------------------------
# ProxSave uses rclone for cloud backups. You can configure the destination in two equivalent ways:
#
# 1) Split remote name + path (recommended):
#      CLOUD_REMOTE=gdrive
#      CLOUD_REMOTE_PATH=proxsave/backup
#    → uploads to: gdrive:proxsave/backup/
#
# 2) Shorthand remote:path (also supported):
#      CLOUD_REMOTE=gdrive:proxsave/backup
#      CLOUD_REMOTE_PATH=
#    → uploads to: gdrive:proxsave/backup/
#
# You can also combine both if you want a stable base + per-host subdirectory:
#   CLOUD_REMOTE=gdrive:proxsave
#   CLOUD_REMOTE_PATH=backup/server1
#   → uploads to: gdrive:proxsave/backup/server1/
#
# Setup steps:
#   1. Run: rclone config (create a remote, e.g., "gdrive" or "s3backup")
#   2. Set CLOUD_REMOTE to the remote name
#   3. Optionally set CLOUD_REMOTE_PATH for subdirectory organization
#
# This is the CORRECT way to use cloud/network storage without filesystem mounting.
# ----------------------------------------------------------------------
CLOUD_ENABLED=false # true-false = enable/disable cloud backup
CLOUD_REMOTE=GoogleDrive # rclone remote NAME (from "rclone config")
CLOUD_REMOTE_PATH=/proxsave/backup      # Optional subdirectory within the remote
# Cloud log storage path:
# - New style: path only (remote name is taken from CLOUD_REMOTE): /proxsave/log
# - Legacy style: full remote:path: myremote:/proxsave/log
CLOUD_LOG_PATH=/proxsave/log
CLOUD_UPLOAD_MODE=parallel          # sequential | parallel (parallel uses a worker pool for associated/bundle files)
CLOUD_PARALLEL_MAX_JOBS=2             # Parallel workers when CLOUD_UPLOAD_MODE=parallel
CLOUD_PARALLEL_VERIFICATION=true     # true = also verify each associated file in parallel
CLOUD_WRITE_HEALTHCHECK=false        # false = auto (list + fallback to write test), true = force write test only

# ----------------------------------------------------------------------
# Rclone settings
# ----------------------------------------------------------------------
# CONNECTION timeout: remote accessibility check (short)
# OPERATION timeout: full upload/download operations (long)
RCLONE_TIMEOUT_CONNECTION=30     # seconds
RCLONE_TIMEOUT_OPERATION=300     # seconds
RCLONE_BANDWIDTH_LIMIT="10M"     # e.g. "10M" for 10 MB/s, empty = unlimited
RCLONE_TRANSFERS=16              # parallel transfers
RCLONE_RETRIES=3                 # retry attempts
RCLONE_VERIFY_METHOD=primary     # primary | alternative
RCLONE_FLAGS="--checkers=4 --stats=0 --drive-use-trash=false --drive-pacer-min-sleep=10ms --drive-pacer-burst=100"

# ----------------------------------------------------------------------
# Batch deletion (cloud storage - avoids API limits)
# ----------------------------------------------------------------------
CLOUD_BATCH_SIZE=20              # files per batch
CLOUD_BATCH_PAUSE=1              # seconds between batches

# ----------------------------------------------------------------------
# Retention policies (maximum number of backups/logs to keep)
# Logs follow the same retention policy as backups
# ----------------------------------------------------------------------
# RETENTION_POLICY selects the engine:
#   - simple: use MAX_*_BACKUPS limits (default)
#   - gfs:    use RETENTION_* tiers (daily/weekly/monthly/yearly)
RETENTION_POLICY=simple

# MODE 1: Simple retention (count-based) - DEFAULT
# Keeps the most recent N backups and removes older ones
MAX_LOCAL_BACKUPS=15
MAX_SECONDARY_BACKUPS=15
MAX_CLOUD_BACKUPS=15

# MODE 2: GFS retention (Grandfather-Father-Son)
# Enabled when RETENTION_POLICY=gfs
# Distributes backups across daily, weekly, monthly, yearly tiers
# NOTE: Setting RETENTION_* disables the corresponding MAX_*_BACKUPS limit
#
# Examples:
# - Simple: RETENTION_DAILY=7, RETENTION_WEEKLY=4 (keep 7 daily backups + 4 weekly)
# - Full: RETENTION_DAILY=7, RETENTION_WEEKLY=4, RETENTION_MONTHLY=12, RETENTION_YEARLY=3

RETENTION_DAILY=        # Keep the latest N daily backups (minimum accepted is 1; 0 is treated as 1)
RETENTION_WEEKLY=       # Keep N weekly backups from past weeks (1 per ISO week)
RETENTION_MONTHLY=     # Keep N monthly backups from past months (1 per month)
RETENTION_YEARLY=      # Keep N yearly backups from past years (1 per year)

# ----------------------------------------------------------------------
# Bundle associated files (group backup + checksum + metadata)
# ----------------------------------------------------------------------
BUNDLE_ASSOCIATED_FILES=true		# true = create bundle.tar with compression=0
ENCRYPT_ARCHIVE=false				# true = encrypt the main archive (tar/.xz) on the fly while creating it
AGE_RECIPIENT=						# Optional inline AGE recipient; if empty the wizard asks for a public key or derives one from your passphrase
AGE_RECIPIENT_FILE=${BASE_DIR}/identity/age/recipient.txt  # File containing one or more recipients (created by the wizard on first run)

# ----------------------------------------------------------------------
# Notifications
# ----------------------------------------------------------------------
# Telegram Notifications
TELEGRAM_ENABLED=false
BOT_TELEGRAM_TYPE=centralized          # "centralized" or "personal"
TELEGRAM_BOT_TOKEN=                    # For personal mode only
TELEGRAM_CHAT_ID=                      # For personal mode only

# Email Notifications
EMAIL_ENABLED=false
EMAIL_DELIVERY_METHOD=relay            # "relay" (cloud relay) | "sendmail" (/usr/sbin/sendmail) | "pmf" (proxmox-mail-forward / Proxmox Notifications)
EMAIL_FALLBACK_SENDMAIL=true           # Historical name: when EMAIL_DELIVERY_METHOD=relay, fallback to "pmf" (proxmox-mail-forward) if relay fails
EMAIL_RECIPIENT=                       # Leave empty for auto-detection from Proxmox
EMAIL_FROM=no-reply@proxmox.tis24.it

# Gotify Notifications
GOTIFY_ENABLED=false
GOTIFY_SERVER_URL=
GOTIFY_TOKEN=
GOTIFY_PRIORITY_SUCCESS=2
GOTIFY_PRIORITY_WARNING=5
GOTIFY_PRIORITY_FAILURE=8

# ----------------------------------------------------------------------
# Webhook notifications (Phase 5.2 – Discord/Slack/Teams/Generic)
# ----------------------------------------------------------------------
WEBHOOK_ENABLED=false
WEBHOOK_ENDPOINTS=                     # Comma-separated names e.g. discord_alerts,teams_ops
WEBHOOK_FORMAT=generic                 # Default format for endpoints without an explicit format
WEBHOOK_TIMEOUT=30                     # seconds
WEBHOOK_MAX_RETRIES=3
WEBHOOK_RETRY_DELAY=2                  # seconds

# For each endpoint use the uppercase name as prefix, e.g. "discord_alerts":
# WEBHOOK_DISCORD_ALERTS_URL=https://discord.com/api/webhooks/XXXX/YYY
# WEBHOOK_DISCORD_ALERTS_FORMAT=discord   # discord | slack | teams | generic
# WEBHOOK_DISCORD_ALERTS_METHOD=POST      # POST recommended; GET/HEAD do not send a payload
# WEBHOOK_DISCORD_ALERTS_HEADERS="X-Custom-Token:abc123"
# WEBHOOK_DISCORD_ALERTS_AUTH_TYPE=none   # none | bearer | basic | hmac
# WEBHOOK_DISCORD_ALERTS_AUTH_TOKEN=
# WEBHOOK_DISCORD_ALERTS_AUTH_USER=
# WEBHOOK_DISCORD_ALERTS_AUTH_PASS=
# WEBHOOK_DISCORD_ALERTS_AUTH_SECRET=

# ----------------------------------------------------------------------
# Metriche / Prometheus
# ----------------------------------------------------------------------
# METRICS_ENABLED controls Prometheus metrics export (node_exporter textfile)
# METRICS_PATH is the directory where proxmox_backup.prom is written
# Leave METRICS_PATH empty to use /var/lib/prometheus/node-exporter
METRICS_ENABLED=false
METRICS_PATH=${BASE_DIR}/metrics

# ----------------------------------------------------------------------
# Collector options
# ----------------------------------------------------------------------
# PVE
BACKUP_CLUSTER_CONFIG=true
BACKUP_PVE_FIREWALL=true
BACKUP_VZDUMP_CONFIG=true
BACKUP_PVE_ACL=true
BACKUP_PVE_JOBS=true
BACKUP_PVE_SCHEDULES=true
BACKUP_PVE_REPLICATION=true
BACKUP_PVE_BACKUP_FILES=true
BACKUP_SMALL_PVE_BACKUPS=false
MAX_PVE_BACKUP_SIZE=100M
PVE_BACKUP_INCLUDE_PATTERN=
BACKUP_CEPH_CONFIG=false
CEPH_CONFIG_PATH=/etc/ceph
BACKUP_VM_CONFIGS=true

# PBS
BACKUP_DATASTORE_CONFIGS=true
BACKUP_USER_CONFIGS=true
BACKUP_REMOTE_CONFIGS=true
BACKUP_SYNC_JOBS=true
BACKUP_VERIFICATION_JOBS=true
BACKUP_TAPE_CONFIGS=true
BACKUP_PRUNE_SCHEDULES=true
PXAR_SCAN_ENABLE=false
PXAR_SCAN_DS_CONCURRENCY=3        # Number of datastores scanned in parallel for PXAR metadata
PXAR_SCAN_INTRA_CONCURRENCY=4     # Worker threads per datastore for PXAR directory/file sampling
PXAR_SCAN_FANOUT_LEVEL=2          # Directory depth for worker fan-out (1=top-level, 2=vm/ct IDs, increase for namespaces)
PXAR_SCAN_MAX_ROOTS=2048          # Maximum worker roots per datastore (limits fan-out enumeration)
PXAR_STOP_ON_CAP=false            # Stop enumeration immediately after hitting PXAR_SCAN_MAX_ROOTS
PXAR_ENUM_READDIR_WORKERS=4       # Parallel ReadDir workers per fanout depth
PXAR_ENUM_BUDGET_MS=0             # Optional time budget for enumeration (0=disabled)
PXAR_FILE_INCLUDE_PATTERN=        # Space/comma separated patterns to locate PXAR files (default auto *.pxar,*.pxar.*)
PXAR_FILE_EXCLUDE_PATTERN=        # Patterns to exclude while sampling files (e.g. *.tmp, *.lock)

# Override collection paths (use only if directories differ from defaults)
PVE_CONFIG_PATH=/etc/pve
PVE_CLUSTER_PATH=/var/lib/pve-cluster
COROSYNC_CONFIG_PATH=${PVE_CONFIG_PATH}/corosync.conf
VZDUMP_CONFIG_PATH=/etc/vzdump.conf
PBS_CONFIG_PATH=/etc/proxmox-backup
PBS_DATASTORE_PATH=              # Extra PBS paths separated by comma/space (e.g. /mnt/pbs1,/mnt/pbs2). Empty = auto-detect.

# System
BACKUP_NETWORK_CONFIGS=true
BACKUP_APT_SOURCES=true
BACKUP_CRON_JOBS=true
BACKUP_SYSTEMD_SERVICES=true
BACKUP_SSL_CERTS=true
BACKUP_SYSCTL_CONFIG=true
BACKUP_KERNEL_MODULES=true
BACKUP_FIREWALL_RULES=false
BACKUP_INSTALLED_PACKAGES=true
BACKUP_SCRIPT_DIR=true
BACKUP_CRITICAL_FILES=true
# SSH configuration and keys (/etc/ssh, /root/.ssh, /home/*/.ssh)
BACKUP_SSH_KEYS=true
# ZFS configuration (/etc/zfs, /etc/hostid, zpool cache/properties)
BACKUP_ZFS_CONFIG=true
BACKUP_ROOT_HOME=true
BACKUP_SCRIPT_REPOSITORY=false
BACKUP_CONFIG_FILE=true        # Include this backup.env configuration file in the backup
SYSTEM_ROOT_PREFIX=            # Optional: override system root (e.g. chroot/test fixture). Empty or "/" = real root.

# ----------------------------------------------------------------------
# Custom paths / blacklist
# ----------------------------------------------------------------------
# Bash-style declaration: one entry per line inside the quotes
CUSTOM_BACKUP_PATHS="
# /root/.config/rclone/rclone.conf
# /srv/custom-config.yaml
# /etc/custom/tool.conf
"

BACKUP_BLACKLIST="
# /root/.cache
# /root/*_tmp
"

# ----------------------------------------------------------------------
# Security and permissions
# ----------------------------------------------------------------------
SKIP_PERMISSION_CHECK=false    # true = non eseguire i controlli di permesso (solo test)
BACKUP_USER=backup             # Utente proprietario delle directory di backup/log
BACKUP_GROUP=backup            # Gruppo proprietario delle directory di backup/log
SET_BACKUP_PERMISSIONS=false   # true = applica chown/chmod stile Bash su backup/log

# ==============================================================================
# End file
# ==============================================================================***
