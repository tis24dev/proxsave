diff --git a/docs/CLI_REFERENCE.md b/docs/CLI_REFERENCE.md
index 8a33a0e..d87706b 100644
--- a/docs/CLI_REFERENCE.md
+++ b/docs/CLI_REFERENCE.md
@@ -414,6 +414,7 @@ Next step: ./build/proxsave --dry-run
 ```
 
 **Use `--cli` when**: TUI rendering issues occur or advanced debugging is needed.
+**Note**: CLI and TUI run the same workflow logic; `--cli` only changes the interface (prompts/progress rendering), not the restore/decrypt behavior.
 
 **`--restore` workflow** (14 phases):
 1. Scans configured storage locations (local/secondary/cloud)
diff --git a/docs/CLOUD_STORAGE.md b/docs/CLOUD_STORAGE.md
index 7707fc8..240b112 100644
--- a/docs/CLOUD_STORAGE.md
+++ b/docs/CLOUD_STORAGE.md
@@ -383,7 +383,7 @@ RETENTION_YEARLY=3
 | `CLOUD_PARALLEL_MAX_JOBS` | `2` | Max concurrent uploads (parallel mode) |
 | `CLOUD_PARALLEL_VERIFICATION` | `true` | Verify checksums after upload |
 | `CLOUD_WRITE_HEALTHCHECK` | `false` | Use write test for connectivity check |
-| `RCLONE_TIMEOUT_CONNECTION` | `30` | Connection timeout (seconds). Also used by restore/decrypt when scanning cloud backups (list + manifest read). |
+| `RCLONE_TIMEOUT_CONNECTION` | `30` | Per-command timeout (seconds). Also used by restore/decrypt cloud scan (`rclone lsf` + per-backup manifest/metadata read). |
 | `RCLONE_TIMEOUT_OPERATION` | `300` | Operation timeout (seconds) |
 | `RCLONE_BANDWIDTH_LIMIT` | _(empty)_ | Upload rate limit (e.g., `5M` = 5 MB/s) |
 | `RCLONE_TRANSFERS` | `4` | Number of parallel transfers |
@@ -437,7 +437,7 @@ path inside the remote, and uses that consistently for:
 - **uploads** (cloud backend);
 - **cloud retention**;
 - **restore / decrypt menus** (entry “Cloud backups (rclone)”).
-  - Restore/decrypt cloud scanning is protected by `RCLONE_TIMEOUT_CONNECTION` (increase it on slow remotes or very large directories).
+  - Restore/decrypt cloud scanning applies `RCLONE_TIMEOUT_CONNECTION` per rclone command (the timer resets on each `lsf`/manifest read).
 
 You can choose the style you prefer; they are equivalent from the tool’s point of view.
 
@@ -617,7 +617,7 @@ rm /tmp/test*.txt
 | `couldn't find configuration section 'gdrive'` | Remote not configured | `rclone config` → create remote |
 | `401 unauthorized` | Credentials expired | `rclone config reconnect gdrive` or regenerate keys |
 | `connection timeout (30s)` | Slow network | Increase `RCLONE_TIMEOUT_CONNECTION=60` |
-| `Timed out while scanning ... (rclone)` | Slow remote / huge directory | Increase `RCLONE_TIMEOUT_CONNECTION` and re-try restore/decrypt scan |
+| `Timed out while scanning ... (rclone)` | Slow remote / huge directory | Increase `RCLONE_TIMEOUT_CONNECTION` and ensure the remote path points to the directory that contains the backups (scan is non-recursive) |
 | `operation timeout (300s exceeded)` | Large file + slow network | Increase `RCLONE_TIMEOUT_OPERATION=900` |
 | `429 Too Many Requests` | API rate limiting | Reduce `RCLONE_TRANSFERS=2`, increase `CLOUD_BATCH_PAUSE=3` |
 | `directory not found` | Path doesn't exist | `rclone mkdir gdrive:pbs-backups` |
diff --git a/docs/CONFIGURATION.md b/docs/CONFIGURATION.md
index f17a209..83c55ee 100644
--- a/docs/CONFIGURATION.md
+++ b/docs/CONFIGURATION.md
@@ -548,7 +548,7 @@ Quick comparison to help you choose the right storage configuration:
 
 ```bash
 # Connection timeout (seconds)
-RCLONE_TIMEOUT_CONNECTION=30       # Remote accessibility check (also used for restore/decrypt cloud scan)
+RCLONE_TIMEOUT_CONNECTION=30       # Remote accessibility check (also used as per-command timeout for restore/decrypt cloud scan)
 
 # Operation timeout (seconds)
 RCLONE_TIMEOUT_OPERATION=300       # Upload/download operations (5 minutes default)
@@ -571,7 +571,7 @@ RCLONE_FLAGS="--checkers=4 --stats=0 --drive-use-trash=false --drive-pacer-min-s
 
 ### Timeout Tuning
 
-- **CONNECTION**: Short timeout for quick accessibility check (default 30s); also caps restore/decrypt cloud scanning (listing backups + reading manifests)
+- **CONNECTION**: Short timeout for quick accessibility check (default 30s); also applies per rclone command during restore/decrypt cloud scanning (listing backups + reading manifests)
 - **OPERATION**: Long timeout for large file uploads (increase for slow networks)
 
 ### Bandwidth Limit Format
@@ -918,6 +918,8 @@ CEPH_CONFIG_PATH=/etc/ceph         # Ceph config directory
 BACKUP_VM_CONFIGS=true             # VM/CT config files
 ```
 
+**Note (PVE snapshot behavior)**: ProxSave snapshots `PVE_CONFIG_PATH` for completeness. When a PVE feature is disabled, proxsave also excludes its well-known files from that snapshot to avoid “still included via full directory copy” surprises (e.g. `qemu-server/` + `lxc/` for `BACKUP_VM_CONFIGS=false`, `firewall/` + `host.fw` for `BACKUP_PVE_FIREWALL=false`, `user.cfg`/`acl.cfg`/`domains.cfg` for `BACKUP_PVE_ACL=false`, `jobs.cfg` + `vzdump.cron` for `BACKUP_PVE_JOBS=false`, `corosync.conf` (and `config.db` capture) for `BACKUP_CLUSTER_CONFIG=false`).
+
 ### PBS-Specific
 
 ```bash
@@ -955,6 +957,8 @@ PXAR_FILE_INCLUDE_PATTERN=         # Include patterns (default: *.pxar, catalog.
 PXAR_FILE_EXCLUDE_PATTERN=         # Exclude patterns (e.g., *.tmp, *.lock)
 ```
 
+**Note (PBS snapshot behavior)**: ProxSave snapshots `PBS_CONFIG_PATH` (`/etc/proxmox-backup`) for completeness. When a PBS feature is disabled, proxsave excludes the corresponding well-known config files from that snapshot (for example, `remote.cfg` is excluded when `BACKUP_REMOTE_CONFIGS=false`) and also skips the related command outputs.
+
 **PXAR scanning**: Collects metadata from Proxmox Backup Server .pxar archives.
 
 ### Override Collection Paths
@@ -1030,6 +1034,8 @@ BACKUP_SCRIPT_REPOSITORY=false     # Include .git directory
 BACKUP_CONFIG_FILE=true            # Include this backup.env configuration file in the backup
 ```
 
+**Note (SSH keys)**: `BACKUP_SSH_KEYS=false` also suppresses `.ssh/` directories when collecting home directories (root and users), so keys aren’t included indirectly via `BACKUP_ROOT_HOME`/home collection.
+
 **Note**: `BACKUP_CONFIG_FILE=true` automatically includes the `configs/backup.env` file in the backup archive. This is highly recommended for disaster recovery, as it allows you to restore your exact backup configuration along with the system files. If you have sensitive credentials in `backup.env`, ensure your backups are encrypted (`ENCRYPT_ARCHIVE=true`).
 
 ---
diff --git a/docs/RESTORE_GUIDE.md b/docs/RESTORE_GUIDE.md
index cffac04..67f36a0 100644
--- a/docs/RESTORE_GUIDE.md
+++ b/docs/RESTORE_GUIDE.md
@@ -2568,10 +2568,10 @@ A: Yes, in two ways:
      `CLOUD_REMOTE` / `CLOUD_REMOTE_PATH` combination and show an entry:
        - `Cloud backups (rclone)`
    - When selected, the tool:
-     - lists `.bundle.tar` bundles on the remote with `rclone lsf`;
-     - reads metadata/manifest via `rclone cat` (without downloading everything);
+     - lists backup candidates on the remote with `rclone lsf` (`.bundle.tar` bundles and legacy `.metadata`+archive pairs);
+     - reads the manifest/metadata via `rclone cat` (without downloading full archives; for bundles the manifest is at the beginning, so this is typically fast);
      - when you pick a backup, downloads it to `/tmp/proxsave` and proceeds with decrypt/restore.
-   - If scanning times out (slow remote / huge directory), increase `RCLONE_TIMEOUT_CONNECTION` and retry.
+   - Cloud scan applies `RCLONE_TIMEOUT_CONNECTION` per rclone command (the timer resets on each list/inspect step). If scanning times out (slow remote / huge directory), increase `RCLONE_TIMEOUT_CONNECTION` and retry. Also ensure the selected remote path points directly to the directory that contains the backups (scan is non-recursive).
 
 2. **From a local rclone mount (restore-only)**  
    If you prefer to mount the rclone backend as a local filesystem:
diff --git a/docs/TROUBLESHOOTING.md b/docs/TROUBLESHOOTING.md
index 67905f2..373ccd7 100644
--- a/docs/TROUBLESHOOTING.md
+++ b/docs/TROUBLESHOOTING.md
@@ -279,7 +279,7 @@ iptables -L -n | grep -i drop
 
 #### Restore/Decrypt: stuck on “Scanning backup path…” or timeout (cloud/rclone)
 
-**Cause**: The tool scans cloud backups by listing the remote (`rclone lsf`) and reading each backup manifest (`rclone cat`). On slow remotes or very large directories this can time out.
+**Cause**: ProxSave scans cloud backups by listing the remote (`rclone lsf`) and inspecting each candidate by reading the manifest/metadata (`rclone cat`). Each rclone call is protected by `RCLONE_TIMEOUT_CONNECTION` (the timer resets per command). On slow remotes or very large directories this can time out.
 
 **Solution**:
 ```bash
@@ -287,8 +287,12 @@ iptables -L -n | grep -i drop
 nano configs/backup.env
 RCLONE_TIMEOUT_CONNECTION=120
 
-# Re-run restore with debug logs (restore log path is printed on start)
+# Ensure you selected the remote directory that contains the backups (scan is non-recursive),
+# then re-run restore with debug logs (restore log path is printed on start)
 ./build/proxsave --restore --log-level debug
+
+# Or use support mode to capture full diagnostics
+./build/proxsave --restore --support
 ```
 
 If it still fails, run the equivalent manual checks:
diff --git a/internal/backup/collector.go b/internal/backup/collector.go
index 1f62ed5..21886d1 100644
--- a/internal/backup/collector.go
+++ b/internal/backup/collector.go
@@ -27,6 +27,8 @@ import (
 type CollectionStats struct {
 	FilesProcessed int64
 	FilesFailed    int64
+	FilesNotFound  int64
+	FilesSkipped   int64
 	DirsCreated    int64
 	BytesCollected int64
 }
@@ -54,6 +56,11 @@ type Collector struct {
 
 	// clusteredPVE records whether cluster mode was detected during PVE collection.
 	clusteredPVE bool
+
+	// Manifest tracking for backup contents
+	pbsManifest    map[string]ManifestEntry
+	pveManifest    map[string]ManifestEntry
+	systemManifest map[string]ManifestEntry
 }
 
 var osSymlink = os.Symlink
@@ -71,6 +78,14 @@ func (c *Collector) incFilesFailed() {
 	atomic.AddInt64(&c.stats.FilesFailed, 1)
 }
 
+func (c *Collector) incFilesNotFound() {
+	atomic.AddInt64(&c.stats.FilesNotFound, 1)
+}
+
+func (c *Collector) incFilesSkipped() {
+	atomic.AddInt64(&c.stats.FilesSkipped, 1)
+}
+
 func (c *Collector) incDirsCreated() {
 	atomic.AddInt64(&c.stats.DirsCreated, 1)
 }
@@ -426,6 +441,38 @@ func (c *Collector) shouldExclude(path string) bool {
 	return false
 }
 
+func (c *Collector) withTemporaryExcludes(extra []string, fn func() error) error {
+	if fn == nil {
+		return nil
+	}
+	if c == nil || c.config == nil || len(extra) == 0 {
+		return fn()
+	}
+
+	seen := make(map[string]struct{}, len(extra))
+	normalized := make([]string, 0, len(extra))
+	for _, pattern := range extra {
+		pattern = strings.TrimSpace(pattern)
+		if pattern == "" {
+			continue
+		}
+		if _, ok := seen[pattern]; ok {
+			continue
+		}
+		seen[pattern] = struct{}{}
+		normalized = append(normalized, pattern)
+	}
+	if len(normalized) == 0 {
+		return fn()
+	}
+
+	original := append([]string(nil), c.config.ExcludePatterns...)
+	c.config.ExcludePatterns = append(c.config.ExcludePatterns, normalized...)
+	defer func() { c.config.ExcludePatterns = original }()
+
+	return fn()
+}
+
 func uniqueCandidates(path, tempDir string) []string {
 	base := filepath.Base(path)
 	candidates := []string{path}
diff --git a/internal/backup/collector_pbs.go b/internal/backup/collector_pbs.go
index b85b957..cac4f8a 100644
--- a/internal/backup/collector_pbs.go
+++ b/internal/backup/collector_pbs.go
@@ -30,6 +30,47 @@ func (c *Collector) pbsConfigPath() string {
 	return c.systemPath("/etc/proxmox-backup")
 }
 
+// collectPBSConfigFile collects a single PBS configuration file with detailed logging
+func (c *Collector) collectPBSConfigFile(ctx context.Context, root, filename, description string, enabled bool) ManifestEntry {
+	if !enabled {
+		c.logger.Debug("Skipping %s: disabled by configuration", filename)
+		c.logger.Info("  %s: disabled", description)
+		return ManifestEntry{Status: StatusDisabled}
+	}
+
+	srcPath := filepath.Join(root, filename)
+	destPath := filepath.Join(c.tempDir, "etc/proxmox-backup", filename)
+
+	c.logger.Debug("Checking %s: %s", filename, srcPath)
+
+	info, err := os.Stat(srcPath)
+	if os.IsNotExist(err) {
+		c.incFilesNotFound()
+		c.logger.Debug("  File not found: %v", err)
+		c.logger.Info("  %s: not configured", description)
+		return ManifestEntry{Status: StatusNotFound}
+	}
+	if err != nil {
+		c.incFilesFailed()
+		c.logger.Debug("  Stat error: %v", err)
+		c.logger.Warning("  %s: failed - %v", description, err)
+		return ManifestEntry{Status: StatusFailed, Error: err.Error()}
+	}
+
+	// Log file details in debug mode
+	c.logger.Debug("  File exists, size=%d, mode=%s, mtime=%s",
+		info.Size(), info.Mode(), info.ModTime().Format(time.RFC3339))
+	c.logger.Debug("  Copying to %s", destPath)
+
+	if err := c.safeCopyFile(ctx, srcPath, destPath, description); err != nil {
+		c.logger.Warning("  %s: failed - %v", description, err)
+		return ManifestEntry{Status: StatusFailed, Error: err.Error()}
+	}
+
+	c.logger.Info("  %s: collected (%s)", description, FormatBytes(info.Size()))
+	return ManifestEntry{Status: StatusCollected, Size: info.Size()}
+}
+
 // CollectPBSConfigs collects Proxmox Backup Server specific configurations
 func (c *Collector) CollectPBSConfigs(ctx context.Context) error {
 	c.logger.Info("Collecting PBS configurations")
@@ -116,116 +157,115 @@ func (c *Collector) CollectPBSConfigs(ctx context.Context) error {
 		c.logger.Skip("PBS PXAR metadata collection disabled.")
 	}
 
+	// Print collection summary
+	c.logger.Info("PBS collection summary:")
+	c.logger.Info("  Files collected: %d", c.stats.FilesProcessed)
+	c.logger.Info("  Files not found: %d", c.stats.FilesNotFound)
+	if c.stats.FilesFailed > 0 {
+		c.logger.Warning("  Files failed: %d", c.stats.FilesFailed)
+	}
+	c.logger.Debug("  Files skipped: %d", c.stats.FilesSkipped)
+	c.logger.Debug("  Bytes collected: %d", c.stats.BytesCollected)
+
 	c.logger.Info("PBS configuration collection completed")
 	return nil
 }
 
 // collectPBSDirectories collects PBS-specific directories
 func (c *Collector) collectPBSDirectories(ctx context.Context, root string) error {
-	c.logger.Debug("Collecting PBS directories (%s, configs, schedules)", root)
-	// PBS main configuration directory
-	if err := c.safeCopyDir(ctx,
-		root,
-		filepath.Join(c.tempDir, "etc/proxmox-backup"),
-		"PBS configuration"); err != nil {
+	c.logger.Debug("Collecting PBS directories (source=%s, dest=%s)",
+		root, filepath.Join(c.tempDir, "etc/proxmox-backup"))
+
+	// Even though we keep a full snapshot of /etc/proxmox-backup (or PBS_CONFIG_PATH),
+	// treat per-feature flags as exclusions so users can selectively omit sensitive files
+	// while still capturing unknown/new PBS config files.
+	//
+	// NOTE: These patterns are applied only for the duration of the directory snapshot to
+	// avoid impacting other collectors.
+	var extraExclude []string
+	if !c.config.BackupDatastoreConfigs {
+		extraExclude = append(extraExclude, "datastore.cfg")
+	}
+	if !c.config.BackupUserConfigs {
+		// User-related configs are intentionally excluded together.
+		extraExclude = append(extraExclude, "user.cfg", "acl.cfg", "domains.cfg")
+	}
+	if !c.config.BackupRemoteConfigs {
+		extraExclude = append(extraExclude, "remote.cfg")
+	}
+	if !c.config.BackupSyncJobs {
+		extraExclude = append(extraExclude, "sync.cfg")
+	}
+	if !c.config.BackupVerificationJobs {
+		extraExclude = append(extraExclude, "verification.cfg")
+	}
+	if !c.config.BackupTapeConfigs {
+		extraExclude = append(extraExclude, "tape.cfg", "media-pool.cfg")
+	}
+	if !c.config.BackupNetworkConfigs {
+		extraExclude = append(extraExclude, "network.cfg")
+	}
+	if !c.config.BackupPruneSchedules {
+		extraExclude = append(extraExclude, "prune.cfg")
+	}
+
+	// PBS main configuration directory (full backup)
+	if len(extraExclude) > 0 {
+		c.logger.Debug("PBS config exclusions enabled (disabled features): %s", strings.Join(extraExclude, ", "))
+	}
+	if err := c.withTemporaryExcludes(extraExclude, func() error {
+		return c.safeCopyDir(ctx,
+			root,
+			filepath.Join(c.tempDir, "etc/proxmox-backup"),
+			"PBS configuration")
+	}); err != nil {
 		return err
 	}
 
+	// Initialize manifest for PBS configs
+	c.pbsManifest = make(map[string]ManifestEntry)
+
+	c.logger.Info("Collecting PBS configuration files:")
+
 	// Datastore configuration
-	if c.config.BackupDatastoreConfigs {
-		if err := c.safeCopyFile(ctx,
-			filepath.Join(root, "datastore.cfg"),
-			filepath.Join(c.tempDir, "etc/proxmox-backup/datastore.cfg"),
-			"Datastore configuration"); err != nil {
-			c.logger.Debug("No datastore.cfg found")
-		}
-	}
+	c.pbsManifest["datastore.cfg"] = c.collectPBSConfigFile(ctx, root, "datastore.cfg",
+		"Datastore configuration", c.config.BackupDatastoreConfigs)
 
 	// User configuration
-	if c.config.BackupUserConfigs {
-		if err := c.safeCopyFile(ctx,
-			filepath.Join(root, "user.cfg"),
-			filepath.Join(c.tempDir, "etc/proxmox-backup/user.cfg"),
-			"User configuration"); err != nil {
-			c.logger.Debug("No user.cfg found")
-		}
+	c.pbsManifest["user.cfg"] = c.collectPBSConfigFile(ctx, root, "user.cfg",
+		"User configuration", c.config.BackupUserConfigs)
 
-		// ACL configuration
-		if err := c.safeCopyFile(ctx,
-			filepath.Join(root, "acl.cfg"),
-			filepath.Join(c.tempDir, "etc/proxmox-backup/acl.cfg"),
-			"ACL configuration"); err != nil {
-			c.logger.Debug("No acl.cfg found")
-		}
-	}
+	// ACL configuration (under user configs flag)
+	c.pbsManifest["acl.cfg"] = c.collectPBSConfigFile(ctx, root, "acl.cfg",
+		"ACL configuration", c.config.BackupUserConfigs)
 
 	// Remote configuration (for sync jobs)
-	if c.config.BackupRemoteConfigs {
-		if err := c.safeCopyFile(ctx,
-			filepath.Join(root, "remote.cfg"),
-			filepath.Join(c.tempDir, "etc/proxmox-backup/remote.cfg"),
-			"Remote configuration"); err != nil {
-			c.logger.Debug("No remote.cfg found")
-		}
-	}
+	c.pbsManifest["remote.cfg"] = c.collectPBSConfigFile(ctx, root, "remote.cfg",
+		"Remote configuration", c.config.BackupRemoteConfigs)
 
 	// Sync jobs configuration
-	if c.config.BackupSyncJobs {
-		if err := c.safeCopyFile(ctx,
-			filepath.Join(root, "sync.cfg"),
-			filepath.Join(c.tempDir, "etc/proxmox-backup/sync.cfg"),
-			"Sync configuration"); err != nil {
-			c.logger.Debug("No sync.cfg found")
-		}
-	}
+	c.pbsManifest["sync.cfg"] = c.collectPBSConfigFile(ctx, root, "sync.cfg",
+		"Sync jobs", c.config.BackupSyncJobs)
 
 	// Verification jobs configuration
-	if c.config.BackupVerificationJobs {
-		if err := c.safeCopyFile(ctx,
-			filepath.Join(root, "verification.cfg"),
-			filepath.Join(c.tempDir, "etc/proxmox-backup/verification.cfg"),
-			"Verification configuration"); err != nil {
-			c.logger.Debug("No verification.cfg found")
-		}
-	}
+	c.pbsManifest["verification.cfg"] = c.collectPBSConfigFile(ctx, root, "verification.cfg",
+		"Verification jobs", c.config.BackupVerificationJobs)
 
-	// Tape backup configuration (if applicable)
-	if c.config.BackupTapeConfigs {
-		if err := c.safeCopyFile(ctx,
-			filepath.Join(root, "tape.cfg"),
-			filepath.Join(c.tempDir, "etc/proxmox-backup/tape.cfg"),
-			"Tape configuration"); err != nil {
-			c.logger.Debug("No tape.cfg found")
-		}
+	// Tape backup configuration
+	c.pbsManifest["tape.cfg"] = c.collectPBSConfigFile(ctx, root, "tape.cfg",
+		"Tape configuration", c.config.BackupTapeConfigs)
 
-		// Media pool configuration
-		if err := c.safeCopyFile(ctx,
-			filepath.Join(root, "media-pool.cfg"),
-			filepath.Join(c.tempDir, "etc/proxmox-backup/media-pool.cfg"),
-			"Media pool configuration"); err != nil {
-			c.logger.Debug("No media-pool.cfg found")
-		}
-	}
+	// Media pool configuration (under tape configs flag)
+	c.pbsManifest["media-pool.cfg"] = c.collectPBSConfigFile(ctx, root, "media-pool.cfg",
+		"Media pool configuration", c.config.BackupTapeConfigs)
 
 	// Network configuration
-	if c.config.BackupNetworkConfigs {
-		if err := c.safeCopyFile(ctx,
-			filepath.Join(root, "network.cfg"),
-			filepath.Join(c.tempDir, "etc/proxmox-backup/network.cfg"),
-			"Network configuration"); err != nil {
-			c.logger.Debug("No network.cfg found")
-		}
-	}
+	c.pbsManifest["network.cfg"] = c.collectPBSConfigFile(ctx, root, "network.cfg",
+		"Network configuration", c.config.BackupNetworkConfigs)
 
 	// Prune/GC schedules
-	if c.config.BackupPruneSchedules {
-		if err := c.safeCopyFile(ctx,
-			filepath.Join(root, "prune.cfg"),
-			filepath.Join(c.tempDir, "etc/proxmox-backup/prune.cfg"),
-			"Prune configuration"); err != nil {
-			c.logger.Debug("No prune.cfg found")
-		}
-	}
+	c.pbsManifest["prune.cfg"] = c.collectPBSConfigFile(ctx, root, "prune.cfg",
+		"Prune schedules", c.config.BackupPruneSchedules)
 
 	c.logger.Debug("PBS directory collection finished")
 	return nil
diff --git a/internal/backup/collector_pbs_extra_test.go b/internal/backup/collector_pbs_extra_test.go
index 93e5f69..1587c99 100644
--- a/internal/backup/collector_pbs_extra_test.go
+++ b/internal/backup/collector_pbs_extra_test.go
@@ -186,3 +186,87 @@ func TestCollectPBSConfigsWithCustomRoot(t *testing.T) {
 		t.Fatalf("expected commands directory, got err: %v", err)
 	}
 }
+
+func TestCollectPBSConfigsExcludesDisabledPBSConfigFiles(t *testing.T) {
+	root := t.TempDir()
+	mustWrite := func(name, contents string) {
+		t.Helper()
+		if err := os.WriteFile(filepath.Join(root, name), []byte(contents), 0o644); err != nil {
+			t.Fatalf("write %s: %v", name, err)
+		}
+	}
+
+	mustWrite("dummy.cfg", "ok")
+	mustWrite("datastore.cfg", "datastore")
+	mustWrite("user.cfg", "user")
+	mustWrite("acl.cfg", "acl")
+	mustWrite("domains.cfg", "domains")
+	mustWrite("remote.cfg", "remote")
+	mustWrite("sync.cfg", "sync")
+	mustWrite("verification.cfg", "verify")
+	mustWrite("tape.cfg", "tape")
+	mustWrite("media-pool.cfg", "media")
+	mustWrite("network.cfg", "net")
+	mustWrite("prune.cfg", "prune")
+
+	cfg := GetDefaultCollectorConfig()
+	cfg.PBSConfigPath = root
+	cfg.BackupDatastoreConfigs = false
+	cfg.BackupUserConfigs = false
+	cfg.BackupRemoteConfigs = false
+	cfg.BackupSyncJobs = false
+	cfg.BackupVerificationJobs = false
+	cfg.BackupTapeConfigs = false
+	cfg.BackupPruneSchedules = false
+	cfg.BackupNetworkConfigs = false
+	cfg.BackupPxarFiles = false
+
+	collector := NewCollectorWithDeps(newTestLogger(), cfg, t.TempDir(), types.ProxmoxBS, false, CollectorDeps{
+		LookPath: func(cmd string) (string, error) {
+			return "/usr/bin/" + cmd, nil
+		},
+		RunCommand: func(_ context.Context, name string, args ...string) ([]byte, error) {
+			if name == "proxmox-backup-manager" && len(args) >= 3 && args[0] == "datastore" && args[1] == "list" {
+				return []byte(`[{"name":"store1","path":"/fake"}]`), nil
+			}
+			return []byte("ok"), nil
+		},
+	})
+
+	if err := collector.CollectPBSConfigs(context.Background()); err != nil {
+		t.Fatalf("CollectPBSConfigs failed: %v", err)
+	}
+
+	destDir := filepath.Join(collector.tempDir, "etc", "proxmox-backup")
+
+	if _, err := os.Stat(filepath.Join(destDir, "dummy.cfg")); err != nil {
+		t.Fatalf("expected dummy.cfg collected, got %v", err)
+	}
+
+	for _, excluded := range []string{
+		"datastore.cfg",
+		"user.cfg",
+		"acl.cfg",
+		"domains.cfg",
+		"remote.cfg",
+		"sync.cfg",
+		"verification.cfg",
+		"tape.cfg",
+		"media-pool.cfg",
+		"network.cfg",
+		"prune.cfg",
+	} {
+		_, err := os.Stat(filepath.Join(destDir, excluded))
+		if err == nil {
+			t.Fatalf("expected %s excluded from PBS config snapshot", excluded)
+		}
+		if !errors.Is(err, os.ErrNotExist) {
+			t.Fatalf("stat %s: %v", excluded, err)
+		}
+	}
+
+	// Ensure related command output is also excluded when the feature flag is disabled.
+	if _, err := os.Stat(filepath.Join(collector.tempDir, "commands", "remote_list.json")); err == nil {
+		t.Fatalf("expected remote_list.json excluded when BACKUP_REMOTE_CONFIGS=false")
+	}
+}
diff --git a/internal/backup/collector_pve.go b/internal/backup/collector_pve.go
index 2a56e8b..b6eaaf6 100644
--- a/internal/backup/collector_pve.go
+++ b/internal/backup/collector_pve.go
@@ -156,10 +156,34 @@ func (c *Collector) collectPVEDirectories(ctx context.Context, clustered bool) e
 	c.logger.Debug("Snapshotting PVE directories (clustered=%v)", clustered)
 
 	pveConfigPath := c.effectivePVEConfigPath()
-	if err := c.safeCopyDir(ctx,
-		pveConfigPath,
-		c.targetPathFor(pveConfigPath),
-		"PVE configuration"); err != nil {
+	var extraExclude []string
+	if !c.config.BackupVMConfigs {
+		extraExclude = append(extraExclude, "qemu-server", "lxc")
+	}
+	if !c.config.BackupPVEFirewall {
+		// Rules can exist both under /etc/pve/firewall and under /etc/pve/nodes/*.
+		extraExclude = append(extraExclude, "firewall", "host.fw")
+	}
+	if !c.config.BackupPVEACL {
+		extraExclude = append(extraExclude, "user.cfg", "acl.cfg", "domains.cfg")
+	}
+	if !c.config.BackupPVEJobs {
+		extraExclude = append(extraExclude, "jobs.cfg", "vzdump.cron")
+	}
+	if !c.config.BackupClusterConfig {
+		// Keep /etc/pve snapshot but omit cluster-specific config files when disabled.
+		extraExclude = append(extraExclude, "corosync.conf")
+	}
+
+	if len(extraExclude) > 0 {
+		c.logger.Debug("PVE config exclusions enabled (disabled features): %s", strings.Join(extraExclude, ", "))
+	}
+	if err := c.withTemporaryExcludes(extraExclude, func() error {
+		return c.safeCopyDir(ctx,
+			pveConfigPath,
+			c.targetPathFor(pveConfigPath),
+			"PVE configuration")
+	}); err != nil {
 		return err
 	}
 
@@ -203,16 +227,20 @@ func (c *Collector) collectPVEDirectories(ctx context.Context, clustered bool) e
 		}
 	}
 
-	// Always attempt to capture config.db even on standalone nodes
-	configDB := filepath.Join(clusterPath, "config.db")
-	if info, err := os.Stat(configDB); err == nil && !info.IsDir() {
-		target := c.targetPathFor(configDB)
-		c.logger.Debug("Copying PVE cluster database %s to %s", configDB, target)
-		if err := c.safeCopyFile(ctx, configDB, target, "PVE cluster database"); err != nil {
-			c.logger.Warning("Failed to copy PVE cluster database %s: %v", configDB, err)
+	if c.config.BackupClusterConfig {
+		// Always attempt to capture config.db even on standalone nodes when cluster config is enabled.
+		configDB := filepath.Join(clusterPath, "config.db")
+		if info, err := os.Stat(configDB); err == nil && !info.IsDir() {
+			target := c.targetPathFor(configDB)
+			c.logger.Debug("Copying PVE cluster database %s to %s", configDB, target)
+			if err := c.safeCopyFile(ctx, configDB, target, "PVE cluster database"); err != nil {
+				c.logger.Warning("Failed to copy PVE cluster database %s: %v", configDB, err)
+			}
+		} else if err != nil && !errors.Is(err, os.ErrNotExist) {
+			c.logger.Warning("Failed to stat PVE cluster database %s: %v", configDB, err)
 		}
-	} else if err != nil && !errors.Is(err, os.ErrNotExist) {
-		c.logger.Warning("Failed to stat PVE cluster database %s: %v", configDB, err)
+	} else {
+		c.logger.Debug("Skipping PVE cluster database capture: BACKUP_CLUSTER_CONFIG=false")
 	}
 
 	// Firewall configuration
diff --git a/internal/backup/collector_pve_test.go b/internal/backup/collector_pve_test.go
index 4d3ea8f..568ad30 100644
--- a/internal/backup/collector_pve_test.go
+++ b/internal/backup/collector_pve_test.go
@@ -2,6 +2,7 @@ package backup
 
 import (
 	"context"
+	"errors"
 	"fmt"
 	"os"
 	"path/filepath"
@@ -697,6 +698,86 @@ func TestCollectPVEReplication(t *testing.T) {
 	}
 }
 
+func TestCollectPVEDirectoriesExcludesDisabledPVEConfigFiles(t *testing.T) {
+	collector := newPVECollector(t)
+	pveRoot := collector.config.PVEConfigPath
+
+	mustMkdir := func(path string) {
+		t.Helper()
+		if err := os.MkdirAll(path, 0o755); err != nil {
+			t.Fatalf("mkdir %s: %v", path, err)
+		}
+	}
+	mustWrite := func(path, contents string) {
+		t.Helper()
+		dir := filepath.Dir(path)
+		if dir != "" && dir != "." {
+			mustMkdir(dir)
+		}
+		if err := os.WriteFile(path, []byte(contents), 0o644); err != nil {
+			t.Fatalf("write %s: %v", path, err)
+		}
+	}
+
+	// Create representative PVE config files and directories that are normally covered by a full /etc/pve snapshot.
+	mustWrite(filepath.Join(pveRoot, "dummy.cfg"), "ok")
+	mustWrite(filepath.Join(pveRoot, "corosync.conf"), "corosync")
+	mustWrite(filepath.Join(pveRoot, "user.cfg"), "user")
+	mustWrite(filepath.Join(pveRoot, "acl.cfg"), "acl")
+	mustWrite(filepath.Join(pveRoot, "domains.cfg"), "domains")
+	mustWrite(filepath.Join(pveRoot, "jobs.cfg"), "jobs")
+	mustWrite(filepath.Join(pveRoot, "vzdump.cron"), "cron")
+	mustWrite(filepath.Join(pveRoot, "qemu-server", "100.conf"), "vm")
+	mustWrite(filepath.Join(pveRoot, "lxc", "101.conf"), "ct")
+	mustWrite(filepath.Join(pveRoot, "firewall", "cluster.fw"), "fw")
+	mustWrite(filepath.Join(pveRoot, "nodes", "node1", "host.fw"), "hostfw")
+
+	clusterPath := filepath.Join(t.TempDir(), "pve-cluster")
+	mustWrite(filepath.Join(clusterPath, "config.db"), "db")
+	collector.config.PVEClusterPath = clusterPath
+
+	collector.config.BackupVMConfigs = false
+	collector.config.BackupPVEFirewall = false
+	collector.config.BackupPVEACL = false
+	collector.config.BackupPVEJobs = false
+	collector.config.BackupClusterConfig = false
+
+	if err := collector.collectPVEDirectories(context.Background(), false); err != nil {
+		t.Fatalf("collectPVEDirectories error: %v", err)
+	}
+
+	destPVE := collector.targetPathFor(pveRoot)
+	if _, err := os.Stat(filepath.Join(destPVE, "dummy.cfg")); err != nil {
+		t.Fatalf("expected dummy.cfg collected, got %v", err)
+	}
+
+	for _, excluded := range []string{
+		"corosync.conf",
+		"user.cfg",
+		"acl.cfg",
+		"domains.cfg",
+		"jobs.cfg",
+		"vzdump.cron",
+		filepath.Join("qemu-server", "100.conf"),
+		filepath.Join("lxc", "101.conf"),
+		filepath.Join("firewall", "cluster.fw"),
+		filepath.Join("nodes", "node1", "host.fw"),
+	} {
+		_, err := os.Stat(filepath.Join(destPVE, excluded))
+		if err == nil {
+			t.Fatalf("expected %s excluded from PVE config snapshot", excluded)
+		}
+		if !errors.Is(err, os.ErrNotExist) {
+			t.Fatalf("stat %s: %v", excluded, err)
+		}
+	}
+
+	destDB := collector.targetPathFor(filepath.Join(clusterPath, "config.db"))
+	if _, err := os.Stat(destDB); err == nil {
+		t.Fatalf("expected config.db excluded when BACKUP_CLUSTER_CONFIG=false")
+	}
+}
+
 // Test collectPVEStorageMetadata function
 func TestCollectPVEStorageMetadata(t *testing.T) {
 	collector := newPVECollector(t)
diff --git a/internal/backup/collector_system.go b/internal/backup/collector_system.go
index 09f5b20..7ca3031 100644
--- a/internal/backup/collector_system.go
+++ b/internal/backup/collector_system.go
@@ -1440,8 +1440,13 @@ func (c *Collector) collectRootHome(ctx context.Context) error {
 	}
 
 	// Only copy security-critical directories; custom paths must be configured explicitly.
-	if err := c.safeCopyDir(ctx, c.systemPath("/root/.ssh"), filepath.Join(target, ".ssh"), "root SSH directory"); err != nil && !errors.Is(err, os.ErrNotExist) {
-		c.logger.Debug("Failed to copy root SSH directory: %v", err)
+	// Respect BACKUP_SSH_KEYS to allow backing up /root without including SSH keys.
+	if c.config.BackupSSHKeys {
+		if err := c.safeCopyDir(ctx, c.systemPath("/root/.ssh"), filepath.Join(target, ".ssh"), "root SSH directory"); err != nil && !errors.Is(err, os.ErrNotExist) {
+			c.logger.Debug("Failed to copy root SSH directory: %v", err)
+		}
+	} else {
+		c.logger.Debug("Skipping /root/.ssh in root home: BACKUP_SSH_KEYS=false")
 	}
 
 	// Copy full root .config directory (for CLI tools, editors, and other configs)
@@ -1489,7 +1494,13 @@ func (c *Collector) collectUserHomes(ctx context.Context) error {
 		}
 
 		if info.IsDir() {
-			if err := c.safeCopyDir(ctx, src, dest, fmt.Sprintf("home directory for %s", name)); err != nil && !errors.Is(err, os.ErrNotExist) {
+			extraExclude := []string(nil)
+			if !c.config.BackupSSHKeys {
+				extraExclude = append(extraExclude, ".ssh")
+			}
+			if err := c.withTemporaryExcludes(extraExclude, func() error {
+				return c.safeCopyDir(ctx, src, dest, fmt.Sprintf("home directory for %s", name))
+			}); err != nil && !errors.Is(err, os.ErrNotExist) {
 				c.logger.Debug("Failed to copy home for %s: %v", name, err)
 			}
 			continue
diff --git a/internal/backup/collector_system_test.go b/internal/backup/collector_system_test.go
index f420c8e..6ee4ac5 100644
--- a/internal/backup/collector_system_test.go
+++ b/internal/backup/collector_system_test.go
@@ -135,6 +135,64 @@ func TestCollectSSHKeysCopiesEtcSSH(t *testing.T) {
 	}
 }
 
+func TestCollectRootHomeSkipsSSHKeysWhenDisabled(t *testing.T) {
+	collector := newTestCollector(t)
+
+	root := t.TempDir()
+	collector.config.SystemRootPrefix = root
+	collector.config.BackupSSHKeys = false
+
+	sshDir := filepath.Join(root, "root", ".ssh")
+	if err := os.MkdirAll(sshDir, 0o755); err != nil {
+		t.Fatalf("mkdir /root/.ssh: %v", err)
+	}
+	if err := os.WriteFile(filepath.Join(sshDir, "id_rsa"), []byte("key"), 0o600); err != nil {
+		t.Fatalf("write id_rsa: %v", err)
+	}
+
+	if err := collector.collectRootHome(context.Background()); err != nil {
+		t.Fatalf("collectRootHome failed: %v", err)
+	}
+
+	if _, err := os.Stat(filepath.Join(collector.tempDir, "root", ".ssh")); err == nil {
+		t.Fatalf("expected /root/.ssh excluded when BACKUP_SSH_KEYS=false")
+	} else if !os.IsNotExist(err) {
+		t.Fatalf("stat /root/.ssh: %v", err)
+	}
+}
+
+func TestCollectUserHomesSkipsSSHKeysWhenDisabled(t *testing.T) {
+	collector := newTestCollector(t)
+
+	root := t.TempDir()
+	collector.config.SystemRootPrefix = root
+	collector.config.BackupSSHKeys = false
+
+	userHome := filepath.Join(root, "home", "alice")
+	if err := os.MkdirAll(filepath.Join(userHome, ".ssh"), 0o755); err != nil {
+		t.Fatalf("mkdir alice .ssh: %v", err)
+	}
+	if err := os.WriteFile(filepath.Join(userHome, ".ssh", "id_rsa"), []byte("key"), 0o600); err != nil {
+		t.Fatalf("write alice id_rsa: %v", err)
+	}
+	if err := os.WriteFile(filepath.Join(userHome, "note.txt"), []byte("note"), 0o644); err != nil {
+		t.Fatalf("write note.txt: %v", err)
+	}
+
+	if err := collector.collectUserHomes(context.Background()); err != nil {
+		t.Fatalf("collectUserHomes failed: %v", err)
+	}
+
+	if _, err := os.Stat(filepath.Join(collector.tempDir, "users", "alice", "note.txt")); err != nil {
+		t.Fatalf("expected note.txt copied: %v", err)
+	}
+	if _, err := os.Stat(filepath.Join(collector.tempDir, "users", "alice", ".ssh")); err == nil {
+		t.Fatalf("expected alice .ssh excluded when BACKUP_SSH_KEYS=false")
+	} else if !os.IsNotExist(err) {
+		t.Fatalf("stat alice .ssh: %v", err)
+	}
+}
+
 func TestWriteReportFileCreatesDirectories(t *testing.T) {
 	collector := newTestCollector(t)
 	report := filepath.Join(collector.tempDir, "reports", "test", "report.txt")
diff --git a/internal/config/templates/backup.env b/internal/config/templates/backup.env
index 17cef09..1981b03 100644
--- a/internal/config/templates/backup.env
+++ b/internal/config/templates/backup.env
@@ -160,7 +160,7 @@ CLOUD_WRITE_HEALTHCHECK=false        # false = auto (list + fallback to write te
 # ----------------------------------------------------------------------
 # CONNECTION timeout: remote accessibility check (short)
 # OPERATION timeout: full upload/download operations (long)
-# NOTE: The connection timeout is also used by restore/decrypt workflows when scanning cloud backups.
+# NOTE: Restore/decrypt cloud scan uses the connection timeout per rclone command (lsf/cat); the timer resets per step.
 RCLONE_TIMEOUT_CONNECTION=30     # seconds
 RCLONE_TIMEOUT_OPERATION=300     # seconds
 RCLONE_BANDWIDTH_LIMIT="10M"     # e.g. "10M" for 10 MB/s, empty = unlimited
diff --git a/internal/orchestrator/.backup.lock b/internal/orchestrator/.backup.lock
index 2a493a8..4813a89 100644
--- a/internal/orchestrator/.backup.lock
+++ b/internal/orchestrator/.backup.lock
@@ -1,3 +1,3 @@
-pid=2367035
+pid=4950
 host=pve
-time=2026-01-21T19:42:55+01:00
+time=2026-01-23T10:01:54+01:00
diff --git a/internal/orchestrator/backup_sources.go b/internal/orchestrator/backup_sources.go
index 8642ae3..3d036d9 100644
--- a/internal/orchestrator/backup_sources.go
+++ b/internal/orchestrator/backup_sources.go
@@ -2,6 +2,7 @@ package orchestrator
 
 import (
 	"context"
+	"errors"
 	"fmt"
 	"os/exec"
 	"path"
@@ -84,10 +85,16 @@ func buildDecryptPathOptions(cfg *config.Config, logger *logging.Logger) (option
 
 // discoverRcloneBackups lists backup candidates from an rclone remote and returns
 // decrypt candidates backed by that remote (bundles and raw archives).
-func discoverRcloneBackups(ctx context.Context, remotePath string, logger *logging.Logger) (candidates []*decryptCandidate, err error) {
+func discoverRcloneBackups(ctx context.Context, cfg *config.Config, remotePath string, logger *logging.Logger, report ProgressReporter) (candidates []*decryptCandidate, err error) {
 	done := logging.DebugStart(logger, "discover rclone backups", "remote=%s", remotePath)
 	defer func() { done(err) }()
 	start := time.Now()
+
+	timeout := 30 * time.Second
+	if cfg != nil && cfg.RcloneTimeoutConnection > 0 {
+		timeout = time.Duration(cfg.RcloneTimeoutConnection) * time.Second
+	}
+	logging.DebugStep(logger, "discover rclone backups", "per_command_timeout=%s", timeout)
 	// Build full remote path - ensure it ends with ":" if it's just a remote name
 	fullPath := strings.TrimSpace(remotePath)
 	if !strings.Contains(fullPath, ":") {
@@ -98,12 +105,20 @@ func discoverRcloneBackups(ctx context.Context, remotePath string, logger *loggi
 	logging.DebugStep(logger, "discover rclone backups", "filters=bundle.tar and raw .metadata")
 	logDebug(logger, "Cloud (rclone): listing backups under %s", fullPath)
 	logDebug(logger, "Cloud (rclone): executing: rclone lsf %s", fullPath)
+	if report != nil {
+		report(fmt.Sprintf("Listing cloud path: %s", fullPath))
+	}
 
 	// Use rclone lsf to list files inside the backup directory
-	cmd := exec.CommandContext(ctx, "rclone", "lsf", fullPath)
+	lsfCtx, cancel := context.WithTimeout(ctx, timeout)
+	defer cancel()
+	cmd := exec.CommandContext(lsfCtx, "rclone", "lsf", fullPath)
 	lsfStart := time.Now()
 	output, err := cmd.CombinedOutput()
 	if err != nil {
+		if errors.Is(lsfCtx.Err(), context.DeadlineExceeded) {
+			return nil, fmt.Errorf("timed out while listing rclone remote %s (timeout=%s). Increase RCLONE_TIMEOUT_CONNECTION if needed: %w (output: %s)", fullPath, timeout, err, strings.TrimSpace(string(output)))
+		}
 		return nil, fmt.Errorf("failed to list rclone remote %s: %w (output: %s)", fullPath, err, string(output))
 	}
 	logging.DebugStep(logger, "discover rclone backups", "rclone lsf output bytes=%d elapsed=%s", len(output), time.Since(lsfStart))
@@ -140,36 +155,25 @@ func discoverRcloneBackups(ctx context.Context, remotePath string, logger *loggi
 		return remoteFile + rel
 	}
 
+	type inspectItem struct {
+		kind           decryptSourceType
+		filename       string
+		remoteBundle   string
+		remoteArchive  string
+		remoteMetadata string
+		remoteChecksum string
+	}
+
+	items := make([]inspectItem, 0)
 	for _, filename := range ordered {
-		// Only process bundle files (both plain and age-encrypted)
-		// Valid patterns:
-		//   - *.tar.{gz|xz|zst}.bundle.tar       (plain bundle)
-		//   - *.tar.{gz|xz|zst}.age.bundle.tar   (age-encrypted bundle)
 		switch {
 		case strings.HasSuffix(filename, ".bundle.tar"):
-			remoteFile := joinRemote(fullPath, filename)
-			manifest, err := inspectRcloneBundleManifest(ctx, remoteFile, logger)
-			if err != nil {
-				manifestErrors++
-				logWarning(logger, "Skipping rclone bundle %s: %v", filename, err)
-				continue
-			}
-
-			displayBase := filepath.Base(manifest.ArchivePath)
-			if strings.TrimSpace(displayBase) == "" {
-				displayBase = filepath.Base(filename)
-			}
-			candidates = append(candidates, &decryptCandidate{
-				Manifest:    manifest,
-				Source:      sourceBundle,
-				BundlePath:  remoteFile,
-				DisplayBase: displayBase,
-				IsRclone:    true,
+			items = append(items, inspectItem{
+				kind:         sourceBundle,
+				filename:     filename,
+				remoteBundle: joinRemote(fullPath, filename),
 			})
-			logDebug(logger, "Cloud (rclone): accepted backup bundle: %s", filename)
-
 		case strings.HasSuffix(filename, ".metadata"):
-			// Raw backups: archive + .metadata (+ optional .sha256).
 			archiveName := strings.TrimSuffix(filename, ".metadata")
 			if !strings.Contains(archiveName, ".tar") {
 				nonCandidateEntries++
@@ -186,28 +190,84 @@ func discoverRcloneBackups(ctx context.Context, remotePath string, logger *loggi
 			if _, ok := snapshot[archiveName+".sha256"]; ok {
 				remoteChecksum = joinRemote(fullPath, archiveName+".sha256")
 			}
+			items = append(items, inspectItem{
+				kind:           sourceRaw,
+				filename:       filename,
+				remoteArchive:  remoteArchive,
+				remoteMetadata: remoteMetadata,
+				remoteChecksum: remoteChecksum,
+			})
+		default:
+			nonCandidateEntries++
+		}
+	}
 
-			manifest, err := inspectRcloneMetadataManifest(ctx, remoteMetadata, remoteArchive, logger)
-			if err != nil {
+	if report != nil {
+		report(fmt.Sprintf("Inspecting %d candidate(s)...", len(items)))
+	}
+
+	for idx, item := range items {
+		if report != nil {
+			report(fmt.Sprintf("Inspecting %d/%d: %s", idx+1, len(items), item.filename))
+		}
+
+		itemCtx, cancel := context.WithTimeout(ctx, timeout)
+		switch item.kind {
+		case sourceBundle:
+			manifest, perr := inspectRcloneBundleManifest(itemCtx, item.remoteBundle, logger)
+			cancel()
+			if perr != nil {
+				if errors.Is(perr, context.DeadlineExceeded) {
+					return nil, fmt.Errorf("timed out while inspecting %s (timeout=%s). Increase RCLONE_TIMEOUT_CONNECTION if needed: %w", item.filename, timeout, perr)
+				}
+				if errors.Is(perr, context.Canceled) {
+					return nil, perr
+				}
+				manifestErrors++
+				logWarning(logger, "Skipping rclone bundle %s: %v", item.filename, perr)
+				continue
+			}
+
+			displayBase := filepath.Base(manifest.ArchivePath)
+			if strings.TrimSpace(displayBase) == "" {
+				displayBase = filepath.Base(item.filename)
+			}
+			candidates = append(candidates, &decryptCandidate{
+				Manifest:    manifest,
+				Source:      sourceBundle,
+				BundlePath:  item.remoteBundle,
+				DisplayBase: displayBase,
+				IsRclone:    true,
+			})
+			logDebug(logger, "Cloud (rclone): accepted backup bundle: %s", item.filename)
+
+		case sourceRaw:
+			manifest, perr := inspectRcloneMetadataManifest(itemCtx, item.remoteMetadata, item.remoteArchive, logger)
+			cancel()
+			if perr != nil {
+				if errors.Is(perr, context.DeadlineExceeded) {
+					return nil, fmt.Errorf("timed out while inspecting %s (timeout=%s). Increase RCLONE_TIMEOUT_CONNECTION if needed: %w", item.filename, timeout, perr)
+				}
+				if errors.Is(perr, context.Canceled) {
+					return nil, perr
+				}
 				manifestErrors++
-				logWarning(logger, "Skipping rclone metadata %s: %v", filename, err)
+				logWarning(logger, "Skipping rclone metadata %s: %v", item.filename, perr)
 				continue
 			}
 			displayBase := filepath.Base(manifest.ArchivePath)
 			if strings.TrimSpace(displayBase) == "" {
-				displayBase = filepath.Base(archiveName)
+				displayBase = filepath.Base(baseNameFromRemoteRef(item.remoteArchive))
 			}
 			candidates = append(candidates, &decryptCandidate{
 				Manifest:        manifest,
 				Source:          sourceRaw,
-				RawArchivePath:  remoteArchive,
-				RawMetadataPath: remoteMetadata,
-				RawChecksumPath: remoteChecksum,
+				RawArchivePath:  item.remoteArchive,
+				RawMetadataPath: item.remoteMetadata,
+				RawChecksumPath: item.remoteChecksum,
 				DisplayBase:     displayBase,
 				IsRclone:        true,
 			})
-		default:
-			nonCandidateEntries++
 		}
 	}
 
diff --git a/internal/orchestrator/backup_sources_test.go b/internal/orchestrator/backup_sources_test.go
index 96ac581..30b9f0d 100644
--- a/internal/orchestrator/backup_sources_test.go
+++ b/internal/orchestrator/backup_sources_test.go
@@ -207,7 +207,7 @@ func TestDiscoverRcloneBackups_ListsAndParsesBundles(t *testing.T) {
 	manifest, cleanup := setupFakeRcloneListAndCat(t)
 	defer cleanup()
 
-	candidates, err := discoverRcloneBackups(ctx, "gdrive:pbs-backups/server1", logger)
+	candidates, err := discoverRcloneBackups(ctx, nil, "gdrive:pbs-backups/server1", logger, nil)
 	if err != nil {
 		t.Fatalf("discoverRcloneBackups() error = %v", err)
 	}
@@ -278,7 +278,7 @@ esac
 	defer os.Unsetenv("METADATA_PATH")
 
 	ctx := context.Background()
-	candidates, err := discoverRcloneBackups(ctx, "gdrive:pbs-backups/server1", nil)
+	candidates, err := discoverRcloneBackups(ctx, nil, "gdrive:pbs-backups/server1", nil, nil)
 	if err != nil {
 		t.Fatalf("discoverRcloneBackups() error = %v", err)
 	}
@@ -407,7 +407,7 @@ esac
 	_ = os.WriteFile(rawNewestArchive, []byte("x"), 0o600)
 	_ = os.WriteFile(rawOldArchive, []byte("x"), 0o600)
 
-	candidates, err := discoverRcloneBackups(context.Background(), "gdrive:backups", nil)
+	candidates, err := discoverRcloneBackups(context.Background(), nil, "gdrive:backups", nil, nil)
 	if err != nil {
 		t.Fatalf("discoverRcloneBackups error: %v", err)
 	}
@@ -433,7 +433,7 @@ func TestDiscoverRcloneBackups_AllowsNilLogger(t *testing.T) {
 	manifest, cleanup := setupFakeRcloneListAndCat(t)
 	defer cleanup()
 
-	candidates, err := discoverRcloneBackups(ctx, "gdrive:pbs-backups/server1", nil)
+	candidates, err := discoverRcloneBackups(ctx, nil, "gdrive:pbs-backups/server1", nil, nil)
 	if err != nil {
 		t.Fatalf("discoverRcloneBackups() error = %v", err)
 	}
diff --git a/internal/orchestrator/decrypt.go b/internal/orchestrator/decrypt.go
index fa4fbdb..92e9e6b 100644
--- a/internal/orchestrator/decrypt.go
+++ b/internal/orchestrator/decrypt.go
@@ -79,94 +79,9 @@ func RunDecryptWorkflowWithDeps(ctx context.Context, deps *Deps, version string)
 	}
 	done := logging.DebugStart(logger, "decrypt workflow", "version=%s", version)
 	defer func() { done(err) }()
-	defer func() {
-		if err == nil {
-			return
-		}
-		if errors.Is(err, input.ErrInputAborted) || errors.Is(err, context.Canceled) {
-			err = ErrDecryptAborted
-		}
-	}()
-
-	reader := bufio.NewReader(os.Stdin)
-	_, prepared, err := prepareDecryptedBackup(ctx, reader, cfg, logger, version, true)
-	if err != nil {
-		return err
-	}
-	defer prepared.Cleanup()
-
-	// Ask for destination directory (where the final decrypted bundle will live)
-	destDir, err := promptDestinationDir(ctx, reader, cfg)
-	if err != nil {
-		return err
-	}
-	if err := restoreFS.MkdirAll(destDir, 0o755); err != nil {
-		return fmt.Errorf("create destination directory: %w", err)
-	}
-	destDir, _ = filepath.Abs(destDir)
-	logger.Info("Destination directory: %s", destDir)
-
-	// Determine the logical decrypted archive path for naming purposes.
-	// This keeps the same defaults and prompts as before, but the archive
-	// itself stays in the temporary working directory.
-	destArchivePath := filepath.Join(destDir, filepath.Base(prepared.ArchivePath))
-	destArchivePath, err = ensureWritablePath(ctx, reader, destArchivePath, "decrypted archive")
-	if err != nil {
-		return err
-	}
-
-	// Work exclusively inside the temporary directory created by preparePlainBundle.
-	workDir := filepath.Dir(prepared.ArchivePath)
-	archiveBase := filepath.Base(destArchivePath)
-	tempArchivePath := filepath.Join(workDir, archiveBase)
-
-	// Ensure the staged archive in the temp dir has the desired basename.
-	if tempArchivePath != prepared.ArchivePath {
-		if err := moveFileSafe(prepared.ArchivePath, tempArchivePath); err != nil {
-			return fmt.Errorf("move decrypted archive within temp dir: %w", err)
-		}
-	}
-
-	manifestCopy := prepared.Manifest
-	// Keep manifest path consistent with previous behavior: it refers to the
-	// archive location in the destination directory, even though the archive
-	// itself is not written there during the decrypt process.
-	manifestCopy.ArchivePath = destArchivePath
 
-	metadataPath := tempArchivePath + ".metadata"
-	if err := backup.CreateManifest(ctx, logger, &manifestCopy, metadataPath); err != nil {
-		return fmt.Errorf("write metadata: %w", err)
-	}
-
-	checksumPath := tempArchivePath + ".sha256"
-	if err := restoreFS.WriteFile(checksumPath, []byte(fmt.Sprintf("%s  %s\n", prepared.Checksum, filepath.Base(tempArchivePath))), 0o640); err != nil {
-		return fmt.Errorf("write checksum file: %w", err)
-	}
-
-	logger.Info("Creating decrypted bundle...")
-	bundlePath, err := createBundle(ctx, logger, tempArchivePath)
-	if err != nil {
-		return err
-	}
-
-	// Only the final decrypted bundle is moved into the destination directory.
-	// All temporary plain artifacts remain confined to the temp workdir and
-	// are removed by prepared.Cleanup().
-	logicalBundlePath := destArchivePath + ".bundle.tar"
-	targetBundlePath := strings.TrimSuffix(logicalBundlePath, ".bundle.tar") + ".decrypted.bundle.tar"
-	targetBundlePath, err = ensureWritablePath(ctx, reader, targetBundlePath, "decrypted bundle")
-	if err != nil {
-		return err
-	}
-	if err := restoreFS.Remove(targetBundlePath); err != nil && !errors.Is(err, os.ErrNotExist) {
-		logger.Warning("Failed to remove existing bundle target: %v", err)
-	}
-	if err := moveFileSafe(bundlePath, targetBundlePath); err != nil {
-		return fmt.Errorf("move decrypted bundle: %w", err)
-	}
-
-	logger.Info("Decrypted bundle created: %s", targetBundlePath)
-	return nil
+		ui := newCLIWorkflowUI(bufio.NewReader(os.Stdin), logger)
+		return runDecryptWorkflowWithUI(ctx, cfg, logger, version, ui)
 }
 
 // RunDecryptWorkflow is the legacy entrypoint that builds default deps.
@@ -185,105 +100,9 @@ func RunDecryptWorkflow(ctx context.Context, cfg *config.Config, logger *logging
 func selectDecryptCandidate(ctx context.Context, reader *bufio.Reader, cfg *config.Config, logger *logging.Logger, requireEncrypted bool) (candidate *decryptCandidate, err error) {
 	done := logging.DebugStart(logger, "select backup candidate", "requireEncrypted=%v", requireEncrypted)
 	defer func() { done(err) }()
-	pathOptions := buildDecryptPathOptions(cfg, logger)
-	if len(pathOptions) == 0 {
-		return nil, fmt.Errorf("no backup paths configured in backup.env")
-	}
-
-	if logger != nil {
-		for _, opt := range pathOptions {
-			logger.Debug("Backup source option prepared: label=%q path=%q isRclone=%v", opt.Label, opt.Path, opt.IsRclone)
-		}
-	}
-
-	var candidates []*decryptCandidate
-	var selectedPath string
-
-	for {
-		option, err := promptPathSelection(ctx, reader, pathOptions)
-		if err != nil {
-			return nil, err
-		}
-
-		if logger != nil {
-			logger.Debug("Backup source selected by user: label=%q path=%q isRclone=%v", option.Label, option.Path, option.IsRclone)
-		}
-
-			logger.Info("Scanning %s for backups...", option.Path)
-
-		// Handle rclone remotes differently from filesystem paths
-		if option.IsRclone {
-			logging.DebugStep(logger, "select backup candidate", "scanning rclone remote: %s", option.Path)
-			candidates, err = discoverRcloneBackups(ctx, option.Path, logger)
-			if err != nil {
-				logger.Warning("Failed to inspect cloud remote %s: %v", option.Path, err)
-				// On persistent failures, remove this option so it is no longer offered.
-				pathOptions = removeDecryptPathOption(pathOptions, option)
-				if len(pathOptions) == 0 {
-					return nil, fmt.Errorf("no usable backup sources available")
-				}
-				continue
-			}
-			if logger != nil {
-				logger.Debug("Cloud (rclone): %d candidate bundle(s) returned for %s", len(candidates), option.Path)
-			}
-		} else {
-			logging.DebugStep(logger, "select backup candidate", "scanning filesystem path: %s", option.Path)
-			info, err := restoreFS.Stat(option.Path)
-			if err != nil || !info.IsDir() {
-				logger.Warning("Path %s is not accessible (%v)", option.Path, err)
-				continue
-			}
-
-			candidates, err = discoverBackupCandidates(logger, option.Path)
-			if err != nil {
-				logger.Warning("Failed to inspect %s: %v", option.Path, err)
-				continue
-			}
-		}
-		if len(candidates) == 0 {
-				logger.Warning("No backups found in %s – removing from source list", option.Path)
-			if logger != nil {
-				logger.Debug("Removing backup source %q (%s) due to empty candidate list", option.Label, option.Path)
-			}
-			pathOptions = removeDecryptPathOption(pathOptions, option)
-			if len(pathOptions) == 0 {
-				return nil, fmt.Errorf("no usable backup sources available")
-			}
-			continue
-		}
-
-		if requireEncrypted {
-			encrypted := filterEncryptedCandidates(candidates)
-			if len(encrypted) == 0 {
-				logger.Warning("No encrypted backups found in %s – removing from source list", option.Path)
-				if logger != nil {
-					logger.Debug("Removing backup source %q (%s) because all candidates are plain (non-encrypted)", option.Label, option.Path)
-				}
-				pathOptions = removeDecryptPathOption(pathOptions, option)
-				if len(pathOptions) == 0 {
-					return nil, fmt.Errorf("no usable backup sources available")
-				}
-				continue
-			}
-
-			if logger != nil {
-				logger.Debug("Backup candidates after encryption filter: total=%d encrypted=%d", len(candidates), len(encrypted))
-			}
-
-			candidates = encrypted
-		}
-		selectedPath = option.Path
-		break
-	}
 
-	if requireEncrypted {
-		logger.Info("Found %d encrypted backup(s) in %s", len(candidates), selectedPath)
-	} else {
-		logger.Info("Found %d backup(s) in %s", len(candidates), selectedPath)
-	}
-	candidate, err = promptCandidateSelection(ctx, reader, candidates)
-	return candidate, err
+	ui := newCLIWorkflowUI(reader, logger)
+	return selectBackupCandidateWithUI(ctx, ui, cfg, logger, requireEncrypted)
 }
 
 func promptPathSelection(ctx context.Context, reader *bufio.Reader, options []decryptPathOption) (decryptPathOption, error) {
@@ -609,113 +428,8 @@ func downloadRcloneBackup(ctx context.Context, remotePath string, logger *loggin
 }
 
 func preparePlainBundle(ctx context.Context, reader *bufio.Reader, cand *decryptCandidate, version string, logger *logging.Logger) (bundle *preparedBundle, err error) {
-	done := logging.DebugStart(logger, "prepare plain bundle", "source=%v rclone=%v", cand.Source, cand.IsRclone)
-	defer func() { done(err) }()
-	// If this is an rclone backup, download it first
-	var rcloneCleanup func()
-	if cand.IsRclone && cand.Source == sourceBundle {
-		logger.Debug("Detected rclone backup, downloading...")
-		localPath, cleanup, err := downloadRcloneBackup(ctx, cand.BundlePath, logger)
-		if err != nil {
-			return nil, fmt.Errorf("failed to download rclone backup: %w", err)
-		}
-		rcloneCleanup = cleanup
-		// Update candidate to use local path
-		cand.BundlePath = localPath
-	}
-
-	tempRoot := filepath.Join("/tmp", "proxsave")
-	if err := restoreFS.MkdirAll(tempRoot, 0o755); err != nil {
-		if rcloneCleanup != nil {
-			rcloneCleanup()
-		}
-		return nil, fmt.Errorf("create temp root: %w", err)
-	}
-	workDir, err := restoreFS.MkdirTemp(tempRoot, "proxmox-decrypt-*")
-	if err != nil {
-		if rcloneCleanup != nil {
-			rcloneCleanup()
-		}
-		return nil, fmt.Errorf("create temp dir: %w", err)
-	}
-	logging.DebugStep(logger, "prepare plain bundle", "workdir=%s", workDir)
-	cleanup := func() {
-		_ = restoreFS.RemoveAll(workDir)
-		if rcloneCleanup != nil {
-			rcloneCleanup()
-		}
-	}
-
-	var staged stagedFiles
-	switch cand.Source {
-	case sourceBundle:
-		logger.Info("Extracting bundle %s", filepath.Base(cand.BundlePath))
-		staged, err = extractBundleToWorkdirWithLogger(cand.BundlePath, workDir, logger)
-	case sourceRaw:
-		logger.Info("Staging raw artifacts for %s", filepath.Base(cand.RawArchivePath))
-		staged, err = copyRawArtifactsToWorkdirWithLogger(ctx, cand, workDir, logger)
-	default:
-		err = fmt.Errorf("unsupported candidate source")
-	}
-	if err != nil {
-		cleanup()
-		return nil, err
-	}
-
-	manifestCopy := *cand.Manifest
-	currentEncryption := strings.ToLower(manifestCopy.EncryptionMode)
-
-	logging.DebugStep(logger, "prepare plain bundle", "encryption=%s", currentEncryption)
-	logger.Info("Preparing archive %s for decryption (mode: %s)", manifestCopy.ArchivePath, statusFromManifest(&manifestCopy))
-
-	plainArchiveName := strings.TrimSuffix(filepath.Base(staged.ArchivePath), ".age")
-	plainArchivePath := filepath.Join(workDir, plainArchiveName)
-
-	if currentEncryption == "age" {
-		if err := decryptArchiveWithPrompts(ctx, reader, staged.ArchivePath, plainArchivePath, logger); err != nil {
-			cleanup()
-			return nil, err
-		}
-	} else {
-		// For plain archives, only copy if source and destination are different
-		// to avoid truncating the file when copying to itself
-		if staged.ArchivePath != plainArchivePath {
-			if err := copyFile(restoreFS, staged.ArchivePath, plainArchivePath); err != nil {
-				cleanup()
-				return nil, fmt.Errorf("copy archive: %w", err)
-			}
-		}
-		// If paths are identical, file is already in the correct location
-	}
-
-	archiveInfo, err := restoreFS.Stat(plainArchivePath)
-	if err != nil {
-		cleanup()
-		return nil, fmt.Errorf("stat decrypted archive: %w", err)
-	}
-
-	checksum, err := backup.GenerateChecksum(ctx, logger, plainArchivePath)
-	if err != nil {
-		cleanup()
-		return nil, fmt.Errorf("generate checksum: %w", err)
-	}
-	logging.DebugStep(logger, "prepare plain bundle", "checksum computed")
-
-	manifestCopy.ArchivePath = plainArchivePath
-	manifestCopy.ArchiveSize = archiveInfo.Size()
-	manifestCopy.SHA256 = checksum
-	manifestCopy.EncryptionMode = "none"
-	if version != "" {
-		manifestCopy.ScriptVersion = version
-	}
-
-	bundle = &preparedBundle{
-		ArchivePath: plainArchivePath,
-		Manifest:    manifestCopy,
-		Checksum:    checksum,
-		cleanup:     cleanup,
-	}
-	return bundle, nil
+	ui := newCLIWorkflowUI(reader, logger)
+	return preparePlainBundleWithUI(ctx, cand, version, logger, ui)
 }
 
 func prepareDecryptedBackup(ctx context.Context, reader *bufio.Reader, cfg *config.Config, logger *logging.Logger, version string, requireEncrypted bool) (candidate *decryptCandidate, prepared *preparedBundle, err error) {
@@ -936,43 +650,9 @@ func copyRawArtifactsToWorkdirWithLogger(ctx context.Context, cand *decryptCandi
 }
 
 func decryptArchiveWithPrompts(ctx context.Context, reader *bufio.Reader, encryptedPath, outputPath string, logger *logging.Logger) error {
-	for {
-		fmt.Print("Enter decryption key or passphrase (0 = exit): ")
-		inputBytes, err := input.ReadPasswordWithContext(ctx, readPassword, int(os.Stdin.Fd()))
-		fmt.Println()
-		if err != nil {
-			return err
-		}
-		trimmed := bytes.TrimSpace(inputBytes)
-		if len(trimmed) == 0 {
-			zeroBytes(inputBytes)
-			logger.Warning("Input cannot be empty")
-			continue
-		}
-		input := string(trimmed)
-		zeroBytes(trimmed)
-		zeroBytes(inputBytes)
-		if input == "0" {
-			return ErrDecryptAborted
-		}
-
-		identities, err := parseIdentityInput(input)
-		resetString(&input)
-		if err != nil {
-			logger.Warning("Invalid key/passphrase: %v", err)
-			continue
-		}
-
-		if err := decryptWithIdentity(encryptedPath, outputPath, identities...); err != nil {
-			var noMatch *age.NoIdentityMatchError
-			if errors.Is(err, age.ErrIncorrectIdentity) || errors.As(err, &noMatch) {
-				logger.Warning("Provided key or passphrase does not match this archive. Try again or press 0 to exit.")
-				continue
-			}
-			return err
-		}
-		return nil
-	}
+	ui := newCLIWorkflowUI(reader, logger)
+	displayName := filepath.Base(encryptedPath)
+	return decryptArchiveWithSecretPrompt(ctx, encryptedPath, outputPath, displayName, logger, ui.PromptDecryptSecret)
 }
 
 func parseIdentityInput(input string) ([]age.Identity, error) {
@@ -1063,48 +743,8 @@ func moveFileSafe(src, dst string) error {
 }
 
 func ensureWritablePath(ctx context.Context, reader *bufio.Reader, path, description string) (string, error) {
-	current := filepath.Clean(path)
-	for {
-		if _, err := restoreFS.Stat(current); errors.Is(err, os.ErrNotExist) {
-			return current, nil
-		} else if err != nil && !errors.Is(err, os.ErrExist) {
-			return "", fmt.Errorf("stat %s: %w", current, err)
-		}
-
-		fmt.Printf("%s %s already exists.\n", titleCaser.String(description), current)
-		fmt.Println("  [1] Overwrite")
-			fmt.Println("  [2] Enter a different path")
-			fmt.Println("  [0] Exit")
-			fmt.Print("Choice: ")
-
-			inputLine, err := input.ReadLineWithContext(ctx, reader)
-			if err != nil {
-				return "", err
-			}
-			switch strings.TrimSpace(inputLine) {
-			case "1":
-				if err := restoreFS.Remove(current); err != nil {
-					fmt.Printf("Failed to remove existing file: %v\n", err)
-					continue
-				}
-				return current, nil
-			case "2":
-				fmt.Print("Enter new path: ")
-				newPath, err := input.ReadLineWithContext(ctx, reader)
-				if err != nil {
-					return "", err
-				}
-			trimmed := strings.TrimSpace(newPath)
-			if trimmed == "" {
-				continue
-			}
-			current = filepath.Clean(trimmed)
-		case "0":
-			return "", ErrDecryptAborted
-		default:
-			fmt.Println("Please enter 1, 2 or 0.")
-		}
-	}
+	ui := newCLIWorkflowUI(reader, nil)
+	return ensureWritablePathWithUI(ctx, ui, path, description)
 }
 
 func formatClusterMode(value string) string {
diff --git a/internal/orchestrator/decrypt_tui.go b/internal/orchestrator/decrypt_tui.go
index a45af1a..b0f23a8 100644
--- a/internal/orchestrator/decrypt_tui.go
+++ b/internal/orchestrator/decrypt_tui.go
@@ -7,8 +7,6 @@ import (
 	"os"
 	"path/filepath"
 	"strings"
-	"sync/atomic"
-	"time"
 
 	"filippo.io/age"
 	"github.com/gdamore/tcell/v2"
@@ -21,15 +19,9 @@ import (
 	"github.com/tis24dev/proxsave/internal/tui/components"
 )
 
-type decryptSelection struct {
-	Candidate *decryptCandidate
-	DestDir   string
-}
-
 const (
 	decryptWizardSubtitle = "Decrypt Backup Workflow"
 	decryptNavText        = "[yellow]Navigation:[white] TAB/↑↓ to move | ENTER to select | ESC to exit screens | Mouse clicks enabled"
-	errorModalPage        = "decrypt-error-modal"
 
 	pathActionOverwrite = "overwrite"
 	pathActionNew       = "new"
@@ -55,401 +47,16 @@ func RunDecryptWorkflowTUI(ctx context.Context, cfg *config.Config, logger *logg
 	done := logging.DebugStart(logger, "decrypt workflow (tui)", "version=%s", version)
 	defer func() { done(err) }()
 
-	selection, err := runDecryptSelectionWizard(ctx, cfg, logger, configPath, buildSig)
-	if err != nil {
+	ui := newTUIWorkflowUI(configPath, buildSig, logger)
+	if err := runDecryptWorkflowWithUI(ctx, cfg, logger, version, ui); err != nil {
 		if errors.Is(err, ErrDecryptAborted) {
 			return ErrDecryptAborted
 		}
 		return err
 	}
-
-	prepared, err := preparePlainBundleTUI(ctx, selection.Candidate, version, logger, configPath, buildSig)
-	if err != nil {
-		return err
-	}
-	defer prepared.Cleanup()
-
-	destDir := selection.DestDir
-	if err := restoreFS.MkdirAll(destDir, 0o755); err != nil {
-		return fmt.Errorf("create destination directory: %w", err)
-	}
-
-	// Determine the logical decrypted archive path for naming purposes.
-	// This keeps the same defaults and prompts as before, but the archive
-	// itself stays in the temporary working directory.
-	destArchivePath := filepath.Join(destDir, filepath.Base(prepared.ArchivePath))
-	destArchivePath, err = ensureWritablePathTUI(destArchivePath, "decrypted archive", configPath, buildSig)
-	if err != nil {
-		return err
-	}
-
-	// Work exclusively inside the temporary directory created by preparePlainBundleTUI.
-	workDir := filepath.Dir(prepared.ArchivePath)
-	archiveBase := filepath.Base(destArchivePath)
-	tempArchivePath := filepath.Join(workDir, archiveBase)
-
-	// Ensure the staged archive in the temp dir has the desired basename.
-	if tempArchivePath != prepared.ArchivePath {
-		if err := moveFileSafe(prepared.ArchivePath, tempArchivePath); err != nil {
-			return fmt.Errorf("move decrypted archive within temp dir: %w", err)
-		}
-	}
-
-	manifestCopy := prepared.Manifest
-	// As in the CLI workflow, keep the manifest's ArchivePath pointing to the
-	// destination archive location while the actual archive continues to live
-	// only inside the temporary work directory.
-	manifestCopy.ArchivePath = destArchivePath
-
-	metadataPath := tempArchivePath + ".metadata"
-	if err := backup.CreateManifest(ctx, logger, &manifestCopy, metadataPath); err != nil {
-		return fmt.Errorf("write metadata: %w", err)
-	}
-
-	checksumPath := tempArchivePath + ".sha256"
-	if err := restoreFS.WriteFile(checksumPath, []byte(fmt.Sprintf("%s  %s\n", prepared.Checksum, filepath.Base(tempArchivePath))), 0o640); err != nil {
-		return fmt.Errorf("write checksum file: %w", err)
-	}
-
-	logger.Debug("Creating decrypted bundle...")
-	bundlePath, err := createBundle(ctx, logger, tempArchivePath)
-	if err != nil {
-		return err
-	}
-
-	// Only the final decrypted bundle is moved into the destination directory.
-	logicalBundlePath := destArchivePath + ".bundle.tar"
-	targetBundlePath := strings.TrimSuffix(logicalBundlePath, ".bundle.tar") + ".decrypted.bundle.tar"
-	targetBundlePath, err = ensureWritablePathTUI(targetBundlePath, "decrypted bundle", configPath, buildSig)
-	if err != nil {
-		return err
-	}
-	if err := restoreFS.Remove(targetBundlePath); err != nil && !errors.Is(err, os.ErrNotExist) {
-		logger.Warning("Failed to remove existing bundle target: %v", err)
-	}
-	if err := moveFileSafe(bundlePath, targetBundlePath); err != nil {
-		return fmt.Errorf("move decrypted bundle: %w", err)
-	}
-
-	logger.Info("Decrypted bundle created: %s", targetBundlePath)
 	return nil
 }
 
-func runDecryptSelectionWizard(ctx context.Context, cfg *config.Config, logger *logging.Logger, configPath, buildSig string) (selection *decryptSelection, err error) {
-	if ctx == nil {
-		ctx = context.Background()
-	}
-	done := logging.DebugStart(logger, "decrypt selection wizard", "tui=true")
-	defer func() { done(err) }()
-	options := buildDecryptPathOptions(cfg, logger)
-	if len(options) == 0 {
-		err = fmt.Errorf("no backup paths configured in backup.env")
-		return nil, err
-	}
-	for _, opt := range options {
-		logging.DebugStep(logger, "decrypt selection wizard", "option label=%q path=%q rclone=%v", opt.Label, opt.Path, opt.IsRclone)
-	}
-
-	app := newTUIApp()
-	pages := tview.NewPages()
-
-	selection = &decryptSelection{}
-	var selectionErr error
-	var scan scanController
-	var scanSeq uint64
-
-	pathList := tview.NewList().ShowSecondaryText(false)
-	pathList.SetMainTextColor(tcell.ColorWhite).
-		SetSelectedTextColor(tcell.ColorWhite).
-		SetSelectedBackgroundColor(tui.ProxmoxOrange)
-
-	for _, opt := range options {
-		// Use parentheses instead of square brackets (tview interprets [] as color tags)
-		label := fmt.Sprintf("%s (%s)", opt.Label, opt.Path)
-		pathList.AddItem(label, "", 0, nil)
-	}
-
-	pathList.SetSelectedFunc(func(index int, mainText, secondaryText string, shortcut rune) {
-		if index < 0 || index >= len(options) {
-			return
-		}
-		selectedOption := options[index]
-		scanID := atomic.AddUint64(&scanSeq, 1)
-		logging.DebugStep(logger, "decrypt selection wizard", "selected source label=%q path=%q rclone=%v", selectedOption.Label, selectedOption.Path, selectedOption.IsRclone)
-		pages.SwitchToPage("loading")
-		go func() {
-			scanCtx, finish := scan.Start(ctx)
-			defer finish()
-
-			var candidates []*decryptCandidate
-			var scanErr error
-			scanDone := logging.DebugStart(logger, "scan backup source", "id=%d path=%s rclone=%v", scanID, selectedOption.Path, selectedOption.IsRclone)
-			defer func() { scanDone(scanErr) }()
-
-			if selectedOption.IsRclone {
-				timeout := 30 * time.Second
-				if cfg != nil && cfg.RcloneTimeoutConnection > 0 {
-					timeout = time.Duration(cfg.RcloneTimeoutConnection) * time.Second
-				}
-				logging.DebugStep(logger, "scan backup source", "id=%d rclone_timeout=%s", scanID, timeout)
-				rcloneCtx, cancel := context.WithTimeout(scanCtx, timeout)
-				defer cancel()
-				candidates, scanErr = discoverRcloneBackups(rcloneCtx, selectedOption.Path, logger)
-			} else {
-				candidates, scanErr = discoverBackupCandidates(logger, selectedOption.Path)
-			}
-			logging.DebugStep(logger, "scan backup source", "candidates=%d", len(candidates))
-			if scanCtx.Err() != nil {
-				scanErr = scanCtx.Err()
-				return
-			}
-			app.QueueUpdateDraw(func() {
-				if scanErr != nil {
-					message := fmt.Sprintf("Failed to inspect %s: %v", selectedOption.Path, scanErr)
-					if selectedOption.IsRclone && errors.Is(scanErr, context.DeadlineExceeded) {
-						message = fmt.Sprintf("Timed out while scanning %s (rclone). Check connectivity/rclone config or increase RCLONE_TIMEOUT_CONNECTION. (%v)", selectedOption.Path, scanErr)
-					}
-					showErrorModal(app, pages, configPath, buildSig, message, func() {
-						pages.SwitchToPage("paths")
-					})
-					return
-				}
-
-				encrypted := filterEncryptedCandidates(candidates)
-				if len(encrypted) == 0 {
-					message := "No encrypted backups found in selected path."
-					showErrorModal(app, pages, configPath, buildSig, message, func() {
-						pages.SwitchToPage("paths")
-					})
-					return
-				}
-
-				showCandidatePage(app, pages, encrypted, configPath, buildSig, func(c *decryptCandidate) {
-					selection.Candidate = c
-					showDestinationForm(app, pages, cfg, c, configPath, buildSig, func(dest string) {
-						selection.DestDir = dest
-						app.Stop()
-					})
-				}, func() {
-					selectionErr = ErrDecryptAborted
-					app.Stop()
-				})
-			})
-		}()
-	})
-	pathList.SetDoneFunc(func() {
-		logging.DebugStep(logger, "decrypt selection wizard", "cancel requested (done func)")
-		scan.Cancel()
-		selectionErr = ErrDecryptAborted
-		app.Stop()
-	})
-
-	form := components.NewForm(app)
-	listHeight := len(options)
-	if listHeight < 8 {
-		listHeight = 8
-	}
-	if listHeight > 14 {
-		listHeight = 14
-	}
-	listItem := components.NewListFormItem(pathList).
-		SetLabel("Available backup sources").
-		SetFieldHeight(listHeight)
-	form.Form.AddFormItem(listItem)
-	form.Form.SetFocus(0)
-
-	form.SetOnCancel(func() {
-		logging.DebugStep(logger, "decrypt selection wizard", "cancel requested (form)")
-		scan.Cancel()
-		selectionErr = ErrDecryptAborted
-	})
-	form.AddCancelButton("Cancel")
-	enableFormNavigation(form, nil)
-
-	pathPage := buildWizardPage("Select backup source", configPath, buildSig, form.Form)
-	pages.AddPage("paths", pathPage, true, true)
-
-	loadingText := tview.NewTextView().
-		SetText("Scanning backup path...").
-		SetTextAlign(tview.AlignCenter)
-
-	loadingForm := components.NewForm(app)
-	loadingForm.SetOnCancel(func() {
-		logging.DebugStep(logger, "decrypt selection wizard", "cancel requested (loading form)")
-		scan.Cancel()
-		selectionErr = ErrDecryptAborted
-	})
-	loadingForm.AddCancelButton("Cancel")
-	loadingContent := tview.NewFlex().
-		SetDirection(tview.FlexRow).
-		AddItem(loadingText, 0, 1, false).
-		AddItem(loadingForm.Form, 3, 0, false)
-	loadingPage := buildWizardPage("Loading backups", configPath, buildSig, loadingContent)
-	pages.AddPage("loading", loadingPage, true, false)
-
-	app.SetRoot(pages, true).SetFocus(form.Form)
-	if runErr := app.Run(); runErr != nil {
-		err = runErr
-		return nil, err
-	}
-	if selectionErr != nil {
-		err = selectionErr
-		return nil, err
-	}
-	if selection.Candidate == nil || selection.DestDir == "" {
-		err = ErrDecryptAborted
-		return nil, err
-	}
-	return selection, nil
-}
-
-func showErrorModal(app *tui.App, pages *tview.Pages, configPath, buildSig, message string, onDismiss func()) {
-	modal := tview.NewModal().
-		SetText(fmt.Sprintf("%s %s\n\n[yellow]Press ENTER to continue[white]", tui.SymbolError, message)).
-		AddButtons([]string{"OK"}).
-		SetDoneFunc(func(buttonIndex int, buttonLabel string) {
-			if pages.HasPage(errorModalPage) {
-				pages.RemovePage(errorModalPage)
-			}
-			if onDismiss != nil {
-				onDismiss()
-			}
-		})
-
-	modal.SetBorder(true).
-		SetTitle(" Decrypt Error ").
-		SetTitleAlign(tview.AlignCenter).
-		SetTitleColor(tui.ErrorRed).
-		SetBorderColor(tui.ErrorRed).
-		SetBackgroundColor(tcell.ColorBlack)
-
-	page := buildWizardPage("Error", configPath, buildSig, modal)
-	if pages.HasPage(errorModalPage) {
-		pages.RemovePage(errorModalPage)
-	}
-	pages.AddPage(errorModalPage, page, true, true)
-	app.SetFocus(modal)
-}
-
-func showCandidatePage(app *tui.App, pages *tview.Pages, candidates []*decryptCandidate, configPath, buildSig string, onSelect func(*decryptCandidate), onCancel func()) {
-	list := tview.NewList().ShowSecondaryText(false)
-	list.SetMainTextColor(tcell.ColorWhite).
-		SetSelectedTextColor(tcell.ColorWhite).
-		SetSelectedBackgroundColor(tui.ProxmoxOrange)
-
-	type row struct {
-		created     string
-		mode        string
-		tool        string
-		targets     string
-		compression string
-	}
-
-	rows := make([]row, len(candidates))
-	var maxMode, maxTool, maxTargets, maxComp int
-
-	for idx, cand := range candidates {
-		created := cand.Manifest.CreatedAt.Format("2006-01-02 15:04:05")
-
-		mode := strings.ToUpper(statusFromManifest(cand.Manifest))
-		if mode == "" {
-			mode = "UNKNOWN"
-		}
-
-		toolVersion := strings.TrimSpace(cand.Manifest.ScriptVersion)
-		if toolVersion == "" {
-			toolVersion = "unknown"
-		}
-		tool := "Tool " + toolVersion
-
-		targets := buildTargetInfo(cand.Manifest)
-
-		comp := ""
-		if c := strings.TrimSpace(cand.Manifest.CompressionType); c != "" {
-			comp = strings.ToUpper(c)
-		}
-
-		rows[idx] = row{
-			created:     created,
-			mode:        mode,
-			tool:        tool,
-			targets:     targets,
-			compression: comp,
-		}
-
-		if len(mode) > maxMode {
-			maxMode = len(mode)
-		}
-		if len(tool) > maxTool {
-			maxTool = len(tool)
-		}
-		if len(targets) > maxTargets {
-			maxTargets = len(targets)
-		}
-		if len(comp) > maxComp {
-			maxComp = len(comp)
-		}
-	}
-
-	for idx, r := range rows {
-		line := fmt.Sprintf(
-			"%2d) %s  %-*s  %-*s  %-*s",
-			idx+1,
-			r.created,
-			maxMode, r.mode,
-			maxTool, r.tool,
-			maxTargets, r.targets,
-		)
-		if maxComp > 0 {
-			line = fmt.Sprintf("%s  %-*s", line, maxComp, r.compression)
-		}
-		list.AddItem(line, "", 0, nil)
-	}
-
-	list.SetSelectedFunc(func(index int, mainText, secondaryText string, shortcut rune) {
-		if index < 0 || index >= len(candidates) {
-			return
-		}
-		onSelect(candidates[index])
-	})
-	list.SetDoneFunc(func() {
-		pages.SwitchToPage("paths")
-	})
-
-	form := components.NewForm(app)
-	listHeight := len(candidates)
-	if listHeight < 8 {
-		listHeight = 8
-	}
-	if listHeight > 14 {
-		listHeight = 14
-	}
-	listItem := components.NewListFormItem(list).
-		SetLabel("Available backups").
-		SetFieldHeight(listHeight)
-	form.Form.AddFormItem(listItem)
-	form.Form.SetFocus(0)
-
-	form.SetOnCancel(func() {
-		if onCancel != nil {
-			onCancel()
-		}
-	})
-
-	// Back goes on the left, Cancel on the right (order of AddButton calls)
-	form.Form.AddButton("Back", func() {
-		pages.SwitchToPage("paths")
-	})
-	form.AddCancelButton("Cancel")
-	enableFormNavigation(form, nil)
-
-	page := buildWizardPage("Select backup to decrypt", configPath, buildSig, form.Form)
-	if pages.HasPage("candidates") {
-		pages.RemovePage("candidates")
-	}
-	pages.AddPage("candidates", page, true, true)
-}
-
 func buildTargetInfo(manifest *backup.Manifest) string {
 	targets := formatTargets(manifest)
 	if targets == "" {
@@ -497,66 +104,6 @@ func filterEncryptedCandidates(candidates []*decryptCandidate) []*decryptCandida
 	return filtered
 }
 
-func showDestinationForm(app *tui.App, pages *tview.Pages, cfg *config.Config, selected *decryptCandidate, configPath, buildSig string, onSubmit func(string)) {
-	defaultDir := "./decrypt"
-	if cfg != nil && strings.TrimSpace(cfg.BaseDir) != "" {
-		defaultDir = filepath.Join(strings.TrimSpace(cfg.BaseDir), "decrypt")
-	}
-	form := components.NewForm(app)
-	form.AddInputField("Destination directory", defaultDir, 48, nil, nil)
-
-	form.SetOnSubmit(func(values map[string]string) error {
-		dest := strings.TrimSpace(values["Destination directory"])
-		if dest == "" {
-			return fmt.Errorf("destination directory cannot be empty")
-		}
-		onSubmit(filepath.Clean(dest))
-		return nil
-	})
-	form.SetOnCancel(func() {
-		pages.SwitchToPage("candidates")
-	})
-
-	// Buttons: Back (left), Continue, Cancel (right)
-	form.Form.AddButton("Back", func() {
-		pages.SwitchToPage("candidates")
-	})
-	form.AddSubmitButton("Continue")
-	form.AddCancelButton("Cancel")
-
-	// Selected backup summary
-	var summary string
-	if selected != nil && selected.Manifest != nil {
-		created := selected.Manifest.CreatedAt.Format("2006-01-02 15:04:05")
-		mode := strings.ToUpper(statusFromManifest(selected.Manifest))
-		if mode == "" {
-			mode = "UNKNOWN"
-		}
-		targetInfo := buildTargetInfo(selected.Manifest)
-		summary = fmt.Sprintf("Selected backup: %s • %s • %s", created, mode, targetInfo)
-	}
-
-	var content tview.Primitive
-	if summary != "" {
-		selText := tview.NewTextView().
-			SetText(summary).
-			SetTextColor(tcell.ColorWhite).
-			SetDynamicColors(true)
-		content = tview.NewFlex().
-			SetDirection(tview.FlexRow).
-			AddItem(selText, 2, 0, false).
-			AddItem(form.Form, 0, 1, true)
-	} else {
-		content = form.Form
-	}
-
-	page := buildWizardPage("Destination directory", configPath, buildSig, content)
-	if pages.HasPage("destination") {
-		pages.RemovePage("destination")
-	}
-	pages.AddPage("destination", page, true, true)
-}
-
 func ensureWritablePathTUI(path, description, configPath, buildSig string) (string, error) {
 	current := filepath.Clean(path)
 	if description == "" {
diff --git a/internal/orchestrator/decrypt_tui_test.go b/internal/orchestrator/decrypt_tui_test.go
index 9b913ab..6404b76 100644
--- a/internal/orchestrator/decrypt_tui_test.go
+++ b/internal/orchestrator/decrypt_tui_test.go
@@ -11,10 +11,7 @@ import (
 	"github.com/rivo/tview"
 
 	"github.com/tis24dev/proxsave/internal/backup"
-	"github.com/tis24dev/proxsave/internal/config"
 	"github.com/tis24dev/proxsave/internal/logging"
-	"github.com/tis24dev/proxsave/internal/tui"
-	"github.com/tis24dev/proxsave/internal/tui/components"
 	"github.com/tis24dev/proxsave/internal/types"
 )
 
@@ -249,131 +246,6 @@ func TestPreparePlainBundleTUICopiesRawArtifacts(t *testing.T) {
 	}
 }
 
-func TestShowErrorModalAddsWizardPage(t *testing.T) {
-	app := tui.NewApp()
-	pages := tview.NewPages()
-
-	showErrorModal(app, pages, "cfg", "sig", "boom", nil)
-
-	if !pages.HasPage(errorModalPage) {
-		t.Fatalf("expected %q page to be present", errorModalPage)
-	}
-
-	page := pages.GetPage(errorModalPage)
-	flex, ok := page.(*tview.Flex)
-	if !ok {
-		t.Fatalf("expected *tview.Flex, got %T", page)
-	}
-	content := flex.GetItem(3)
-	modal, ok := content.(*tview.Modal)
-	if !ok {
-		t.Fatalf("expected *tview.Modal content, got %T", content)
-	}
-	if modal.GetTitle() != " Decrypt Error " {
-		t.Fatalf("modal title=%q; want %q", modal.GetTitle(), " Decrypt Error ")
-	}
-}
-
-func TestShowCandidatePageAddsCandidatesPageWithItems(t *testing.T) {
-	app := tui.NewApp()
-	pages := tview.NewPages()
-
-	now := time.Unix(1700000000, 0)
-	candidates := []*decryptCandidate{
-		{
-			Manifest: &backup.Manifest{
-				CreatedAt:       now,
-				EncryptionMode:  "age",
-				ProxmoxTargets:  []string{"pve"},
-				ProxmoxVersion:  "8.1",
-				CompressionType: "zstd",
-				ClusterMode:     "standalone",
-				ScriptVersion:   "1.0.0",
-			},
-		},
-		{
-			Manifest: &backup.Manifest{
-				CreatedAt:       now.Add(-time.Hour),
-				EncryptionMode:  "age",
-				ProxmoxTargets:  []string{"pbs"},
-				CompressionType: "xz",
-				ScriptVersion:   "1.0.0",
-			},
-		},
-	}
-
-	showCandidatePage(app, pages, candidates, "cfg", "sig", func(*decryptCandidate) {}, func() {})
-
-	if !pages.HasPage("candidates") {
-		t.Fatalf("expected candidates page to be present")
-	}
-	page := pages.GetPage("candidates")
-	flex, ok := page.(*tview.Flex)
-	if !ok {
-		t.Fatalf("expected *tview.Flex, got %T", page)
-	}
-	content := flex.GetItem(3)
-	form, ok := content.(*tview.Form)
-	if !ok {
-		t.Fatalf("expected *tview.Form content, got %T", content)
-	}
-	if form.GetFormItemCount() != 1 {
-		t.Fatalf("form items=%d; want 1", form.GetFormItemCount())
-	}
-	listItem, ok := form.GetFormItem(0).(*components.ListFormItem)
-	if !ok {
-		t.Fatalf("expected *components.ListFormItem, got %T", form.GetFormItem(0))
-	}
-	if got := listItem.GetItemCount(); got != len(candidates) {
-		t.Fatalf("list items=%d; want %d", got, len(candidates))
-	}
-}
-
-func TestShowDestinationFormAddsDestinationPageWithInput(t *testing.T) {
-	app := tui.NewApp()
-	pages := tview.NewPages()
-
-	cfg := &config.Config{BaseDir: t.TempDir()}
-	selected := &decryptCandidate{
-		Manifest: &backup.Manifest{
-			CreatedAt:      time.Unix(1700000000, 0),
-			EncryptionMode: "age",
-			ProxmoxTargets: []string{"pve"},
-			ScriptVersion:  "1.0.0",
-		},
-	}
-
-	showDestinationForm(app, pages, cfg, selected, "cfg", "sig", func(string) {})
-
-	if !pages.HasPage("destination") {
-		t.Fatalf("expected destination page to be present")
-	}
-	page := pages.GetPage("destination")
-	flex, ok := page.(*tview.Flex)
-	if !ok {
-		t.Fatalf("expected *tview.Flex, got %T", page)
-	}
-	content := flex.GetItem(3)
-	inner, ok := content.(*tview.Flex)
-	if !ok {
-		t.Fatalf("expected inner *tview.Flex, got %T", content)
-	}
-	form, ok := inner.GetItem(1).(*tview.Form)
-	if !ok {
-		t.Fatalf("expected *tview.Form, got %T", inner.GetItem(1))
-	}
-	if form.GetFormItemCount() < 1 {
-		t.Fatalf("expected at least 1 form item")
-	}
-	field, ok := form.GetFormItem(0).(*tview.InputField)
-	if !ok {
-		t.Fatalf("expected first form item to be *tview.InputField, got %T", form.GetFormItem(0))
-	}
-	if field.GetLabel() != "Destination directory" {
-		t.Fatalf("label=%q; want %q", field.GetLabel(), "Destination directory")
-	}
-}
-
 func TestPreparePlainBundleTUIRejectsInvalidCandidate(t *testing.T) {
 	logger := logging.New(types.LogLevelError, false)
 	ctx := context.Background()
diff --git a/internal/orchestrator/network_apply.go b/internal/orchestrator/network_apply.go
index 22de576..ad1b2e9 100644
--- a/internal/orchestrator/network_apply.go
+++ b/internal/orchestrator/network_apply.go
@@ -68,386 +68,6 @@ func shouldAttemptNetworkApply(plan *RestorePlan) bool {
 	return plan.HasCategoryID("network")
 }
 
-func maybeApplyNetworkConfigCLI(ctx context.Context, reader *bufio.Reader, logger *logging.Logger, plan *RestorePlan, safetyBackup, networkRollbackBackup *SafetyBackupResult, stageRoot, archivePath string, dryRun bool) (err error) {
-	if !shouldAttemptNetworkApply(plan) {
-		if logger != nil {
-			logger.Debug("Network safe apply (CLI): skipped (network category not selected)")
-		}
-		return nil
-	}
-	done := logging.DebugStart(logger, "network safe apply (cli)", "dryRun=%v euid=%d archive=%s", dryRun, os.Geteuid(), strings.TrimSpace(archivePath))
-	defer func() { done(err) }()
-
-	if !isRealRestoreFS(restoreFS) {
-		logger.Debug("Skipping live network apply: non-system filesystem in use")
-		return nil
-	}
-	if dryRun {
-		logger.Info("Dry run enabled: skipping live network apply")
-		return nil
-	}
-	if os.Geteuid() != 0 {
-		logger.Warning("Skipping live network apply: requires root privileges")
-		return nil
-	}
-
-	logging.DebugStep(logger, "network safe apply (cli)", "Resolve rollback backup paths")
-	networkRollbackPath := ""
-	if networkRollbackBackup != nil {
-		networkRollbackPath = strings.TrimSpace(networkRollbackBackup.BackupPath)
-	}
-	fullRollbackPath := ""
-	if safetyBackup != nil {
-		fullRollbackPath = strings.TrimSpace(safetyBackup.BackupPath)
-	}
-	logging.DebugStep(logger, "network safe apply (cli)", "Rollback backup resolved: network=%q full=%q", networkRollbackPath, fullRollbackPath)
-	if networkRollbackPath == "" && fullRollbackPath == "" {
-		logger.Warning("Skipping live network apply: rollback backup not available")
-		if strings.TrimSpace(stageRoot) != "" {
-			logger.Info("Network configuration is staged; skipping NIC repair/apply due to missing rollback backup.")
-			return nil
-		}
-		repairNow, err := promptYesNo(ctx, reader, "Attempt NIC name repair in restored network config files now (no reload)? (y/N): ")
-		if err != nil {
-			return err
-		}
-		logging.DebugStep(logger, "network safe apply (cli)", "User choice: repairNow=%v", repairNow)
-		if repairNow {
-			_ = maybeRepairNICNamesCLI(ctx, reader, logger, archivePath)
-		}
-		logger.Info("Skipping live network apply (you can reboot or apply manually later).")
-		return nil
-	}
-
-	logging.DebugStep(logger, "network safe apply (cli)", "Prompt: apply network now with rollback timer")
-	rollbackSeconds := int(defaultNetworkRollbackTimeout.Seconds())
-	fmt.Println()
-	fmt.Println("Network restore: a restored network configuration is ready to apply.")
-	if strings.TrimSpace(stageRoot) != "" {
-		fmt.Printf("Source: %s (will be copied to /etc and applied)\n", strings.TrimSpace(stageRoot))
-	}
-	fmt.Println("This will reload networking immediately (no reboot).")
-	fmt.Println("WARNING: This may change the active IP and disconnect SSH/Web sessions.")
-	fmt.Printf("After applying, type COMMIT within %ds or ProxSave will roll back automatically.\n", rollbackSeconds)
-	fmt.Println("Recommendation: run this step from the local console/IPMI, not over SSH.")
-	applyNow, err := promptYesNoWithCountdown(ctx, reader, logger, "Apply network configuration now?", 90*time.Second, false)
-	if err != nil {
-		return err
-	}
-	logging.DebugStep(logger, "network safe apply (cli)", "User choice: applyNow=%v", applyNow)
-	if !applyNow {
-		if strings.TrimSpace(stageRoot) == "" {
-			repairNow, err := promptYesNo(ctx, reader, "Attempt NIC name repair in restored network config files now (no reload)? (y/N): ")
-			if err != nil {
-				return err
-			}
-			logging.DebugStep(logger, "network safe apply (cli)", "User choice: repairNow=%v", repairNow)
-			if repairNow {
-				_ = maybeRepairNICNamesCLI(ctx, reader, logger, archivePath)
-			}
-		} else {
-			logger.Info("Network configuration is staged (not yet written to /etc); skipping NIC repair prompt.")
-		}
-		logger.Info("Skipping live network apply (you can apply later).")
-		return nil
-	}
-
-	rollbackPath := networkRollbackPath
-	if rollbackPath == "" {
-		if fullRollbackPath == "" {
-			logger.Warning("Skipping live network apply: rollback backup not available")
-			return nil
-		}
-		logging.DebugStep(logger, "network safe apply (cli)", "Prompt: network-only rollback missing; allow full rollback backup fallback")
-		ok, err := promptYesNo(ctx, reader, "Network-only rollback backup not available. Use full safety backup for rollback instead (may revert other restored categories)? (y/N): ")
-		if err != nil {
-			return err
-		}
-		logging.DebugStep(logger, "network safe apply (cli)", "User choice: allowFullRollback=%v", ok)
-		if !ok {
-			repairNow, err := promptYesNo(ctx, reader, "Attempt NIC name repair in restored network config files now (no reload)? (y/N): ")
-			if err != nil {
-				return err
-			}
-			logging.DebugStep(logger, "network safe apply (cli)", "User choice: repairNow=%v", repairNow)
-			if repairNow {
-				_ = maybeRepairNICNamesCLI(ctx, reader, logger, archivePath)
-			}
-			logger.Info("Skipping live network apply (you can reboot or apply manually later).")
-			return nil
-		}
-		rollbackPath = fullRollbackPath
-	}
-	logging.DebugStep(logger, "network safe apply (cli)", "Selected rollback backup: %s", rollbackPath)
-
-	systemType := SystemTypeUnknown
-	if plan != nil {
-		systemType = plan.SystemType
-	}
-	if err := applyNetworkWithRollbackCLI(ctx, reader, logger, rollbackPath, networkRollbackPath, stageRoot, archivePath, defaultNetworkRollbackTimeout, systemType); err != nil {
-		return err
-	}
-	return nil
-}
-
-func applyNetworkWithRollbackCLI(ctx context.Context, reader *bufio.Reader, logger *logging.Logger, rollbackBackupPath, networkRollbackPath, stageRoot, archivePath string, timeout time.Duration, systemType SystemType) (err error) {
-	done := logging.DebugStart(
-		logger,
-		"network safe apply (cli)",
-		"rollbackBackup=%s networkRollback=%s timeout=%s systemType=%s stage=%s",
-		strings.TrimSpace(rollbackBackupPath),
-		strings.TrimSpace(networkRollbackPath),
-		timeout,
-		systemType,
-		strings.TrimSpace(stageRoot),
-	)
-	defer func() { done(err) }()
-
-	logging.DebugStep(logger, "network safe apply (cli)", "Create diagnostics directory")
-	diagnosticsDir, err := createNetworkDiagnosticsDir()
-	if err != nil {
-		logger.Warning("Network diagnostics disabled: %v", err)
-		diagnosticsDir = ""
-	} else {
-		logger.Info("Network diagnostics directory: %s", diagnosticsDir)
-	}
-
-	logging.DebugStep(logger, "network safe apply (cli)", "Detect management interface (SSH/default route)")
-	iface, source := detectManagementInterface(ctx, logger)
-	if iface != "" {
-		logger.Info("Detected management interface: %s (%s)", iface, source)
-	}
-
-	if diagnosticsDir != "" {
-		logging.DebugStep(logger, "network safe apply (cli)", "Capture network snapshot (before)")
-		if snap, err := writeNetworkSnapshot(ctx, logger, diagnosticsDir, "before", 3*time.Second); err != nil {
-			logger.Debug("Network snapshot before apply failed: %v", err)
-		} else {
-			logger.Debug("Network snapshot (before): %s", snap)
-		}
-
-		logging.DebugStep(logger, "network safe apply (cli)", "Run baseline health checks (before)")
-		healthBefore := runNetworkHealthChecks(ctx, networkHealthOptions{
-			SystemType:         systemType,
-			Logger:             logger,
-			CommandTimeout:     3 * time.Second,
-			EnableGatewayPing:  false,
-			ForceSSHRouteCheck: false,
-			EnableDNSResolve:   false,
-		})
-		if path, err := writeNetworkHealthReportFileNamed(diagnosticsDir, "health_before.txt", healthBefore); err != nil {
-			logger.Debug("Failed to write network health (before) report: %v", err)
-		} else {
-			logger.Debug("Network health (before) report: %s", path)
-		}
-	}
-
-	if strings.TrimSpace(stageRoot) != "" {
-		logging.DebugStep(logger, "network safe apply (cli)", "Apply staged network files to system paths (before NIC repair)")
-		applied, err := applyNetworkFilesFromStage(logger, stageRoot)
-		if err != nil {
-			return err
-		}
-		if len(applied) > 0 {
-			logging.DebugStep(logger, "network safe apply (cli)", "Staged network files written: %d", len(applied))
-		}
-	}
-
-	logging.DebugStep(logger, "network safe apply (cli)", "NIC name repair (optional)")
-	_ = maybeRepairNICNamesCLI(ctx, reader, logger, archivePath)
-
-	if strings.TrimSpace(iface) != "" {
-		if cur, err := currentNetworkEndpoint(ctx, iface, 2*time.Second); err == nil {
-			if tgt, err := targetNetworkEndpointFromConfig(logger, iface); err == nil {
-				logger.Info("Network plan: %s -> %s", cur.summary(), tgt.summary())
-			}
-		}
-	}
-
-	if diagnosticsDir != "" {
-		logging.DebugStep(logger, "network safe apply (cli)", "Write network plan (current -> target)")
-		if planText, err := buildNetworkPlanReport(ctx, logger, iface, source, 2*time.Second); err != nil {
-			logger.Debug("Network plan build failed: %v", err)
-		} else if strings.TrimSpace(planText) != "" {
-			if path, err := writeNetworkTextReportFile(diagnosticsDir, "plan.txt", planText+"\n"); err != nil {
-				logger.Debug("Network plan write failed: %v", err)
-			} else {
-				logger.Debug("Network plan: %s", path)
-			}
-		}
-
-		logging.DebugStep(logger, "network safe apply (cli)", "Run ifquery diagnostic (pre-apply)")
-		ifqueryPre := runNetworkIfqueryDiagnostic(ctx, 5*time.Second, logger)
-		if !ifqueryPre.Skipped {
-			if path, err := writeNetworkIfqueryDiagnosticReportFile(diagnosticsDir, "ifquery_pre_apply.txt", ifqueryPre); err != nil {
-				logger.Debug("Failed to write ifquery (pre-apply) report: %v", err)
-			} else {
-				logger.Debug("ifquery (pre-apply) report: %s", path)
-			}
-		}
-	}
-
-	logging.DebugStep(logger, "network safe apply (cli)", "Network preflight validation (ifupdown/ifupdown2)")
-	preflight := runNetworkPreflightValidation(ctx, 5*time.Second, logger)
-	if diagnosticsDir != "" {
-		if path, err := writeNetworkPreflightReportFile(diagnosticsDir, preflight); err != nil {
-			logger.Debug("Failed to write network preflight report: %v", err)
-		} else {
-			logger.Debug("Network preflight report: %s", path)
-		}
-	}
-	if !preflight.Ok() {
-		logger.Warning("%s", preflight.Summary())
-		if diagnosticsDir != "" {
-			logger.Info("Network diagnostics saved under: %s", diagnosticsDir)
-		}
-		if strings.TrimSpace(stageRoot) != "" && strings.TrimSpace(networkRollbackPath) != "" {
-			logging.DebugStep(logger, "network safe apply (cli)", "Preflight failed in staged mode: rolling back network files automatically")
-			rollbackLog, rbErr := rollbackNetworkFilesNow(ctx, logger, networkRollbackPath, diagnosticsDir)
-			if strings.TrimSpace(rollbackLog) != "" {
-				logger.Info("Network rollback log: %s", rollbackLog)
-			}
-			if rbErr != nil {
-				logger.Error("Network apply aborted: preflight validation failed (%s) and rollback failed: %v", preflight.CommandLine(), rbErr)
-				return fmt.Errorf("network preflight validation failed; rollback attempt failed: %w", rbErr)
-			}
-			if diagnosticsDir != "" {
-				logging.DebugStep(logger, "network safe apply (cli)", "Capture network snapshot (after rollback)")
-				if snap, err := writeNetworkSnapshot(ctx, logger, diagnosticsDir, "after_rollback", 3*time.Second); err != nil {
-					logger.Debug("Network snapshot after rollback failed: %v", err)
-				} else {
-					logger.Debug("Network snapshot (after rollback): %s", snap)
-				}
-				logging.DebugStep(logger, "network safe apply (cli)", "Run ifquery diagnostic (after rollback)")
-				ifqueryAfterRollback := runNetworkIfqueryDiagnostic(ctx, 5*time.Second, logger)
-				if !ifqueryAfterRollback.Skipped {
-					if path, err := writeNetworkIfqueryDiagnosticReportFile(diagnosticsDir, "ifquery_after_rollback.txt", ifqueryAfterRollback); err != nil {
-						logger.Debug("Failed to write ifquery (after rollback) report: %v", err)
-					} else {
-						logger.Debug("ifquery (after rollback) report: %s", path)
-					}
-				}
-			}
-			logger.Warning(
-				"Network apply aborted: preflight validation failed (%s). Rolled back /etc/network/*, /etc/hosts, /etc/hostname, /etc/resolv.conf to the pre-restore state (rollback=%s).",
-				preflight.CommandLine(),
-				strings.TrimSpace(networkRollbackPath),
-			)
-			return fmt.Errorf("network preflight validation failed; network files rolled back")
-		}
-		if !preflight.Skipped && preflight.ExitError != nil && strings.TrimSpace(networkRollbackPath) != "" {
-			fmt.Println()
-			fmt.Println("WARNING: Network preflight failed. The restored network configuration may break connectivity on reboot.")
-			rollbackNow, perr := promptYesNoWithDefault(
-				ctx,
-				reader,
-				"Roll back restored network config files to the pre-restore configuration now? (Y/n): ",
-				true,
-			)
-			if perr != nil {
-				return perr
-			}
-			logging.DebugStep(logger, "network safe apply (cli)", "User choice: rollbackNow=%v", rollbackNow)
-			if rollbackNow {
-				logging.DebugStep(logger, "network safe apply (cli)", "Rollback network files now (backup=%s)", strings.TrimSpace(networkRollbackPath))
-				rollbackLog, rbErr := rollbackNetworkFilesNow(ctx, logger, networkRollbackPath, diagnosticsDir)
-				if strings.TrimSpace(rollbackLog) != "" {
-					logger.Info("Network rollback log: %s", rollbackLog)
-				}
-				if rbErr != nil {
-					logger.Warning("Network rollback failed: %v", rbErr)
-					return fmt.Errorf("network preflight validation failed; rollback attempt failed: %w", rbErr)
-				}
-				logger.Warning("Network files rolled back to pre-restore configuration due to preflight failure")
-				return fmt.Errorf("network preflight validation failed; network files rolled back")
-			}
-		}
-		return fmt.Errorf("network preflight validation failed; aborting live network apply")
-	}
-
-	logging.DebugStep(logger, "network safe apply (cli)", "Arm rollback timer BEFORE applying changes")
-	handle, err := armNetworkRollback(ctx, logger, rollbackBackupPath, timeout, diagnosticsDir)
-	if err != nil {
-		return err
-	}
-
-	logging.DebugStep(logger, "network safe apply (cli)", "Apply network configuration now")
-	if err := applyNetworkConfig(ctx, logger); err != nil {
-		logger.Warning("Network apply failed: %v", err)
-		return err
-	}
-
-	if diagnosticsDir != "" {
-		logging.DebugStep(logger, "network safe apply (cli)", "Capture network snapshot (after)")
-		if snap, err := writeNetworkSnapshot(ctx, logger, diagnosticsDir, "after", 3*time.Second); err != nil {
-			logger.Debug("Network snapshot after apply failed: %v", err)
-		} else {
-			logger.Debug("Network snapshot (after): %s", snap)
-		}
-
-		logging.DebugStep(logger, "network safe apply (cli)", "Run ifquery diagnostic (post-apply)")
-		ifqueryPost := runNetworkIfqueryDiagnostic(ctx, 5*time.Second, logger)
-		if !ifqueryPost.Skipped {
-			if path, err := writeNetworkIfqueryDiagnosticReportFile(diagnosticsDir, "ifquery_post_apply.txt", ifqueryPost); err != nil {
-				logger.Debug("Failed to write ifquery (post-apply) report: %v", err)
-			} else {
-				logger.Debug("ifquery (post-apply) report: %s", path)
-			}
-		}
-	}
-
-	logging.DebugStep(logger, "network safe apply (cli)", "Run post-apply health checks")
-	health := runNetworkHealthChecks(ctx, networkHealthOptions{
-		SystemType:         systemType,
-		Logger:             logger,
-		CommandTimeout:     3 * time.Second,
-		EnableGatewayPing:  true,
-		ForceSSHRouteCheck: false,
-		EnableDNSResolve:   true,
-		LocalPortChecks:    defaultNetworkPortChecks(systemType),
-	})
-	logNetworkHealthReport(logger, health)
-	fmt.Println(health.Details())
-	if diagnosticsDir != "" {
-		if path, err := writeNetworkHealthReportFile(diagnosticsDir, health); err != nil {
-			logger.Debug("Failed to write network health report: %v", err)
-		} else {
-			logger.Debug("Network health report: %s", path)
-		}
-		fmt.Printf("Network diagnostics saved under: %s\n", diagnosticsDir)
-	}
-	if health.Severity == networkHealthCritical {
-		fmt.Println("CRITICAL: Connectivity checks failed. Recommended action: do NOT commit and let rollback run.")
-	}
-
-	remaining := handle.remaining(time.Now())
-	if remaining <= 0 {
-		logger.Warning("Rollback window already expired; leaving rollback armed")
-		return nil
-	}
-
-	logging.DebugStep(logger, "network safe apply (cli)", "Wait for COMMIT (rollback in %ds)", int(remaining.Seconds()))
-	committed, err := promptNetworkCommitWithCountdown(ctx, reader, logger, remaining)
-	if err != nil {
-		logger.Warning("Commit input lost (%v); rollback remains ARMED and will proceed automatically.", err)
-		return buildNetworkApplyNotCommittedError(ctx, logger, iface, handle)
-	}
-	logging.DebugStep(logger, "network safe apply (cli)", "User commit result: committed=%v", committed)
-	if committed {
-		if rollbackAlreadyRunning(ctx, logger, handle) {
-			logger.Warning("Commit received too late: rollback already running. Network configuration NOT committed.")
-			return buildNetworkApplyNotCommittedError(ctx, logger, iface, handle)
-		}
-		disarmNetworkRollback(ctx, logger, handle)
-		logger.Info("Network configuration committed successfully.")
-		return nil
-	}
-
-	// Not committed: keep rollback ARMED. Do not disarm.
-	// The rollback script will run via systemd-run/nohup when the timer expires.
-	return buildNetworkApplyNotCommittedError(ctx, logger, iface, handle)
-}
-
 // extractIPFromSnapshot reads the IP address for a given interface from a network snapshot report file.
 // It searches the output section that follows the "$ ip -br addr" command written by writeNetworkSnapshot.
 func extractIPFromSnapshot(path, iface string) string {
diff --git a/internal/orchestrator/network_apply_preflight_rollback_test.go b/internal/orchestrator/network_apply_preflight_rollback_test.go
index 7483531..4926829 100644
--- a/internal/orchestrator/network_apply_preflight_rollback_test.go
+++ b/internal/orchestrator/network_apply_preflight_rollback_test.go
@@ -1,7 +1,6 @@
 package orchestrator
 
 import (
-	"bufio"
 	"context"
 	"fmt"
 	"os"
@@ -11,7 +10,7 @@ import (
 	"time"
 )
 
-func TestApplyNetworkWithRollbackCLI_RollsBackFilesOnPreflightFailure(t *testing.T) {
+func TestApplyNetworkWithRollbackWithUI_RollsBackFilesOnPreflightFailure(t *testing.T) {
 	origFS := restoreFS
 	origCmd := restoreCmd
 	origTime := restoreTime
@@ -50,13 +49,13 @@ func TestApplyNetworkWithRollbackCLI_RollsBackFilesOnPreflightFailure(t *testing
 	}
 	restoreCmd = fake
 
-	reader := bufio.NewReader(strings.NewReader("\n"))
 	logger := newTestLogger()
 	rollbackBackup := "/tmp/proxsave/network_rollback_backup_20260118_134651.tar.gz"
 
-	err := applyNetworkWithRollbackCLI(
+	ui := &fakeRestoreWorkflowUI{confirmAction: true}
+	err := applyNetworkWithRollbackWithUI(
 		context.Background(),
-		reader,
+		ui,
 		logger,
 		rollbackBackup,
 		rollbackBackup,
diff --git a/internal/orchestrator/orchestrator.go b/internal/orchestrator/orchestrator.go
index 5b7d15b..d252bed 100644
--- a/internal/orchestrator/orchestrator.go
+++ b/internal/orchestrator/orchestrator.go
@@ -63,6 +63,7 @@ type BackupStats struct {
 	EndTime                   time.Time
 	FilesCollected            int
 	FilesFailed               int
+	FilesNotFound             int
 	DirsCreated               int
 	BytesCollected            int64
 	ArchiveSize               int64
@@ -654,10 +655,11 @@ func (o *Orchestrator) RunGoBackup(ctx context.Context, pType types.ProxmoxType,
 	collStats := collector.GetStats()
 	stats.FilesCollected = int(collStats.FilesProcessed)
 	stats.FilesFailed = int(collStats.FilesFailed)
+	stats.FilesNotFound = int(collStats.FilesNotFound)
 	stats.DirsCreated = int(collStats.DirsCreated)
 	stats.BytesCollected = collStats.BytesCollected
 	stats.FilesIncluded = int(collStats.FilesProcessed)
-	stats.FilesMissing = int(collStats.FilesFailed)
+	stats.FilesMissing = int(collStats.FilesNotFound)
 	stats.UncompressedSize = collStats.BytesCollected
 	if pType == types.ProxmoxVE {
 		if collector.IsClusteredPVE() {
@@ -671,6 +673,11 @@ func (o *Orchestrator) RunGoBackup(ctx context.Context, pType types.ProxmoxType,
 		o.logger.Debug("Failed to write backup metadata: %v", err)
 	}
 
+	// Write backup manifest with file status details
+	if err := collector.WriteManifest(hostname); err != nil {
+		o.logger.Debug("Failed to write backup manifest: %v", err)
+	}
+
 	o.logger.Info("Collection completed: %d files (%s), %d failed, %d dirs created",
 		collStats.FilesProcessed,
 		backup.FormatBytes(collStats.BytesCollected),
diff --git a/internal/orchestrator/restore.go b/internal/orchestrator/restore.go
index d50d267..e0f6120 100644
--- a/internal/orchestrator/restore.go
+++ b/internal/orchestrator/restore.go
@@ -64,545 +64,15 @@ func RunRestoreWorkflow(ctx context.Context, cfg *config.Config, logger *logging
 	if cfg == nil {
 		return fmt.Errorf("configuration not available")
 	}
-	done := logging.DebugStart(logger, "restore workflow (cli)", "version=%s", version)
-	defer func() { done(err) }()
-
-	restoreHadWarnings := false
-	defer func() {
-		if err == nil {
-			return
-		}
-		if errors.Is(err, input.ErrInputAborted) ||
-			errors.Is(err, ErrDecryptAborted) ||
-			errors.Is(err, ErrAgeRecipientSetupAborted) ||
-			errors.Is(err, context.Canceled) ||
-			(ctx != nil && ctx.Err() != nil) {
-			err = ErrRestoreAborted
-		}
-	}()
-
-	reader := bufio.NewReader(os.Stdin)
-	candidate, prepared, err := prepareDecryptedBackupFunc(ctx, reader, cfg, logger, version, false)
-	if err != nil {
-		return err
-	}
-	defer prepared.Cleanup()
-
-	destRoot := "/"
-	logger.Info("Restore target: system root (/) — files will be written back to their original paths")
-
-	// Detect system type
-	systemType := restoreSystem.DetectCurrentSystem()
-	logger.Info("Detected system type: %s", GetSystemTypeString(systemType))
-
-	// Validate compatibility
-	if err := ValidateCompatibility(candidate.Manifest); err != nil {
-		logger.Warning("Compatibility check: %v", err)
-		fmt.Println()
-		fmt.Printf("⚠ %v\n", err)
-		fmt.Println()
-		fmt.Print("Do you want to continue anyway? This may cause system instability. (yes/no): ")
-
-		response, err := input.ReadLineWithContext(ctx, reader)
-		if err != nil {
-			return err
-		}
-		if strings.TrimSpace(strings.ToLower(response)) != "yes" {
-			return fmt.Errorf("restore aborted due to incompatibility")
-		}
-	}
-
-	// Analyze available categories in the backup
-	logger.Info("Analyzing backup contents...")
-	availableCategories, err := AnalyzeBackupCategories(prepared.ArchivePath, logger)
-	if err != nil {
-		logger.Warning("Could not analyze categories: %v", err)
-		logger.Info("Falling back to full restore mode")
-		return runFullRestore(ctx, reader, candidate, prepared, destRoot, logger, cfg.DryRun)
-	}
-
-	// Show restore mode selection menu
-	mode, err := restorePrompter.SelectRestoreMode(ctx, logger, systemType)
-	if err != nil {
-		if errors.Is(err, ErrRestoreAborted) {
-			return ErrRestoreAborted
-		}
-		return err
-	}
-
-	// Determine selected categories based on mode
-	var selectedCategories []Category
-	if mode == RestoreModeCustom {
-		// Interactive category selection
-		selectedCategories, err = restorePrompter.SelectCategories(ctx, logger, availableCategories, systemType)
-		if err != nil {
-			if errors.Is(err, ErrRestoreAborted) {
-				return ErrRestoreAborted
-			}
-			return err
-		}
-	} else {
-		// Pre-defined mode (Full, Storage, Base)
-		selectedCategories = GetCategoriesForMode(mode, systemType, availableCategories)
-	}
-
-	plan := PlanRestore(candidate.Manifest, selectedCategories, systemType, mode)
-
-	// Cluster safety prompt: if backup proviene da cluster e vogliamo ripristinare pve_cluster, chiedi come procedere.
-	clusterBackup := strings.EqualFold(strings.TrimSpace(candidate.Manifest.ClusterMode), "cluster")
-	if plan.NeedsClusterRestore && clusterBackup {
-		logger.Info("Backup marked as cluster node; enabling guarded restore options for pve_cluster")
-		choice, promptErr := promptClusterRestoreMode(ctx, reader)
-		if promptErr != nil {
-			return promptErr
-		}
-		if choice == 0 {
-			return ErrRestoreAborted
-		}
-		if choice == 1 {
-			plan.ApplyClusterSafeMode(true)
-			logger.Info("Selected SAFE cluster restore: /var/lib/pve-cluster will be exported only, not written to system")
-		} else {
-			plan.ApplyClusterSafeMode(false)
-			logger.Warning("Selected RECOVERY cluster restore: full cluster database will be restored; ensure other nodes are isolated")
-		}
-	}
-
-	// Staging is designed to protect live systems. In test runs (fake filesystem) or non-root targets,
-	// extract staged categories directly to the destination to keep restore semantics predictable.
-	if destRoot != "/" || !isRealRestoreFS(restoreFS) {
-		if len(plan.StagedCategories) > 0 {
-			logging.DebugStep(logger, "restore", "Staging disabled (destRoot=%s realFS=%v): extracting %d staged category(ies) directly", destRoot, isRealRestoreFS(restoreFS), len(plan.StagedCategories))
-			plan.NormalCategories = append(plan.NormalCategories, plan.StagedCategories...)
-			plan.StagedCategories = nil
-		}
-	}
-
-	// Create restore configuration
-	restoreConfig := &SelectiveRestoreConfig{
-		Mode:       mode,
-		SystemType: systemType,
-		Metadata:   candidate.Manifest,
-	}
-	restoreConfig.SelectedCategories = append(restoreConfig.SelectedCategories, plan.NormalCategories...)
-	restoreConfig.SelectedCategories = append(restoreConfig.SelectedCategories, plan.StagedCategories...)
-	restoreConfig.SelectedCategories = append(restoreConfig.SelectedCategories, plan.ExportCategories...)
-
-	// Show detailed restore plan
-	ShowRestorePlan(logger, restoreConfig)
-
-	// Confirm operation
-	confirmed, err := restorePrompter.ConfirmRestore(ctx, logger)
-	if err != nil {
-		if errors.Is(err, ErrRestoreAborted) {
-			return ErrRestoreAborted
-		}
-		return err
-	}
-	if !confirmed {
-		logger.Info("Restore operation cancelled by user")
-		return ErrRestoreAborted
-	}
-
-	// Create safety backup of current configuration (only for categories that will write to system paths)
-	var safetyBackup *SafetyBackupResult
-	var networkRollbackBackup *SafetyBackupResult
-	systemWriteCategories := append([]Category{}, plan.NormalCategories...)
-	systemWriteCategories = append(systemWriteCategories, plan.StagedCategories...)
-	if len(systemWriteCategories) > 0 {
-		logger.Info("")
-		safetyBackup, err = CreateSafetyBackup(logger, systemWriteCategories, destRoot)
-		if err != nil {
-			logger.Warning("Failed to create safety backup: %v", err)
-			fmt.Println()
-			fmt.Print("Continue without safety backup? (yes/no): ")
-			response, err := input.ReadLineWithContext(ctx, reader)
-			if err != nil {
-				return err
-			}
-			if strings.TrimSpace(strings.ToLower(response)) != "yes" {
-				return fmt.Errorf("restore aborted: safety backup failed")
-			}
-		} else {
-			logger.Info("Safety backup location: %s", safetyBackup.BackupPath)
-			logger.Info("You can restore from this backup if needed using: tar -xzf %s -C /", safetyBackup.BackupPath)
-		}
-	}
-
-	if plan.HasCategoryID("network") {
-		logger.Info("")
-		logging.DebugStep(logger, "restore", "Create network-only rollback backup for transactional network apply")
-		networkRollbackBackup, err = CreateNetworkRollbackBackup(logger, systemWriteCategories, destRoot)
-		if err != nil {
-			logger.Warning("Failed to create network rollback backup: %v", err)
-		} else if networkRollbackBackup != nil && strings.TrimSpace(networkRollbackBackup.BackupPath) != "" {
-			logger.Info("Network rollback backup location: %s", networkRollbackBackup.BackupPath)
-			logger.Info("This backup is used for the %ds network rollback timer and only includes network paths.", int(defaultNetworkRollbackTimeout.Seconds()))
-		}
-	}
-
-	// If we are restoring cluster database, stop PVE services and unmount /etc/pve before writing
-	needsClusterRestore := plan.NeedsClusterRestore
-	clusterServicesStopped := false
-	pbsServicesStopped := false
-	needsPBSServices := plan.NeedsPBSServices
-	if needsClusterRestore {
-		logger.Info("")
-		logger.Info("Preparing system for cluster database restore: stopping PVE services and unmounting /etc/pve")
-		if err := stopPVEClusterServices(ctx, logger); err != nil {
-			return err
-		}
-		clusterServicesStopped = true
-		defer func() {
-			restartCtx, cancel := context.WithTimeout(context.Background(), 2*serviceStartTimeout+2*serviceVerifyTimeout+10*time.Second)
-			defer cancel()
-			if err := startPVEClusterServices(restartCtx, logger); err != nil {
-				logger.Warning("Failed to restart PVE services after restore: %v", err)
-			}
-		}()
 
-		if err := unmountEtcPVE(ctx, logger); err != nil {
-			logger.Warning("Could not unmount /etc/pve: %v", err)
-		}
-	}
-
-	// For PBS restores, stop PBS services before applying configuration/datastore changes if relevant categories are selected
-	if needsPBSServices {
-		logger.Info("")
-		logger.Info("Preparing PBS system for restore: stopping proxmox-backup services")
-		if err := stopPBSServices(ctx, logger); err != nil {
-			logger.Warning("Unable to stop PBS services automatically: %v", err)
-			fmt.Println()
-			fmt.Println("⚠ PBS services are still running. Continuing restore may leave proxmox-backup processes active.")
-			logger.Info("Continuing restore without stopping PBS services")
-		} else {
-			pbsServicesStopped = true
-			defer func() {
-				restartCtx, cancel := context.WithTimeout(context.Background(), 2*serviceStartTimeout+2*serviceVerifyTimeout+10*time.Second)
-				defer cancel()
-				if err := startPBSServices(restartCtx, logger); err != nil {
-					logger.Warning("Failed to restart PBS services after restore: %v", err)
-				}
-			}()
-		}
+	if logger == nil {
+		logger = logging.GetDefaultLogger()
 	}
+	done := logging.DebugStart(logger, "restore workflow (cli)", "version=%s", version)
+	defer func() { done(err) }()
 
-	// Perform selective extraction for normal categories
-	var detailedLogPath string
-
-	// Intercept filesystem category to handle it via Smart Merge
-	needsFilesystemRestore := false
-	if plan.HasCategoryID("filesystem") {
-		needsFilesystemRestore = true
-		// Filter it out from normal categories to prevent blind overwrite
-		var filtered []Category
-		for _, cat := range plan.NormalCategories {
-			if cat.ID != "filesystem" {
-				filtered = append(filtered, cat)
-			}
-		}
-		plan.NormalCategories = filtered
-		logging.DebugStep(logger, "restore", "Filesystem category intercepted: enabling Smart Merge workflow (skipping generic extraction)")
-	}
-
-	if len(plan.NormalCategories) > 0 {
-		logger.Info("")
-		categoriesForExtraction := plan.NormalCategories
-		if needsClusterRestore {
-			logging.DebugStep(logger, "restore", "Cluster RECOVERY shadow-guard: sanitize categories to avoid /etc/pve shadow writes")
-			sanitized, removed := sanitizeCategoriesForClusterRecovery(categoriesForExtraction)
-			removedPaths := 0
-			for _, paths := range removed {
-				removedPaths += len(paths)
-			}
-			logging.DebugStep(
-				logger,
-				"restore",
-				"Cluster RECOVERY shadow-guard: categories_before=%d categories_after=%d removed_categories=%d removed_paths=%d",
-				len(categoriesForExtraction),
-				len(sanitized),
-				len(removed),
-				removedPaths,
-			)
-			if len(removed) > 0 {
-				logger.Warning("Cluster RECOVERY restore: skipping direct restore of /etc/pve paths to prevent shadowing while pmxcfs is stopped/unmounted")
-				for _, cat := range categoriesForExtraction {
-					if paths, ok := removed[cat.ID]; ok && len(paths) > 0 {
-						logger.Warning("  - %s (%s): %s", cat.Name, cat.ID, strings.Join(paths, ", "))
-					}
-				}
-				logger.Info("These paths are expected to be restored from config.db and become visible after /etc/pve is remounted.")
-			} else {
-				logging.DebugStep(logger, "restore", "Cluster RECOVERY shadow-guard: no /etc/pve paths detected in selected categories")
-			}
-			categoriesForExtraction = sanitized
-			var extractionIDs []string
-			for _, cat := range categoriesForExtraction {
-				if id := strings.TrimSpace(cat.ID); id != "" {
-					extractionIDs = append(extractionIDs, id)
-				}
-			}
-			if len(extractionIDs) > 0 {
-				logging.DebugStep(logger, "restore", "Cluster RECOVERY shadow-guard: extraction_categories=%s", strings.Join(extractionIDs, ","))
-			} else {
-				logging.DebugStep(logger, "restore", "Cluster RECOVERY shadow-guard: extraction_categories=<none>")
-			}
-		}
-
-		if len(categoriesForExtraction) == 0 {
-			logging.DebugStep(logger, "restore", "Skip system-path extraction: no categories remain after shadow-guard")
-			logger.Info("No system-path categories remain after cluster shadow-guard; skipping system-path extraction.")
-		} else {
-			detailedLogPath, err = extractSelectiveArchive(ctx, prepared.ArchivePath, destRoot, categoriesForExtraction, mode, logger)
-			if err != nil {
-				logger.Error("Restore failed: %v", err)
-				if safetyBackup != nil {
-					logger.Info("You can rollback using the safety backup at: %s", safetyBackup.BackupPath)
-				}
-				return err
-			}
-		}
-	} else {
-		logger.Info("")
-		logger.Info("No system-path categories selected for restore (only export categories will be processed).")
-	}
-
-	// Handle export-only categories by extracting them to a separate directory
-	exportLogPath := ""
-	exportRoot := ""
-	if len(plan.ExportCategories) > 0 {
-		exportRoot = exportDestRoot(cfg.BaseDir)
-		logger.Info("")
-		logger.Info("Exporting %d export-only category(ies) to: %s", len(plan.ExportCategories), exportRoot)
-		if err := restoreFS.MkdirAll(exportRoot, 0o755); err != nil {
-			return fmt.Errorf("failed to create export directory %s: %w", exportRoot, err)
-		}
-
-		if exportLog, err := extractSelectiveArchive(ctx, prepared.ArchivePath, exportRoot, plan.ExportCategories, RestoreModeCustom, logger); err != nil {
-			if errors.Is(err, ErrRestoreAborted) || input.IsAborted(err) {
-				return err
-			}
-			logger.Warning("Export completed with errors: %v", err)
-		} else {
-			exportLogPath = exportLog
-		}
-	}
-
-	// SAFE cluster mode: offer applying configs via pvesh without touching config.db
-	if plan.ClusterSafeMode {
-		if exportRoot == "" {
-			logger.Warning("Cluster SAFE mode selected but export directory not available; skipping automatic pvesh apply")
-		} else if err := runSafeClusterApply(ctx, reader, exportRoot, logger); err != nil {
-			if errors.Is(err, ErrRestoreAborted) || input.IsAborted(err) {
-				return err
-			}
-			logger.Warning("Cluster SAFE apply completed with errors: %v", err)
-		}
-	}
-
-	// Stage sensitive categories (network, PBS datastore/jobs) to a temporary directory and apply them safely later.
-	stageLogPath := ""
-	stageRoot := ""
-	if len(plan.StagedCategories) > 0 {
-		stageRoot = stageDestRoot()
-		logger.Info("")
-		logger.Info("Staging %d sensitive category(ies) to: %s", len(plan.StagedCategories), stageRoot)
-		if err := restoreFS.MkdirAll(stageRoot, 0o755); err != nil {
-			return fmt.Errorf("failed to create staging directory %s: %w", stageRoot, err)
-		}
-
-		if stageLog, err := extractSelectiveArchive(ctx, prepared.ArchivePath, stageRoot, plan.StagedCategories, RestoreModeCustom, logger); err != nil {
-			if errors.Is(err, ErrRestoreAborted) || input.IsAborted(err) {
-				return err
-			}
-			logger.Warning("Staging completed with errors: %v", err)
-		} else {
-			stageLogPath = stageLog
-		}
-
-		logger.Info("")
-		if err := maybeApplyPBSConfigsFromStage(ctx, logger, plan, stageRoot, cfg.DryRun); err != nil {
-			if errors.Is(err, ErrRestoreAborted) || input.IsAborted(err) {
-				return err
-			}
-			logger.Warning("PBS staged config apply: %v", err)
-		}
-	}
-
-	stageRootForNetworkApply := stageRoot
-	if installed, err := maybeInstallNetworkConfigFromStage(ctx, logger, plan, stageRoot, prepared.ArchivePath, networkRollbackBackup, cfg.DryRun); err != nil {
-		if errors.Is(err, ErrRestoreAborted) || input.IsAborted(err) {
-			return err
-		}
-		logger.Warning("Network staged install: %v", err)
-	} else if installed {
-		stageRootForNetworkApply = ""
-		logging.DebugStep(logger, "restore", "Network staged install completed: configuration written to /etc (no reload); live apply will use system paths")
-	}
-
-	// Recreate directory structures from configuration files if relevant categories were restored
-	logger.Info("")
-	categoriesForDirRecreate := append([]Category{}, plan.NormalCategories...)
-	categoriesForDirRecreate = append(categoriesForDirRecreate, plan.StagedCategories...)
-	if shouldRecreateDirectories(systemType, categoriesForDirRecreate) {
-		if err := RecreateDirectoriesFromConfig(systemType, logger); err != nil {
-			logger.Warning("Failed to recreate directory structures: %v", err)
-			logger.Warning("You may need to manually create storage/datastore directories")
-		}
-	} else {
-		logger.Debug("Skipping datastore/storage directory recreation (category not selected)")
-	}
-
-	// Smart Filesystem Merge
-	if needsFilesystemRestore {
-		logger.Info("")
-		// Extract fstab to a temporary location
-		fsTempDir, err := restoreFS.MkdirTemp("", "proxsave-fstab-")
-		if err != nil {
-			logger.Warning("Failed to create temp dir for fstab merge: %v", err)
-		} else {
-			defer restoreFS.RemoveAll(fsTempDir)
-			// Construct a temporary category for extraction
-			fsCat := GetCategoryByID("filesystem", availableCategories)
-			if fsCat == nil {
-				logger.Warning("Filesystem category not available in analyzed backup contents; skipping fstab merge")
-			} else {
-				fsCategory := []Category{*fsCat}
-				if _, err := extractSelectiveArchive(ctx, prepared.ArchivePath, fsTempDir, fsCategory, RestoreModeCustom, logger); err != nil {
-					if errors.Is(err, ErrRestoreAborted) || input.IsAborted(err) {
-						return err
-					}
-					logger.Warning("Failed to extract filesystem config for merge: %v", err)
-				} else {
-					// Perform Smart Merge
-					currentFstab := filepath.Join(destRoot, "etc", "fstab")
-					backupFstab := filepath.Join(fsTempDir, "etc", "fstab")
-					if err := SmartMergeFstab(ctx, logger, reader, currentFstab, backupFstab, cfg.DryRun); err != nil {
-						if errors.Is(err, ErrRestoreAborted) || input.IsAborted(err) {
-							logger.Info("Restore aborted by user during Smart Filesystem Configuration Merge.")
-							return err
-						}
-						restoreHadWarnings = true
-						logger.Warning("Smart Fstab Merge failed: %v", err)
-					}
-				}
-			}
-		}
-	}
-
-	logger.Info("")
-	if plan.HasCategoryID("network") {
-		logger.Info("")
-		if err := maybeRepairResolvConfAfterRestore(ctx, logger, prepared.ArchivePath, cfg.DryRun); err != nil {
-			if errors.Is(err, ErrRestoreAborted) || input.IsAborted(err) {
-				return err
-			}
-			restoreHadWarnings = true
-			logger.Warning("DNS resolver repair: %v", err)
-		}
-	}
-
-	logger.Info("")
-	if err := maybeApplyNetworkConfigCLI(ctx, reader, logger, plan, safetyBackup, networkRollbackBackup, stageRootForNetworkApply, prepared.ArchivePath, cfg.DryRun); err != nil {
-		if errors.Is(err, ErrRestoreAborted) || input.IsAborted(err) {
-			logger.Info("Restore aborted by user during network apply prompt.")
-			return err
-		}
-		restoreHadWarnings = true
-		if errors.Is(err, ErrNetworkApplyNotCommitted) {
-			var notCommitted *NetworkApplyNotCommittedError
-			observedIP := "unknown"
-			rollbackLog := ""
-			rollbackArmed := false
-			if errors.As(err, &notCommitted) && notCommitted != nil {
-				if strings.TrimSpace(notCommitted.RestoredIP) != "" {
-					observedIP = strings.TrimSpace(notCommitted.RestoredIP)
-				}
-				rollbackLog = strings.TrimSpace(notCommitted.RollbackLog)
-				rollbackArmed = notCommitted.RollbackArmed
-				// Save abort info for footer display
-				lastRestoreAbortInfo = &RestoreAbortInfo{
-					NetworkRollbackArmed:  rollbackArmed,
-					NetworkRollbackLog:    rollbackLog,
-					NetworkRollbackMarker: strings.TrimSpace(notCommitted.RollbackMarker),
-					OriginalIP:            notCommitted.OriginalIP,
-					CurrentIP:             observedIP,
-					RollbackDeadline:      notCommitted.RollbackDeadline,
-				}
-			}
-			if rollbackArmed {
-				logger.Warning("Network apply not committed; rollback is ARMED and will run automatically. Current IP: %s", observedIP)
-			} else {
-				logger.Warning("Network apply not committed; rollback has executed (or marker cleared). Current IP: %s", observedIP)
-			}
-			if rollbackLog != "" {
-				logger.Info("Rollback log: %s", rollbackLog)
-			}
-		} else {
-			logger.Warning("Network apply step skipped or failed: %v", err)
-		}
-	}
-
-	logger.Info("")
-	if restoreHadWarnings {
-		logger.Warning("Restore completed with warnings.")
-	} else {
-		logger.Info("Restore completed successfully.")
-	}
-	logger.Info("Temporary decrypted bundle removed.")
-
-	if detailedLogPath != "" {
-		logger.Info("Detailed restore log: %s", detailedLogPath)
-	}
-	if exportRoot != "" {
-		logger.Info("Export directory: %s", exportRoot)
-	}
-	if exportLogPath != "" {
-		logger.Info("Export detailed log: %s", exportLogPath)
-	}
-	if stageRoot != "" {
-		logger.Info("Staging directory: %s", stageRoot)
-	}
-	if stageLogPath != "" {
-		logger.Info("Staging detailed log: %s", stageLogPath)
-	}
-
-	if safetyBackup != nil {
-		logger.Info("Safety backup preserved at: %s", safetyBackup.BackupPath)
-		logger.Info("Remove it manually if restore was successful: rm %s", safetyBackup.BackupPath)
-	}
-
-	logger.Info("")
-	logger.Info("IMPORTANT: You may need to restart services for changes to take effect.")
-	if systemType == SystemTypePVE {
-		if needsClusterRestore && clusterServicesStopped {
-			logger.Info("  PVE services were stopped/restarted during restore; verify status with: pvecm status")
-		} else {
-			logger.Info("  PVE services: systemctl restart pve-cluster pvedaemon pveproxy")
-		}
-	} else if systemType == SystemTypePBS {
-		if pbsServicesStopped {
-			logger.Info("  PBS services were stopped/restarted during restore; verify status with: systemctl status proxmox-backup proxmox-backup-proxy")
-		} else {
-			logger.Info("  PBS services: systemctl restart proxmox-backup-proxy proxmox-backup")
-		}
-
-		// Check ZFS pool status for PBS systems only when ZFS category was restored
-		if hasCategoryID(plan.NormalCategories, "zfs") {
-			logger.Info("")
-			if err := checkZFSPoolsAfterRestore(logger); err != nil {
-				logger.Warning("ZFS pool check: %v", err)
-			}
-		} else {
-			logger.Debug("Skipping ZFS pool verification (ZFS category not selected)")
-		}
-	}
-
-	logger.Info("")
-	logger.Warning("⚠ SYSTEM REBOOT RECOMMENDED")
-	logger.Info("Reboot the node (or at least restart networking and system services) to ensure all restored configurations take effect cleanly.")
-
-	return nil
+	ui := newCLIWorkflowUI(bufio.NewReader(os.Stdin), logger)
+	return runRestoreWorkflowWithUI(ctx, cfg, logger, version, ui)
 }
 
 // checkZFSPoolsAfterRestore checks if ZFS pools need to be imported after restore
@@ -1315,176 +785,11 @@ func extractPlainArchive(ctx context.Context, archivePath, destRoot string, logg
 // runSafeClusterApply applies selected cluster configs via pvesh without touching config.db.
 // It operates on files extracted to exportRoot (e.g. exportDestRoot).
 func runSafeClusterApply(ctx context.Context, reader *bufio.Reader, exportRoot string, logger *logging.Logger) (err error) {
-	done := logging.DebugStart(logger, "safe cluster apply", "export_root=%s", exportRoot)
-	defer func() { done(err) }()
-
-	if err := ctx.Err(); err != nil {
-		return err
-	}
-
-	pveshPath, lookErr := exec.LookPath("pvesh")
-	if lookErr != nil {
-		logger.Warning("pvesh not found in PATH; skipping SAFE cluster apply")
-		return nil
-	}
-	logging.DebugStep(logger, "safe cluster apply", "pvesh=%s", pveshPath)
-
-	currentNode, _ := os.Hostname()
-	currentNode = shortHost(currentNode)
-	if strings.TrimSpace(currentNode) == "" {
-		currentNode = "localhost"
-	}
-	logging.DebugStep(logger, "safe cluster apply", "current_node=%s", currentNode)
-
-	logger.Info("")
-	logger.Info("SAFE cluster restore: applying configs via pvesh (node=%s)", currentNode)
-
-	sourceNode := currentNode
-	logging.DebugStep(logger, "safe cluster apply", "List exported node directories under %s", filepath.Join(exportRoot, "etc/pve/nodes"))
-	exportNodes, nodesErr := listExportNodeDirs(exportRoot)
-	if nodesErr != nil {
-		logger.Warning("Failed to inspect exported node directories: %v", nodesErr)
-	} else if len(exportNodes) > 0 {
-		logging.DebugStep(logger, "safe cluster apply", "export_nodes=%s", strings.Join(exportNodes, ","))
-	} else {
-		logging.DebugStep(logger, "safe cluster apply", "No exported node directories found")
-	}
-
-	if len(exportNodes) > 0 && !stringSliceContains(exportNodes, sourceNode) {
-		logging.DebugStep(logger, "safe cluster apply", "Node mismatch: current_node=%s export_nodes=%s", currentNode, strings.Join(exportNodes, ","))
-		logger.Warning("SAFE cluster restore: VM/CT configs not found for current node %s in export; available nodes: %s", currentNode, strings.Join(exportNodes, ", "))
-		if len(exportNodes) == 1 {
-			sourceNode = exportNodes[0]
-			logging.DebugStep(logger, "safe cluster apply", "Auto-select source node: %s", sourceNode)
-			logger.Info("SAFE cluster restore: using exported node %s as VM/CT source, applying to current node %s", sourceNode, currentNode)
-		} else {
-			for _, node := range exportNodes {
-				qemuCount, lxcCount := countVMConfigsForNode(exportRoot, node)
-				logging.DebugStep(logger, "safe cluster apply", "Export node candidate: %s (qemu=%d, lxc=%d)", node, qemuCount, lxcCount)
-			}
-			selected, selErr := promptExportNodeSelection(ctx, reader, exportRoot, currentNode, exportNodes)
-			if selErr != nil {
-				return selErr
-			}
-			if strings.TrimSpace(selected) == "" {
-				logging.DebugStep(logger, "safe cluster apply", "User selected: skip VM/CT apply (no source node)")
-				logger.Info("Skipping VM/CT apply (no source node selected)")
-				sourceNode = ""
-			} else {
-				sourceNode = selected
-				logging.DebugStep(logger, "safe cluster apply", "User selected source node: %s", sourceNode)
-				logger.Info("SAFE cluster restore: selected exported node %s as VM/CT source, applying to current node %s", sourceNode, currentNode)
-			}
-		}
-	}
-	logging.DebugStep(logger, "safe cluster apply", "Selected VM/CT source node: %q (current_node=%q)", sourceNode, currentNode)
-
-	var vmEntries []vmEntry
-	if strings.TrimSpace(sourceNode) != "" {
-		logging.DebugStep(logger, "safe cluster apply", "Scan VM/CT configs in export (source_node=%s)", sourceNode)
-		var vmErr error
-		vmEntries, vmErr = scanVMConfigs(exportRoot, sourceNode)
-		if vmErr != nil {
-			logger.Warning("Failed to scan VM configs: %v", vmErr)
-		} else {
-			logging.DebugStep(logger, "safe cluster apply", "VM/CT configs found=%d (source_node=%s)", len(vmEntries), sourceNode)
-			qemuCount := 0
-			lxcCount := 0
-			for _, entry := range vmEntries {
-				switch entry.Kind {
-				case "qemu":
-					qemuCount++
-				case "lxc":
-					lxcCount++
-				}
-			}
-			logging.DebugStep(logger, "safe cluster apply", "VM/CT breakdown: qemu=%d lxc=%d", qemuCount, lxcCount)
-		}
-	}
-	if len(vmEntries) > 0 {
-		fmt.Println()
-		if sourceNode == currentNode {
-			fmt.Printf("Found %d VM/CT configs for node %s\n", len(vmEntries), currentNode)
-		} else {
-			fmt.Printf("Found %d VM/CT configs for exported node %s (will apply to current node %s)\n", len(vmEntries), sourceNode, currentNode)
-		}
-		applyVMs, promptErr := promptYesNo(ctx, reader, "Apply all VM/CT configs via pvesh? ")
-		if promptErr != nil {
-			return promptErr
-		}
-		logging.DebugStep(logger, "safe cluster apply", "User choice: apply_vms=%v (entries=%d)", applyVMs, len(vmEntries))
-		if applyVMs {
-			applied, failed := applyVMConfigs(ctx, vmEntries, logger)
-			logger.Info("VM/CT apply completed: ok=%d failed=%d", applied, failed)
-		} else {
-			logger.Info("Skipping VM/CT apply")
-		}
-	} else {
-		if strings.TrimSpace(sourceNode) == "" {
-			logger.Info("No VM/CT configs applied (no source node selected)")
-		} else {
-			logger.Info("No VM/CT configs found for node %s in export", sourceNode)
-		}
-	}
-
-	// Storage configuration
-	storageCfg := filepath.Join(exportRoot, "etc/pve/storage.cfg")
-	logging.DebugStep(logger, "safe cluster apply", "Check export: storage.cfg (%s)", storageCfg)
-	storageInfo, storageErr := restoreFS.Stat(storageCfg)
-	if storageErr == nil && !storageInfo.IsDir() {
-		logging.DebugStep(logger, "safe cluster apply", "storage.cfg found (size=%d)", storageInfo.Size())
-		fmt.Println()
-		fmt.Printf("Storage configuration found: %s\n", storageCfg)
-		applyStorage, err := promptYesNo(ctx, reader, "Apply storage.cfg via pvesh?")
-		if err != nil {
-			return err
-		}
-		logging.DebugStep(logger, "safe cluster apply", "User choice: apply_storage=%v", applyStorage)
-		if applyStorage {
-			logging.DebugStep(logger, "safe cluster apply", "Apply storage.cfg via pvesh")
-			applied, failed, err := applyStorageCfg(ctx, storageCfg, logger)
-			logging.DebugStep(logger, "safe cluster apply", "Storage apply result: ok=%d failed=%d err=%v", applied, failed, err)
-			if err != nil {
-				logger.Warning("Storage apply encountered errors: %v", err)
-			}
-			logger.Info("Storage apply completed: ok=%d failed=%d", applied, failed)
-		} else {
-			logger.Info("Skipping storage.cfg apply")
-		}
-	} else {
-		logging.DebugStep(logger, "safe cluster apply", "storage.cfg not found (err=%v)", storageErr)
-		logger.Info("No storage.cfg found in export")
+	if logger == nil {
+		logger = logging.GetDefaultLogger()
 	}
-
-	// Datacenter configuration
-	dcCfg := filepath.Join(exportRoot, "etc/pve/datacenter.cfg")
-	logging.DebugStep(logger, "safe cluster apply", "Check export: datacenter.cfg (%s)", dcCfg)
-	dcInfo, dcErr := restoreFS.Stat(dcCfg)
-	if dcErr == nil && !dcInfo.IsDir() {
-		logging.DebugStep(logger, "safe cluster apply", "datacenter.cfg found (size=%d)", dcInfo.Size())
-		fmt.Println()
-		fmt.Printf("Datacenter configuration found: %s\n", dcCfg)
-		applyDC, err := promptYesNo(ctx, reader, "Apply datacenter.cfg via pvesh?")
-		if err != nil {
-			return err
-		}
-		logging.DebugStep(logger, "safe cluster apply", "User choice: apply_datacenter=%v", applyDC)
-		if applyDC {
-			logging.DebugStep(logger, "safe cluster apply", "Apply datacenter.cfg via pvesh")
-			if err := runPvesh(ctx, logger, []string{"set", "/cluster/config", "-conf", dcCfg}); err != nil {
-				logger.Warning("Failed to apply datacenter.cfg: %v", err)
-			} else {
-				logger.Info("datacenter.cfg applied successfully")
-			}
-		} else {
-			logger.Info("Skipping datacenter.cfg apply")
-		}
-	} else {
-		logging.DebugStep(logger, "safe cluster apply", "datacenter.cfg not found (err=%v)", dcErr)
-		logger.Info("No datacenter.cfg found in export")
-	}
-
-	return nil
+	ui := newCLIWorkflowUI(reader, logger)
+	return runSafeClusterApplyWithUI(ctx, ui, exportRoot, logger)
 }
 
 type vmEntry struct {
diff --git a/internal/orchestrator/restore_tui.go b/internal/orchestrator/restore_tui.go
index 898e812..db818ca 100644
--- a/internal/orchestrator/restore_tui.go
+++ b/internal/orchestrator/restore_tui.go
@@ -1,35 +1,25 @@
 package orchestrator
 
 import (
-	"bufio"
 	"context"
 	"errors"
 	"fmt"
-	"os"
-	"path/filepath"
 	"sort"
 	"strings"
-	"sync/atomic"
 	"time"
 
 	"github.com/gdamore/tcell/v2"
 	"github.com/rivo/tview"
 
 	"github.com/tis24dev/proxsave/internal/config"
-	"github.com/tis24dev/proxsave/internal/input"
 	"github.com/tis24dev/proxsave/internal/logging"
 	"github.com/tis24dev/proxsave/internal/tui"
 	"github.com/tis24dev/proxsave/internal/tui/components"
 )
 
-type restoreSelection struct {
-	Candidate *decryptCandidate
-}
-
 const (
 	restoreWizardSubtitle = "Restore Backup Workflow"
 	restoreNavText        = "[yellow]Navigation:[white] TAB/↑↓ to move | ENTER to select | ESC to exit screens | Mouse clicks enabled"
-	restoreErrorModalPage = "restore-error-modal"
 )
 
 var errRestoreBackToMode = errors.New("restore mode back")
@@ -37,803 +27,27 @@ var promptYesNoTUIFunc = promptYesNoTUI
 
 // RunRestoreWorkflowTUI runs the restore workflow using a TUI flow.
 func RunRestoreWorkflowTUI(ctx context.Context, cfg *config.Config, logger *logging.Logger, version, configPath, buildSig string) (err error) {
-	if cfg == nil {
-		return fmt.Errorf("configuration not available")
-	}
-	if logger == nil {
-		logger = logging.GetDefaultLogger()
-	}
-	done := logging.DebugStart(logger, "restore workflow (tui)", "version=%s", version)
-	defer func() { done(err) }()
-	defer func() {
-		if err == nil {
-			return
-		}
-		if errors.Is(err, ErrDecryptAborted) ||
-			errors.Is(err, ErrAgeRecipientSetupAborted) ||
-			errors.Is(err, context.Canceled) ||
-			(ctx != nil && ctx.Err() != nil) {
-			err = ErrRestoreAborted
-		}
-	}()
-	if strings.TrimSpace(buildSig) == "" {
-		buildSig = "n/a"
-	}
-
-	candidate, prepared, err := prepareDecryptedBackupTUI(ctx, cfg, logger, version, configPath, buildSig)
-	if err != nil {
-		return err
-	}
-	defer prepared.Cleanup()
-
-	destRoot := "/"
-	logger.Info("Restore target: system root (/) — files will be written back to their original paths")
-
-	// Detect system type
-	systemType := restoreSystem.DetectCurrentSystem()
-	logger.Info("Detected system type: %s", GetSystemTypeString(systemType))
-
-	// Validate compatibility
-	if err := ValidateCompatibility(candidate.Manifest); err != nil {
-		logger.Warning("Compatibility check: %v", err)
-		proceed, perr := promptCompatibilityTUI(configPath, buildSig, err)
-		if perr != nil {
-			return perr
-		}
-		if !proceed {
-			return fmt.Errorf("restore aborted due to incompatibility")
-		}
-	}
-
-	// Analyze available categories in the backup
-	logger.Info("Analyzing backup contents...")
-	availableCategories, err := AnalyzeBackupCategories(prepared.ArchivePath, logger)
-	if err != nil {
-		logger.Warning("Could not analyze categories: %v", err)
-		logger.Info("Falling back to full restore mode")
-		return runFullRestoreTUI(ctx, candidate, prepared, destRoot, logger, cfg.DryRun, configPath, buildSig)
-	}
-
-	// Restore mode selection (loop to allow going back from category selection)
-	var (
-		mode               RestoreMode
-		selectedCategories []Category
-	)
-
-	for {
-		backupSummary := fmt.Sprintf(
-			"%s (%s)",
-			candidate.DisplayBase,
-			candidate.Manifest.CreatedAt.Format("2006-01-02 15:04:05"),
-		)
-
-		mode, err = selectRestoreModeTUI(systemType, configPath, buildSig, backupSummary)
-		if err != nil {
-			if errors.Is(err, ErrRestoreAborted) {
-				return ErrRestoreAborted
-			}
-			return err
-		}
-
-		if mode != RestoreModeCustom {
-			selectedCategories = GetCategoriesForMode(mode, systemType, availableCategories)
-			break
-		}
-
-		selectedCategories, err = selectCategoriesTUI(availableCategories, systemType, configPath, buildSig)
-		if err != nil {
-			if errors.Is(err, ErrRestoreAborted) {
-				return ErrRestoreAborted
-			}
-			if errors.Is(err, errRestoreBackToMode) {
-				// User chose "Back" from category selection: re-open restore mode selection.
-				continue
-			}
-			return err
-		}
-		break
-	}
-
-	plan := PlanRestore(candidate.Manifest, selectedCategories, systemType, mode)
-
-	// Cluster safety prompt (SAFE vs RECOVERY)
-	clusterBackup := strings.EqualFold(strings.TrimSpace(candidate.Manifest.ClusterMode), "cluster")
-	if plan.NeedsClusterRestore && clusterBackup {
-		logger.Info("Backup marked as cluster node; enabling guarded restore options for pve_cluster")
-		choice, promptErr := promptClusterRestoreModeTUI(configPath, buildSig)
-		if promptErr != nil {
-			if errors.Is(promptErr, ErrRestoreAborted) {
-				return ErrRestoreAborted
-			}
-			return promptErr
-		}
-		if choice == 0 {
-			return ErrRestoreAborted
-		}
-		if choice == 1 {
-			plan.ApplyClusterSafeMode(true)
-			logger.Info("Selected SAFE cluster restore: /var/lib/pve-cluster will be exported only, not written to system")
-		} else {
-			plan.ApplyClusterSafeMode(false)
-			logger.Warning("Selected RECOVERY cluster restore: full cluster database will be restored; ensure other nodes are isolated")
-		}
-	}
-
-	// Staging is designed to protect live systems. In test runs (fake filesystem) or non-root targets,
-	// extract staged categories directly to the destination to keep restore semantics predictable.
-	if destRoot != "/" || !isRealRestoreFS(restoreFS) {
-		if len(plan.StagedCategories) > 0 {
-			logging.DebugStep(logger, "restore", "Staging disabled (destRoot=%s realFS=%v): extracting %d staged category(ies) directly", destRoot, isRealRestoreFS(restoreFS), len(plan.StagedCategories))
-			plan.NormalCategories = append(plan.NormalCategories, plan.StagedCategories...)
-			plan.StagedCategories = nil
-		}
-	}
-
-	// Create restore configuration
-	restoreConfig := &SelectiveRestoreConfig{
-		Mode:       mode,
-		SystemType: systemType,
-		Metadata:   candidate.Manifest,
-	}
-	restoreConfig.SelectedCategories = append(restoreConfig.SelectedCategories, plan.NormalCategories...)
-	restoreConfig.SelectedCategories = append(restoreConfig.SelectedCategories, plan.StagedCategories...)
-	restoreConfig.SelectedCategories = append(restoreConfig.SelectedCategories, plan.ExportCategories...)
-
-	// Show detailed restore plan
-	if err := showRestorePlanTUI(restoreConfig, configPath, buildSig); err != nil {
-		if errors.Is(err, ErrRestoreAborted) {
-			return ErrRestoreAborted
-		}
-		return err
-	}
-
-	// Confirm operation (RESTORE)
-	confirmed, err := confirmRestoreTUI(configPath, buildSig)
-	if err != nil {
-		return err
-	}
-	if !confirmed {
-		logger.Info("Restore operation cancelled by user")
-		return ErrRestoreAborted
-	}
-
-	// Create safety backup of current configuration (only for categories that will write to system paths)
-	var safetyBackup *SafetyBackupResult
-	var networkRollbackBackup *SafetyBackupResult
-	systemWriteCategories := append([]Category{}, plan.NormalCategories...)
-	systemWriteCategories = append(systemWriteCategories, plan.StagedCategories...)
-	if len(systemWriteCategories) > 0 {
-		logger.Info("")
-		safetyBackup, err = CreateSafetyBackup(logger, systemWriteCategories, destRoot)
-		if err != nil {
-			logger.Warning("Failed to create safety backup: %v", err)
-			cont, perr := promptContinueWithoutSafetyBackupTUI(configPath, buildSig, err)
-			if perr != nil {
-				return perr
-			}
-			if !cont {
-				return fmt.Errorf("restore aborted: safety backup failed")
-			}
-		} else {
-			logger.Info("Safety backup location: %s", safetyBackup.BackupPath)
-			logger.Info("You can restore from this backup if needed using: tar -xzf %s -C /", safetyBackup.BackupPath)
-		}
-	}
-
-	if plan.HasCategoryID("network") {
-		logger.Info("")
-		logging.DebugStep(logger, "restore", "Create network-only rollback backup for transactional network apply")
-		networkRollbackBackup, err = CreateNetworkRollbackBackup(logger, systemWriteCategories, destRoot)
-		if err != nil {
-			logger.Warning("Failed to create network rollback backup: %v", err)
-		} else if networkRollbackBackup != nil && strings.TrimSpace(networkRollbackBackup.BackupPath) != "" {
-			logger.Info("Network rollback backup location: %s", networkRollbackBackup.BackupPath)
-			logger.Info("This backup is used for the %ds network rollback timer and only includes network paths.", int(defaultNetworkRollbackTimeout.Seconds()))
-		}
-	}
-
-	// If we are restoring cluster database, stop PVE services and unmount /etc/pve before writing
-	needsClusterRestore := plan.NeedsClusterRestore
-	clusterServicesStopped := false
-	pbsServicesStopped := false
-	needsPBSServices := plan.NeedsPBSServices
-	if needsClusterRestore {
-		logger.Info("")
-		logger.Info("Preparing system for cluster database restore: stopping PVE services and unmounting /etc/pve")
-		if err := stopPVEClusterServices(ctx, logger); err != nil {
-			return err
-		}
-		clusterServicesStopped = true
-		defer func() {
-			restartCtx, cancel := context.WithTimeout(context.Background(), 2*serviceStartTimeout+2*serviceVerifyTimeout+10*time.Second)
-			defer cancel()
-			if err := startPVEClusterServices(restartCtx, logger); err != nil {
-				logger.Warning("Failed to restart PVE services after restore: %v", err)
-			}
-		}()
-
-		if err := unmountEtcPVE(ctx, logger); err != nil {
-			logger.Warning("Could not unmount /etc/pve: %v", err)
-		}
-	}
-
-	// For PBS restores, stop PBS services before applying configuration/datastore changes if relevant categories are selected
-	if needsPBSServices {
-		logger.Info("")
-		logger.Info("Preparing PBS system for restore: stopping proxmox-backup services")
-		if err := stopPBSServices(ctx, logger); err != nil {
-			logger.Warning("Unable to stop PBS services automatically: %v", err)
-			cont, perr := promptContinueWithPBSServicesTUI(configPath, buildSig)
-			if perr != nil {
-				return perr
-			}
-			if !cont {
-				return ErrRestoreAborted
-			}
-			logger.Warning("Continuing restore with PBS services still running")
-		} else {
-			pbsServicesStopped = true
-			defer func() {
-				restartCtx, cancel := context.WithTimeout(context.Background(), 2*serviceStartTimeout+2*serviceVerifyTimeout+10*time.Second)
-				defer cancel()
-				if err := startPBSServices(restartCtx, logger); err != nil {
-					logger.Warning("Failed to restart PBS services after restore: %v", err)
-				}
-			}()
-		}
-	}
-
-	// Perform selective extraction for normal categories
-	var detailedLogPath string
-	if len(plan.NormalCategories) > 0 {
-		logger.Info("")
-		categoriesForExtraction := plan.NormalCategories
-		if needsClusterRestore {
-			logging.DebugStep(logger, "restore", "Cluster RECOVERY shadow-guard: sanitize categories to avoid /etc/pve shadow writes")
-			sanitized, removed := sanitizeCategoriesForClusterRecovery(categoriesForExtraction)
-			removedPaths := 0
-			for _, paths := range removed {
-				removedPaths += len(paths)
-			}
-			logging.DebugStep(
-				logger,
-				"restore",
-				"Cluster RECOVERY shadow-guard: categories_before=%d categories_after=%d removed_categories=%d removed_paths=%d",
-				len(categoriesForExtraction),
-				len(sanitized),
-				len(removed),
-				removedPaths,
-			)
-			if len(removed) > 0 {
-				logger.Warning("Cluster RECOVERY restore: skipping direct restore of /etc/pve paths to prevent shadowing while pmxcfs is stopped/unmounted")
-				for _, cat := range categoriesForExtraction {
-					if paths, ok := removed[cat.ID]; ok && len(paths) > 0 {
-						logger.Warning("  - %s (%s): %s", cat.Name, cat.ID, strings.Join(paths, ", "))
-					}
-				}
-				logger.Info("These paths are expected to be restored from config.db and become visible after /etc/pve is remounted.")
-			} else {
-				logging.DebugStep(logger, "restore", "Cluster RECOVERY shadow-guard: no /etc/pve paths detected in selected categories")
-			}
-			categoriesForExtraction = sanitized
-			var extractionIDs []string
-			for _, cat := range categoriesForExtraction {
-				if id := strings.TrimSpace(cat.ID); id != "" {
-					extractionIDs = append(extractionIDs, id)
-				}
-			}
-			if len(extractionIDs) > 0 {
-				logging.DebugStep(logger, "restore", "Cluster RECOVERY shadow-guard: extraction_categories=%s", strings.Join(extractionIDs, ","))
-			} else {
-				logging.DebugStep(logger, "restore", "Cluster RECOVERY shadow-guard: extraction_categories=<none>")
-			}
-		}
-
-		if len(categoriesForExtraction) == 0 {
-			logging.DebugStep(logger, "restore", "Skip system-path extraction: no categories remain after shadow-guard")
-			logger.Info("No system-path categories remain after cluster shadow-guard; skipping system-path extraction.")
-		} else {
-			detailedLogPath, err = extractSelectiveArchive(ctx, prepared.ArchivePath, destRoot, categoriesForExtraction, mode, logger)
-			if err != nil {
-				logger.Error("Restore failed: %v", err)
-				if safetyBackup != nil {
-					logger.Info("You can rollback using the safety backup at: %s", safetyBackup.BackupPath)
-				}
-				return err
-			}
-		}
-	} else {
-		logger.Info("")
-		logger.Info("No system-path categories selected for restore (only export categories will be processed).")
-	}
-
-	// Handle export-only categories by extracting them to a separate directory
-	exportLogPath := ""
-	exportRoot := ""
-	if len(plan.ExportCategories) > 0 {
-		exportRoot = exportDestRoot(cfg.BaseDir)
-		logger.Info("")
-		logger.Info("Exporting %d export-only category(ies) to: %s", len(plan.ExportCategories), exportRoot)
-		if err := restoreFS.MkdirAll(exportRoot, 0o755); err != nil {
-			return fmt.Errorf("failed to create export directory %s: %w", exportRoot, err)
-		}
-
-		if exportLog, exErr := extractSelectiveArchive(ctx, prepared.ArchivePath, exportRoot, plan.ExportCategories, RestoreModeCustom, logger); exErr != nil {
-			if errors.Is(exErr, ErrRestoreAborted) || input.IsAborted(exErr) {
-				return exErr
-			}
-			logger.Warning("Export completed with errors: %v", exErr)
-		} else {
-			exportLogPath = exportLog
-		}
-	}
-
-	// SAFE cluster mode: offer applying configs via pvesh without touching config.db
-	if plan.ClusterSafeMode {
-		if exportRoot == "" {
-			logger.Warning("Cluster SAFE mode selected but export directory not available; skipping automatic pvesh apply")
-		} else if err := runSafeClusterApply(ctx, bufio.NewReader(os.Stdin), exportRoot, logger); err != nil {
-			// Note: runSafeClusterApply currently uses console prompts; this step remains non-TUI.
-			if errors.Is(err, ErrRestoreAborted) || input.IsAborted(err) {
-				return err
-			}
-			logger.Warning("Cluster SAFE apply completed with errors: %v", err)
-		}
-	}
-
-	// Stage sensitive categories (network, PBS datastore/jobs) to a temporary directory and apply them safely later.
-	stageLogPath := ""
-	stageRoot := ""
-	if len(plan.StagedCategories) > 0 {
-		stageRoot = stageDestRoot()
-		logger.Info("")
-		logger.Info("Staging %d sensitive category(ies) to: %s", len(plan.StagedCategories), stageRoot)
-		if err := restoreFS.MkdirAll(stageRoot, 0o755); err != nil {
-			return fmt.Errorf("failed to create staging directory %s: %w", stageRoot, err)
-		}
-
-		if stageLog, err := extractSelectiveArchive(ctx, prepared.ArchivePath, stageRoot, plan.StagedCategories, RestoreModeCustom, logger); err != nil {
-			if errors.Is(err, ErrRestoreAborted) || input.IsAborted(err) {
-				return err
-			}
-			logger.Warning("Staging completed with errors: %v", err)
-		} else {
-			stageLogPath = stageLog
-		}
-
-		logger.Info("")
-		if err := maybeApplyPBSConfigsFromStage(ctx, logger, plan, stageRoot, cfg.DryRun); err != nil {
-			if errors.Is(err, ErrRestoreAborted) || input.IsAborted(err) {
-				return err
-			}
-			logger.Warning("PBS staged config apply: %v", err)
-		}
-	}
-
-	stageRootForNetworkApply := stageRoot
-	if installed, err := maybeInstallNetworkConfigFromStage(ctx, logger, plan, stageRoot, prepared.ArchivePath, networkRollbackBackup, cfg.DryRun); err != nil {
-		if errors.Is(err, ErrRestoreAborted) || input.IsAborted(err) {
-			return err
-		}
-		logger.Warning("Network staged install: %v", err)
-	} else if installed {
-		stageRootForNetworkApply = ""
-		logging.DebugStep(logger, "restore", "Network staged install completed: configuration written to /etc (no reload); live apply will use system paths")
-	}
-
-	// Recreate directory structures from configuration files if relevant categories were restored
-	logger.Info("")
-	categoriesForDirRecreate := append([]Category{}, plan.NormalCategories...)
-	categoriesForDirRecreate = append(categoriesForDirRecreate, plan.StagedCategories...)
-	if shouldRecreateDirectories(systemType, categoriesForDirRecreate) {
-		if err := RecreateDirectoriesFromConfig(systemType, logger); err != nil {
-			logger.Warning("Failed to recreate directory structures: %v", err)
-			logger.Warning("You may need to manually create storage/datastore directories")
-		}
-	} else {
-		logger.Debug("Skipping datastore/storage directory recreation (category not selected)")
-	}
-
-	logger.Info("")
-	if plan.HasCategoryID("network") {
-		logger.Info("")
-		if err := maybeRepairResolvConfAfterRestore(ctx, logger, prepared.ArchivePath, cfg.DryRun); err != nil {
-			if errors.Is(err, ErrRestoreAborted) || input.IsAborted(err) {
-				return err
-			}
-			logger.Warning("DNS resolver repair: %v", err)
-		}
-	}
-
-	logger.Info("")
-	if err := maybeApplyNetworkConfigTUI(ctx, logger, plan, safetyBackup, networkRollbackBackup, stageRootForNetworkApply, prepared.ArchivePath, configPath, buildSig, cfg.DryRun); err != nil {
-		if errors.Is(err, ErrRestoreAborted) || input.IsAborted(err) {
-			return err
-		}
-		logger.Warning("Network apply step skipped or failed: %v", err)
-	}
-
-	logger.Info("")
-	logger.Info("Restore completed successfully.")
-	logger.Info("Temporary decrypted bundle removed.")
-
-	if detailedLogPath != "" {
-		logger.Info("Detailed restore log: %s", detailedLogPath)
-	}
-	if exportRoot != "" {
-		logger.Info("Export directory: %s", exportRoot)
-	}
-	if exportLogPath != "" {
-		logger.Info("Export detailed log: %s", exportLogPath)
-	}
-	if stageRoot != "" {
-		logger.Info("Staging directory: %s", stageRoot)
-	}
-	if stageLogPath != "" {
-		logger.Info("Staging detailed log: %s", stageLogPath)
-	}
-
-	if safetyBackup != nil {
-		logger.Info("Safety backup preserved at: %s", safetyBackup.BackupPath)
-		logger.Info("Remove it manually if restore was successful: rm %s", safetyBackup.BackupPath)
-	}
-
-	logger.Info("")
-	logger.Info("IMPORTANT: You may need to restart services for changes to take effect.")
-	if systemType == SystemTypePVE {
-		if needsClusterRestore && clusterServicesStopped {
-			logger.Info("  PVE services were stopped/restarted during restore; verify status with: pvecm status")
-		} else {
-			logger.Info("  PVE services: systemctl restart pve-cluster pvedaemon pveproxy")
-		}
-	} else if systemType == SystemTypePBS {
-		if pbsServicesStopped {
-			logger.Info("  PBS services were stopped/restarted during restore; verify status with: systemctl status proxmox-backup proxmox-backup-proxy")
-		} else {
-			logger.Info("  PBS services: systemctl restart proxmox-backup-proxy proxmox-backup")
-		}
-
-		// Check ZFS pool status for PBS systems only when ZFS category was restored
-		if hasCategoryID(plan.NormalCategories, "zfs") {
-			logger.Info("")
-			if err := checkZFSPoolsAfterRestore(logger); err != nil {
-				logger.Warning("ZFS pool check: %v", err)
-			}
-		} else {
-			logger.Debug("Skipping ZFS pool verification (ZFS category not selected)")
-		}
-	}
-
-	logger.Info("")
-	logger.Warning("⚠ SYSTEM REBOOT RECOMMENDED")
-	logger.Info("Reboot the node (or at least restart networking and system services) to ensure all restored configurations take effect cleanly.")
-
-	return nil
-}
-
-func prepareDecryptedBackupTUI(ctx context.Context, cfg *config.Config, logger *logging.Logger, version, configPath, buildSig string) (*decryptCandidate, *preparedBundle, error) {
-	candidate, err := runRestoreSelectionWizard(ctx, cfg, logger, configPath, buildSig)
-	if err != nil {
-		return nil, nil, err
-	}
-
-	prepared, err := preparePlainBundleTUI(ctx, candidate, version, logger, configPath, buildSig)
-	if err != nil {
-		return nil, nil, err
-	}
-
-	return candidate, prepared, nil
-}
-
-func runRestoreSelectionWizard(ctx context.Context, cfg *config.Config, logger *logging.Logger, configPath, buildSig string) (candidate *decryptCandidate, err error) {
-	if ctx == nil {
-		ctx = context.Background()
-	}
-	done := logging.DebugStart(logger, "restore selection wizard", "tui=true")
-	defer func() { done(err) }()
-	options := buildDecryptPathOptions(cfg, logger)
-	if len(options) == 0 {
-		err = fmt.Errorf("no backup paths configured in backup.env")
-		return nil, err
-	}
-	for _, opt := range options {
-		logging.DebugStep(logger, "restore selection wizard", "option label=%q path=%q rclone=%v", opt.Label, opt.Path, opt.IsRclone)
-	}
-
-	app := newTUIApp()
-	pages := tview.NewPages()
-
-	selection := &restoreSelection{}
-	var selectionErr error
-	var scan scanController
-	var scanSeq uint64
-
-	pathList := tview.NewList().ShowSecondaryText(false)
-	pathList.SetMainTextColor(tcell.ColorWhite).
-		SetSelectedTextColor(tcell.ColorWhite).
-		SetSelectedBackgroundColor(tui.ProxmoxOrange)
-
-	for _, opt := range options {
-		// Use parentheses instead of square brackets (tview interprets [] as color tags)
-		label := fmt.Sprintf("%s (%s)", opt.Label, opt.Path)
-		pathList.AddItem(label, "", 0, nil)
-	}
-
-	pathList.SetSelectedFunc(func(index int, mainText, secondaryText string, shortcut rune) {
-		if index < 0 || index >= len(options) {
-			return
-		}
-		selectedOption := options[index]
-		scanID := atomic.AddUint64(&scanSeq, 1)
-		logging.DebugStep(logger, "restore selection wizard", "selected source label=%q path=%q rclone=%v", selectedOption.Label, selectedOption.Path, selectedOption.IsRclone)
-		pages.SwitchToPage("paths-loading")
-		go func() {
-			scanCtx, finish := scan.Start(ctx)
-			defer finish()
-
-			var candidates []*decryptCandidate
-			var scanErr error
-			scanDone := logging.DebugStart(logger, "scan backup source", "id=%d path=%s rclone=%v", scanID, selectedOption.Path, selectedOption.IsRclone)
-			defer func() { scanDone(scanErr) }()
-
-			if selectedOption.IsRclone {
-				timeout := 30 * time.Second
-				if cfg != nil && cfg.RcloneTimeoutConnection > 0 {
-					timeout = time.Duration(cfg.RcloneTimeoutConnection) * time.Second
-				}
-				logging.DebugStep(logger, "scan backup source", "id=%d rclone_timeout=%s", scanID, timeout)
-				rcloneCtx, cancel := context.WithTimeout(scanCtx, timeout)
-				defer cancel()
-				candidates, scanErr = discoverRcloneBackups(rcloneCtx, selectedOption.Path, logger)
-			} else {
-				candidates, scanErr = discoverBackupCandidates(logger, selectedOption.Path)
-			}
-			logging.DebugStep(logger, "scan backup source", "candidates=%d", len(candidates))
-			if scanCtx.Err() != nil {
-				scanErr = scanCtx.Err()
-				return
-			}
-			app.QueueUpdateDraw(func() {
-				if scanErr != nil {
-					message := fmt.Sprintf("Failed to inspect %s: %v", selectedOption.Path, scanErr)
-					if selectedOption.IsRclone && errors.Is(scanErr, context.DeadlineExceeded) {
-						message = fmt.Sprintf("Timed out while scanning %s (rclone). Check connectivity/rclone config or increase RCLONE_TIMEOUT_CONNECTION. (%v)", selectedOption.Path, scanErr)
-					}
-					showRestoreErrorModal(app, pages, configPath, buildSig, message, func() {
-						pages.SwitchToPage("paths")
-					})
-					return
-				}
-				if len(candidates) == 0 {
-					message := "No backups found in selected path."
-					showRestoreErrorModal(app, pages, configPath, buildSig, message, func() {
-						pages.SwitchToPage("paths")
-					})
-					return
-				}
-
-				showRestoreCandidatePage(app, pages, candidates, configPath, buildSig, func(c *decryptCandidate) {
-					selection.Candidate = c
-					app.Stop()
-				}, func() {
-					selectionErr = ErrRestoreAborted
-					app.Stop()
-				})
-			})
-		}()
-	})
-	pathList.SetDoneFunc(func() {
-		logging.DebugStep(logger, "restore selection wizard", "cancel requested (done func)")
-		scan.Cancel()
-		selectionErr = ErrRestoreAborted
-		app.Stop()
-	})
-
-	form := components.NewForm(app)
-	listHeight := len(options)
-	if listHeight < 8 {
-		listHeight = 8
-	}
-	if listHeight > 14 {
-		listHeight = 14
-	}
-	listItem := components.NewListFormItem(pathList).
-		SetLabel("Available backup sources").
-		SetFieldHeight(listHeight)
-	form.Form.AddFormItem(listItem)
-	form.Form.SetFocus(0)
-
-	form.SetOnCancel(func() {
-		logging.DebugStep(logger, "restore selection wizard", "cancel requested (form)")
-		scan.Cancel()
-		selectionErr = ErrRestoreAborted
-	})
-	form.AddCancelButton("Cancel")
-	enableFormNavigation(form, nil)
-
-	pathPage := buildRestoreWizardPage("Select backup source", configPath, buildSig, form.Form)
-	pages.AddPage("paths", pathPage, true, true)
-
-	loadingText := tview.NewTextView().
-		SetText("Scanning backup path...").
-		SetTextAlign(tview.AlignCenter)
-
-	loadingForm := components.NewForm(app)
-	loadingForm.SetOnCancel(func() {
-		logging.DebugStep(logger, "restore selection wizard", "cancel requested (loading form)")
-		scan.Cancel()
-		selectionErr = ErrRestoreAborted
-	})
-	loadingForm.AddCancelButton("Cancel")
-	loadingContent := tview.NewFlex().
-		SetDirection(tview.FlexRow).
-		AddItem(loadingText, 0, 1, false).
-		AddItem(loadingForm.Form, 3, 0, false)
-	loadingPage := buildRestoreWizardPage("Loading backups", configPath, buildSig, loadingContent)
-	pages.AddPage("paths-loading", loadingPage, true, false)
-
-	app.SetRoot(pages, true).SetFocus(form.Form)
-	if runErr := app.Run(); runErr != nil {
-		err = runErr
-		return nil, err
-	}
-	if selectionErr != nil {
-		err = selectionErr
-		return nil, err
-	}
-	if selection.Candidate == nil {
-		err = ErrRestoreAborted
-		return nil, err
-	}
-	candidate = selection.Candidate
-	return candidate, nil
-}
-
-func showRestoreErrorModal(app *tui.App, pages *tview.Pages, configPath, buildSig, message string, onDismiss func()) {
-	modal := tview.NewModal().
-		SetText(fmt.Sprintf("%s %s\n\n[yellow]Press ENTER to continue[white]", tui.SymbolError, message)).
-		AddButtons([]string{"OK"}).
-		SetDoneFunc(func(buttonIndex int, buttonLabel string) {
-			if pages.HasPage(restoreErrorModalPage) {
-				pages.RemovePage(restoreErrorModalPage)
-			}
-			if onDismiss != nil {
-				onDismiss()
-			}
-		})
-
-	modal.SetBorder(true).
-		SetTitle(" Restore Error ").
-		SetTitleAlign(tview.AlignCenter).
-		SetTitleColor(tui.ErrorRed).
-		SetBorderColor(tui.ErrorRed).
-		SetBackgroundColor(tcell.ColorBlack)
-
-	page := buildRestoreWizardPage("Error", configPath, buildSig, modal)
-	if pages.HasPage(restoreErrorModalPage) {
-		pages.RemovePage(restoreErrorModalPage)
-	}
-	pages.AddPage(restoreErrorModalPage, page, true, true)
-	app.SetFocus(modal)
-}
-
-func showRestoreCandidatePage(app *tui.App, pages *tview.Pages, candidates []*decryptCandidate, configPath, buildSig string, onSelect func(*decryptCandidate), onCancel func()) {
-	list := tview.NewList().ShowSecondaryText(false)
-	list.SetMainTextColor(tcell.ColorWhite).
-		SetSelectedTextColor(tcell.ColorWhite).
-		SetSelectedBackgroundColor(tui.ProxmoxOrange)
-
-	type row struct {
-		created     string
-		mode        string
-		tool        string
-		targets     string
-		compression string
-	}
-
-	rows := make([]row, len(candidates))
-	var maxMode, maxTool, maxTargets, maxComp int
-
-	for idx, cand := range candidates {
-		created := cand.Manifest.CreatedAt.Format("2006-01-02 15:04:05")
-
-		mode := strings.ToUpper(statusFromManifest(cand.Manifest))
-		if mode == "" {
-			mode = "UNKNOWN"
-		}
-
-		toolVersion := strings.TrimSpace(cand.Manifest.ScriptVersion)
-		if toolVersion == "" {
-			toolVersion = "unknown"
-		}
-		tool := "Tool " + toolVersion
-
-		targets := buildTargetInfo(cand.Manifest)
-
-		comp := ""
-		if c := strings.TrimSpace(cand.Manifest.CompressionType); c != "" {
-			comp = strings.ToUpper(c)
-		}
-
-		rows[idx] = row{
-			created:     created,
-			mode:        mode,
-			tool:        tool,
-			targets:     targets,
-			compression: comp,
-		}
-
-		if len(mode) > maxMode {
-			maxMode = len(mode)
-		}
-		if len(tool) > maxTool {
-			maxTool = len(tool)
-		}
-		if len(targets) > maxTargets {
-			maxTargets = len(targets)
-		}
-		if len(comp) > maxComp {
-			maxComp = len(comp)
-		}
-	}
-
-	for idx, r := range rows {
-		line := fmt.Sprintf(
-			"%2d) %s  %-*s  %-*s  %-*s",
-			idx+1,
-			r.created,
-			maxMode, r.mode,
-			maxTool, r.tool,
-			maxTargets, r.targets,
-		)
-		if maxComp > 0 {
-			line = fmt.Sprintf("%s  %-*s", line, maxComp, r.compression)
-		}
-		list.AddItem(line, "", 0, nil)
-	}
-
-	list.SetSelectedFunc(func(index int, mainText, secondaryText string, shortcut rune) {
-		if index < 0 || index >= len(candidates) {
-			return
-		}
-		onSelect(candidates[index])
-	})
-	list.SetDoneFunc(func() {
-		pages.SwitchToPage("paths")
-	})
-
-	form := components.NewForm(app)
-	listHeight := len(candidates)
-	if listHeight < 8 {
-		listHeight = 8
+	if cfg == nil {
+		return fmt.Errorf("configuration not available")
 	}
-	if listHeight > 14 {
-		listHeight = 14
+	if logger == nil {
+		logger = logging.GetDefaultLogger()
+	}
+	if strings.TrimSpace(buildSig) == "" {
+		buildSig = "n/a"
 	}
-	listItem := components.NewListFormItem(list).
-		SetLabel("Available backups").
-		SetFieldHeight(listHeight)
-	form.Form.AddFormItem(listItem)
-	form.Form.SetFocus(0)
-
-	form.SetOnCancel(func() {
-		if onCancel != nil {
-			onCancel()
-		}
-	})
 
-	// Back goes on the left, Cancel on the right (order of AddButton calls)
-	form.Form.AddButton("Back", func() {
-		pages.SwitchToPage("paths")
-	})
-	form.AddCancelButton("Cancel")
-	enableFormNavigation(form, nil)
+	done := logging.DebugStart(logger, "restore workflow (tui)", "version=%s", version)
+	defer func() { done(err) }()
 
-	page := buildRestoreWizardPage("Select backup to restore", configPath, buildSig, form.Form)
-	if pages.HasPage("candidates") {
-		pages.RemovePage("candidates")
+	ui := newTUIRestoreWorkflowUI(configPath, buildSig, logger)
+	if err := runRestoreWorkflowWithUI(ctx, cfg, logger, version, ui); err != nil {
+		if errors.Is(err, ErrRestoreAborted) {
+			return ErrRestoreAborted
+		}
+		return err
 	}
-	pages.AddPage("candidates", page, true, true)
+	return nil
 }
 
 func selectRestoreModeTUI(systemType SystemType, configPath, buildSig, backupSummary string) (RestoreMode, error) {
@@ -1098,436 +312,6 @@ func promptContinueWithPBSServicesTUI(configPath, buildSig string) (bool, error)
 	)
 }
 
-func maybeApplyNetworkConfigTUI(ctx context.Context, logger *logging.Logger, plan *RestorePlan, safetyBackup, networkRollbackBackup *SafetyBackupResult, stageRoot, archivePath, configPath, buildSig string, dryRun bool) (err error) {
-	if !shouldAttemptNetworkApply(plan) {
-		if logger != nil {
-			logger.Debug("Network safe apply (TUI): skipped (network category not selected)")
-		}
-		return nil
-	}
-	done := logging.DebugStart(logger, "network safe apply (tui)", "dryRun=%v euid=%d stage=%s archive=%s", dryRun, os.Geteuid(), strings.TrimSpace(stageRoot), strings.TrimSpace(archivePath))
-	defer func() { done(err) }()
-
-	if !isRealRestoreFS(restoreFS) {
-		logger.Debug("Skipping live network apply: non-system filesystem in use")
-		return nil
-	}
-	if dryRun {
-		logger.Info("Dry run enabled: skipping live network apply")
-		return nil
-	}
-	if os.Geteuid() != 0 {
-		logger.Warning("Skipping live network apply: requires root privileges")
-		return nil
-	}
-
-	logging.DebugStep(logger, "network safe apply (tui)", "Resolve rollback backup paths")
-	networkRollbackPath := ""
-	if networkRollbackBackup != nil {
-		networkRollbackPath = strings.TrimSpace(networkRollbackBackup.BackupPath)
-	}
-	fullRollbackPath := ""
-	if safetyBackup != nil {
-		fullRollbackPath = strings.TrimSpace(safetyBackup.BackupPath)
-	}
-	logging.DebugStep(logger, "network safe apply (tui)", "Rollback backup resolved: network=%q full=%q", networkRollbackPath, fullRollbackPath)
-	if networkRollbackPath == "" && fullRollbackPath == "" {
-		logger.Warning("Skipping live network apply: rollback backup not available")
-		if strings.TrimSpace(stageRoot) != "" {
-			logger.Info("Network configuration is staged; skipping NIC repair/apply due to missing rollback backup.")
-			return nil
-		}
-		repairNow, err := promptYesNoTUIFunc(
-			"NIC name repair (recommended)",
-			configPath,
-			buildSig,
-			"Attempt NIC name repair in restored network config files now (no reload)?\n\nThis will only rewrite /etc/network/interfaces and /etc/network/interfaces.d/* when safe mappings are found.",
-			"Repair now",
-			"Skip repair",
-		)
-		if err != nil {
-			return err
-		}
-		logging.DebugStep(logger, "network safe apply (tui)", "User choice: repairNow=%v", repairNow)
-		if repairNow {
-			if repair := maybeRepairNICNamesTUI(ctx, logger, archivePath, configPath, buildSig); repair != nil {
-				_ = promptOkTUI("NIC repair result", configPath, buildSig, repair.Details(), "OK")
-			}
-		}
-		logger.Info("Skipping live network apply (you can reboot or apply manually later).")
-		return nil
-	}
-
-	logging.DebugStep(logger, "network safe apply (tui)", "Prompt: apply network now with rollback timer")
-	sourceLine := "Source: /etc/network (will be applied)"
-	if strings.TrimSpace(stageRoot) != "" {
-		sourceLine = fmt.Sprintf("Source: %s (will be copied to /etc and applied)", strings.TrimSpace(stageRoot))
-	}
-	message := fmt.Sprintf(
-		"Network restore: a restored network configuration is ready to apply.\n%s\n\nThis will reload networking immediately (no reboot).\n\nWARNING: This may change the active IP and disconnect SSH/Web sessions.\n\nAfter applying, type COMMIT within %ds or ProxSave will roll back automatically.\n\nRecommendation: run this step from the local console/IPMI, not over SSH.\n\nApply network configuration now?",
-		sourceLine,
-		int(defaultNetworkRollbackTimeout.Seconds()),
-	)
-	applyNow, err := promptYesNoTUIWithCountdown(
-		ctx,
-		logger,
-		"Apply network configuration",
-		configPath,
-		buildSig,
-		message,
-		"Apply now",
-		"Skip apply",
-		90*time.Second,
-	)
-	if err != nil {
-		return err
-	}
-	logging.DebugStep(logger, "network safe apply (tui)", "User choice: applyNow=%v", applyNow)
-	if !applyNow {
-		if strings.TrimSpace(stageRoot) == "" {
-			repairNow, err := promptYesNoTUIFunc(
-				"NIC name repair (recommended)",
-				configPath,
-				buildSig,
-				"Attempt NIC name repair in restored network config files now (no reload)?\n\nThis will only rewrite /etc/network/interfaces and /etc/network/interfaces.d/* when safe mappings are found.",
-				"Repair now",
-				"Skip repair",
-			)
-			if err != nil {
-				return err
-			}
-			logging.DebugStep(logger, "network safe apply (tui)", "User choice: repairNow=%v", repairNow)
-			if repairNow {
-				if repair := maybeRepairNICNamesTUI(ctx, logger, archivePath, configPath, buildSig); repair != nil {
-					_ = promptOkTUI("NIC repair result", configPath, buildSig, repair.Details(), "OK")
-				}
-			}
-		} else {
-			logger.Info("Network configuration is staged (not yet written to /etc); skipping NIC repair prompt.")
-		}
-		logger.Info("Skipping live network apply (you can apply later).")
-		return nil
-	}
-
-	rollbackPath := networkRollbackPath
-	if rollbackPath == "" {
-		logging.DebugStep(logger, "network safe apply (tui)", "Prompt: network-only rollback missing; allow full rollback backup fallback")
-		ok, err := promptYesNoTUIFunc(
-			"Network-only rollback not available",
-			configPath,
-			buildSig,
-			"Network-only rollback backup is not available.\n\nIf you proceed, the rollback timer will use the full safety backup, which may revert other restored categories.\n\nProceed anyway?",
-			"Proceed with full rollback",
-			"Skip apply",
-		)
-		if err != nil {
-			return err
-		}
-		logging.DebugStep(logger, "network safe apply (tui)", "User choice: allowFullRollback=%v", ok)
-		if !ok {
-			repairNow, err := promptYesNoTUIFunc(
-				"NIC name repair (recommended)",
-				configPath,
-				buildSig,
-				"Attempt NIC name repair in restored network config files now (no reload)?\n\nThis will only rewrite /etc/network/interfaces and /etc/network/interfaces.d/* when safe mappings are found.",
-				"Repair now",
-				"Skip repair",
-			)
-			if err != nil {
-				return err
-			}
-			logging.DebugStep(logger, "network safe apply (tui)", "User choice: repairNow=%v", repairNow)
-			if repairNow {
-				if repair := maybeRepairNICNamesTUI(ctx, logger, archivePath, configPath, buildSig); repair != nil {
-					_ = promptOkTUI("NIC repair result", configPath, buildSig, repair.Details(), "OK")
-				}
-			}
-			logger.Info("Skipping live network apply (you can reboot or apply manually later).")
-			return nil
-		}
-		rollbackPath = fullRollbackPath
-	}
-
-	logging.DebugStep(logger, "network safe apply (tui)", "Selected rollback backup: %s", rollbackPath)
-	if err := applyNetworkWithRollbackTUI(ctx, logger, rollbackPath, networkRollbackPath, stageRoot, archivePath, configPath, buildSig, defaultNetworkRollbackTimeout, plan.SystemType); err != nil {
-		return err
-	}
-	return nil
-}
-
-func applyNetworkWithRollbackTUI(ctx context.Context, logger *logging.Logger, rollbackBackupPath, networkRollbackPath, stageRoot, archivePath, configPath, buildSig string, timeout time.Duration, systemType SystemType) (err error) {
-	done := logging.DebugStart(
-		logger,
-		"network safe apply (tui)",
-		"rollbackBackup=%s networkRollback=%s timeout=%s systemType=%s stage=%s",
-		strings.TrimSpace(rollbackBackupPath),
-		strings.TrimSpace(networkRollbackPath),
-		timeout,
-		systemType,
-		strings.TrimSpace(stageRoot),
-	)
-	defer func() { done(err) }()
-
-	logging.DebugStep(logger, "network safe apply (tui)", "Create diagnostics directory")
-	diagnosticsDir, err := createNetworkDiagnosticsDir()
-	if err != nil {
-		logger.Warning("Network diagnostics disabled: %v", err)
-		diagnosticsDir = ""
-	} else {
-		logger.Info("Network diagnostics directory: %s", diagnosticsDir)
-	}
-
-	logging.DebugStep(logger, "network safe apply (tui)", "Detect management interface (SSH/default route)")
-	iface, source := detectManagementInterface(ctx, logger)
-	if iface != "" {
-		logger.Info("Detected management interface: %s (%s)", iface, source)
-	}
-
-	if diagnosticsDir != "" {
-		logging.DebugStep(logger, "network safe apply (tui)", "Capture network snapshot (before)")
-		if snap, err := writeNetworkSnapshot(ctx, logger, diagnosticsDir, "before", 3*time.Second); err != nil {
-			logger.Debug("Network snapshot before apply failed: %v", err)
-		} else {
-			logger.Debug("Network snapshot (before): %s", snap)
-		}
-
-		logging.DebugStep(logger, "network safe apply (tui)", "Run baseline health checks (before)")
-		healthBefore := runNetworkHealthChecks(ctx, networkHealthOptions{
-			SystemType:         systemType,
-			Logger:             logger,
-			CommandTimeout:     3 * time.Second,
-			EnableGatewayPing:  false,
-			ForceSSHRouteCheck: false,
-			EnableDNSResolve:   false,
-		})
-		if path, err := writeNetworkHealthReportFileNamed(diagnosticsDir, "health_before.txt", healthBefore); err != nil {
-			logger.Debug("Failed to write network health (before) report: %v", err)
-		} else {
-			logger.Debug("Network health (before) report: %s", path)
-		}
-	}
-
-	if strings.TrimSpace(stageRoot) != "" {
-		logging.DebugStep(logger, "network safe apply (tui)", "Apply staged network files to system paths (before NIC repair)")
-		applied, err := applyNetworkFilesFromStage(logger, stageRoot)
-		if err != nil {
-			return err
-		}
-		if len(applied) > 0 {
-			logging.DebugStep(logger, "network safe apply (tui)", "Staged network files written: %d", len(applied))
-		}
-	}
-
-	logging.DebugStep(logger, "network safe apply (tui)", "NIC name repair (optional)")
-	nicRepair := maybeRepairNICNamesTUI(ctx, logger, archivePath, configPath, buildSig)
-	if nicRepair != nil {
-		if nicRepair.Applied() || nicRepair.SkippedReason != "" {
-			logger.Info("%s", nicRepair.Summary())
-		} else {
-			logger.Debug("%s", nicRepair.Summary())
-		}
-	}
-
-	if strings.TrimSpace(iface) != "" {
-		if cur, err := currentNetworkEndpoint(ctx, iface, 2*time.Second); err == nil {
-			if tgt, err := targetNetworkEndpointFromConfig(logger, iface); err == nil {
-				logger.Info("Network plan: %s -> %s", cur.summary(), tgt.summary())
-			}
-		}
-	}
-
-	if diagnosticsDir != "" {
-		logging.DebugStep(logger, "network safe apply (tui)", "Write network plan (current -> target)")
-		if planText, err := buildNetworkPlanReport(ctx, logger, iface, source, 2*time.Second); err != nil {
-			logger.Debug("Network plan build failed: %v", err)
-		} else if strings.TrimSpace(planText) != "" {
-			if path, err := writeNetworkTextReportFile(diagnosticsDir, "plan.txt", planText+"\n"); err != nil {
-				logger.Debug("Network plan write failed: %v", err)
-			} else {
-				logger.Debug("Network plan: %s", path)
-			}
-		}
-
-		logging.DebugStep(logger, "network safe apply (tui)", "Run ifquery diagnostic (pre-apply)")
-		ifqueryPre := runNetworkIfqueryDiagnostic(ctx, 5*time.Second, logger)
-		if !ifqueryPre.Skipped {
-			if path, err := writeNetworkIfqueryDiagnosticReportFile(diagnosticsDir, "ifquery_pre_apply.txt", ifqueryPre); err != nil {
-				logger.Debug("Failed to write ifquery (pre-apply) report: %v", err)
-			} else {
-				logger.Debug("ifquery (pre-apply) report: %s", path)
-			}
-		}
-	}
-
-	logging.DebugStep(logger, "network safe apply (tui)", "Network preflight validation (ifupdown/ifupdown2)")
-	preflight := runNetworkPreflightValidation(ctx, 5*time.Second, logger)
-	if diagnosticsDir != "" {
-		if path, err := writeNetworkPreflightReportFile(diagnosticsDir, preflight); err != nil {
-			logger.Debug("Failed to write network preflight report: %v", err)
-		} else {
-			logger.Debug("Network preflight report: %s", path)
-		}
-	}
-	if !preflight.Ok() {
-		message := preflight.Summary()
-		if strings.TrimSpace(diagnosticsDir) != "" {
-			message += "\n\nDiagnostics saved under:\n" + diagnosticsDir
-		}
-		if out := strings.TrimSpace(preflight.Output); out != "" {
-			message += "\n\nOutput:\n" + out
-		}
-		if strings.TrimSpace(stageRoot) != "" && strings.TrimSpace(networkRollbackPath) != "" {
-			logging.DebugStep(logger, "network safe apply (tui)", "Preflight failed in staged mode: rolling back network files automatically")
-			rollbackLog, rbErr := rollbackNetworkFilesNow(ctx, logger, networkRollbackPath, diagnosticsDir)
-			if strings.TrimSpace(rollbackLog) != "" {
-				logger.Info("Network rollback log: %s", rollbackLog)
-			}
-			if rbErr != nil {
-				logger.Error("Network apply aborted: preflight validation failed (%s) and rollback failed: %v", preflight.CommandLine(), rbErr)
-				_ = promptOkTUI("Network rollback failed", configPath, buildSig, rbErr.Error(), "OK")
-				return fmt.Errorf("network preflight validation failed; rollback attempt failed: %w", rbErr)
-			}
-			if diagnosticsDir != "" {
-				logging.DebugStep(logger, "network safe apply (tui)", "Capture network snapshot (after rollback)")
-				if snap, err := writeNetworkSnapshot(ctx, logger, diagnosticsDir, "after_rollback", 3*time.Second); err != nil {
-					logger.Debug("Network snapshot after rollback failed: %v", err)
-				} else {
-					logger.Debug("Network snapshot (after rollback): %s", snap)
-				}
-				logging.DebugStep(logger, "network safe apply (tui)", "Run ifquery diagnostic (after rollback)")
-				ifqueryAfterRollback := runNetworkIfqueryDiagnostic(ctx, 5*time.Second, logger)
-				if !ifqueryAfterRollback.Skipped {
-					if path, err := writeNetworkIfqueryDiagnosticReportFile(diagnosticsDir, "ifquery_after_rollback.txt", ifqueryAfterRollback); err != nil {
-						logger.Debug("Failed to write ifquery (after rollback) report: %v", err)
-					} else {
-						logger.Debug("ifquery (after rollback) report: %s", path)
-					}
-				}
-			}
-			logger.Warning(
-				"Network apply aborted: preflight validation failed (%s). Rolled back /etc/network/*, /etc/hosts, /etc/hostname, /etc/resolv.conf to the pre-restore state (rollback=%s).",
-				preflight.CommandLine(),
-				strings.TrimSpace(networkRollbackPath),
-			)
-			_ = promptOkTUI(
-				"Network preflight failed",
-				configPath,
-				buildSig,
-				fmt.Sprintf("Network configuration failed preflight and was rolled back automatically.\n\nRollback log:\n%s", strings.TrimSpace(rollbackLog)),
-				"OK",
-			)
-			return fmt.Errorf("network preflight validation failed; network files rolled back")
-		}
-		if !preflight.Skipped && preflight.ExitError != nil && strings.TrimSpace(networkRollbackPath) != "" {
-			message += "\n\nRollback restored network config files to the pre-restore configuration now? (recommended)"
-			rollbackNow, err := promptYesNoTUIFunc(
-				"Network preflight failed",
-				configPath,
-				buildSig,
-				message,
-				"Rollback now",
-				"Keep restored files",
-			)
-			if err != nil {
-				return err
-			}
-			logging.DebugStep(logger, "network safe apply (tui)", "User choice: rollbackNow=%v", rollbackNow)
-			if rollbackNow {
-				logging.DebugStep(logger, "network safe apply (tui)", "Rollback network files now (backup=%s)", strings.TrimSpace(networkRollbackPath))
-				rollbackLog, rbErr := rollbackNetworkFilesNow(ctx, logger, networkRollbackPath, diagnosticsDir)
-				if strings.TrimSpace(rollbackLog) != "" {
-					logger.Info("Network rollback log: %s", rollbackLog)
-				}
-				if rbErr != nil {
-					_ = promptOkTUI("Network rollback failed", configPath, buildSig, rbErr.Error(), "OK")
-					return fmt.Errorf("network preflight validation failed; rollback attempt failed: %w", rbErr)
-				}
-				_ = promptOkTUI(
-					"Network rollback completed",
-					configPath,
-					buildSig,
-					fmt.Sprintf("Network files rolled back to pre-restore configuration.\n\nRollback log:\n%s", strings.TrimSpace(rollbackLog)),
-					"OK",
-				)
-				return fmt.Errorf("network preflight validation failed; network files rolled back")
-			}
-		} else {
-			_ = promptOkTUI("Network preflight failed", configPath, buildSig, message, "OK")
-		}
-		return fmt.Errorf("network preflight validation failed; aborting live network apply")
-	}
-
-	logging.DebugStep(logger, "network safe apply (tui)", "Arm rollback timer BEFORE applying changes")
-	handle, err := armNetworkRollback(ctx, logger, rollbackBackupPath, timeout, diagnosticsDir)
-	if err != nil {
-		return err
-	}
-
-	logging.DebugStep(logger, "network safe apply (tui)", "Apply network configuration now")
-	if err := applyNetworkConfig(ctx, logger); err != nil {
-		logger.Warning("Network apply failed: %v", err)
-		return err
-	}
-
-	if diagnosticsDir != "" {
-		logging.DebugStep(logger, "network safe apply (tui)", "Capture network snapshot (after)")
-		if snap, err := writeNetworkSnapshot(ctx, logger, diagnosticsDir, "after", 3*time.Second); err != nil {
-			logger.Debug("Network snapshot after apply failed: %v", err)
-		} else {
-			logger.Debug("Network snapshot (after): %s", snap)
-		}
-
-		logging.DebugStep(logger, "network safe apply (tui)", "Run ifquery diagnostic (post-apply)")
-		ifqueryPost := runNetworkIfqueryDiagnostic(ctx, 5*time.Second, logger)
-		if !ifqueryPost.Skipped {
-			if path, err := writeNetworkIfqueryDiagnosticReportFile(diagnosticsDir, "ifquery_post_apply.txt", ifqueryPost); err != nil {
-				logger.Debug("Failed to write ifquery (post-apply) report: %v", err)
-			} else {
-				logger.Debug("ifquery (post-apply) report: %s", path)
-			}
-		}
-	}
-
-	logging.DebugStep(logger, "network safe apply (tui)", "Run post-apply health checks")
-	health := runNetworkHealthChecks(ctx, networkHealthOptions{
-		SystemType:         systemType,
-		Logger:             logger,
-		CommandTimeout:     3 * time.Second,
-		EnableGatewayPing:  true,
-		ForceSSHRouteCheck: false,
-		EnableDNSResolve:   true,
-		LocalPortChecks:    defaultNetworkPortChecks(systemType),
-	})
-	logNetworkHealthReport(logger, health)
-	if diagnosticsDir != "" {
-		if path, err := writeNetworkHealthReportFile(diagnosticsDir, health); err != nil {
-			logger.Debug("Failed to write network health report: %v", err)
-		} else {
-			logger.Debug("Network health report: %s", path)
-		}
-	}
-
-	remaining := handle.remaining(time.Now())
-	if remaining <= 0 {
-		logger.Warning("Rollback window already expired; leaving rollback armed")
-		return nil
-	}
-
-	logging.DebugStep(logger, "network safe apply (tui)", "Wait for COMMIT (rollback in %ds)", int(remaining.Seconds()))
-	committed, err := promptNetworkCommitTUI(remaining, health, nicRepair, diagnosticsDir, configPath, buildSig)
-	if err != nil {
-		logger.Warning("Commit prompt error: %v", err)
-	}
-	logging.DebugStep(logger, "network safe apply (tui)", "User commit result: committed=%v", committed)
-	if committed {
-		disarmNetworkRollback(ctx, logger, handle)
-		logger.Info("Network configuration committed successfully.")
-		return nil
-	}
-	logger.Warning("Network configuration not committed; rollback will run automatically.")
-	return nil
-}
-
 func maybeRepairNICNamesTUI(ctx context.Context, logger *logging.Logger, archivePath, configPath, buildSig string) *nicRepairResult {
 	logging.DebugStep(logger, "NIC repair", "Plan NIC name repair (archive=%s)", strings.TrimSpace(archivePath))
 	plan, err := planNICNameRepair(ctx, archivePath)
@@ -1837,152 +621,6 @@ func confirmRestoreTUI(configPath, buildSig string) (bool, error) {
 	return true, nil
 }
 
-func runFullRestoreTUI(ctx context.Context, candidate *decryptCandidate, prepared *preparedBundle, destRoot string, logger *logging.Logger, dryRun bool, configPath, buildSig string) error {
-	if candidate == nil || prepared == nil || prepared.Manifest.ArchivePath == "" {
-		return fmt.Errorf("invalid restore candidate")
-	}
-
-	app := newTUIApp()
-	manifest := candidate.Manifest
-
-	var b strings.Builder
-	fmt.Fprintf(&b, "Selected backup: %s (%s)\n",
-		candidate.DisplayBase,
-		manifest.CreatedAt.Format("2006-01-02 15:04:05"),
-	)
-	b.WriteString("Restore destination: / (system root; original paths will be preserved)\n")
-	b.WriteString("WARNING: This operation will overwrite configuration files on this system.\n\n")
-	b.WriteString("Press RESTORE to start the restore process, or Cancel to abort.\nYou will be asked for explicit confirmation before overwriting files.\n")
-
-	infoText := tview.NewTextView().
-		SetText(b.String()).
-		SetWrap(true).
-		SetTextColor(tcell.ColorWhite)
-
-	form := components.NewForm(app)
-	var confirmed bool
-	var aborted bool
-	form.SetOnSubmit(func(values map[string]string) error {
-		confirmed = true
-		return nil
-	})
-	form.SetOnCancel(func() {
-		aborted = true
-	})
-	form.AddSubmitButton("RESTORE")
-	form.AddCancelButton("Cancel")
-	enableFormNavigation(form, nil)
-
-	content := tview.NewFlex().
-		SetDirection(tview.FlexRow).
-		AddItem(infoText, 4, 0, false).
-		AddItem(form.Form, 0, 1, true)
-
-	page := buildRestoreWizardPage("Full restore confirmation", configPath, buildSig, content)
-	form.SetParentView(page)
-
-	if err := app.SetRoot(page, true).SetFocus(form.Form).Run(); err != nil {
-		return err
-	}
-	if aborted || !confirmed {
-		return ErrRestoreAborted
-	}
-
-	ok, err := confirmOverwriteTUI(configPath, buildSig)
-	if err != nil {
-		return err
-	}
-	if !ok {
-		return ErrRestoreAborted
-	}
-
-	safeFstabMerge := destRoot == "/" && isRealRestoreFS(restoreFS)
-	skipFn := func(name string) bool {
-		if !safeFstabMerge {
-			return false
-		}
-		clean := strings.TrimPrefix(strings.TrimSpace(name), "./")
-		clean = strings.TrimPrefix(clean, "/")
-		return clean == "etc/fstab"
-	}
-
-	if safeFstabMerge {
-		logger.Warning("Full restore safety: /etc/fstab will not be overwritten; Smart Merge will be offered after extraction.")
-	}
-
-	if err := extractPlainArchive(ctx, prepared.ArchivePath, destRoot, logger, skipFn); err != nil {
-		return err
-	}
-
-	if safeFstabMerge {
-		fsTempDir, err := restoreFS.MkdirTemp("", "proxsave-fstab-")
-		if err != nil {
-			logger.Warning("Failed to create temp dir for fstab merge: %v", err)
-		} else {
-			defer restoreFS.RemoveAll(fsTempDir)
-			fsCategory := []Category{{
-				ID:   "filesystem",
-				Name: "Filesystem Configuration",
-				Paths: []string{
-					"./etc/fstab",
-				},
-			}}
-			if err := extractArchiveNative(ctx, prepared.ArchivePath, fsTempDir, logger, fsCategory, RestoreModeCustom, nil, "", nil); err != nil {
-				logger.Warning("Failed to extract filesystem config for merge: %v", err)
-			} else {
-				currentFstab := filepath.Join(destRoot, "etc", "fstab")
-				backupFstab := filepath.Join(fsTempDir, "etc", "fstab")
-				currentEntries, currentRaw, err := parseFstab(currentFstab)
-				if err != nil {
-					logger.Warning("Failed to parse current fstab: %v", err)
-				} else if backupEntries, _, err := parseFstab(backupFstab); err != nil {
-					logger.Warning("Failed to parse backup fstab: %v", err)
-				} else {
-					analysis := analyzeFstabMerge(logger, currentEntries, backupEntries)
-					if len(analysis.ProposedMounts) == 0 {
-						logger.Info("No new safe mounts found to restore. Keeping current fstab.")
-					} else {
-						var msg strings.Builder
-						msg.WriteString("ProxSave found missing mounts in /etc/fstab.\n\n")
-						if analysis.RootComparable && !analysis.RootMatch {
-							msg.WriteString("⚠ Root UUID mismatch: the backup appears to come from a different machine.\n")
-						}
-						if analysis.SwapComparable && !analysis.SwapMatch {
-							msg.WriteString("⚠ Swap mismatch: the current swap configuration will be kept.\n")
-						}
-						msg.WriteString("\nProposed mounts (safe):\n")
-						for _, m := range analysis.ProposedMounts {
-							fmt.Fprintf(&msg, "  - %s -> %s (%s)\n", m.Device, m.MountPoint, m.Type)
-						}
-						if len(analysis.SkippedMounts) > 0 {
-							msg.WriteString("\nMounts found but not auto-proposed:\n")
-							for _, m := range analysis.SkippedMounts {
-								fmt.Fprintf(&msg, "  - %s -> %s (%s)\n", m.Device, m.MountPoint, m.Type)
-							}
-							msg.WriteString("\nHint: verify disks/UUIDs and options (nofail/_netdev) before adding them.\n")
-						}
-
-						apply, perr := promptYesNoTUIWithCountdown(ctx, logger, "Smart fstab merge", configPath, buildSig, msg.String(), "Apply", "Skip", 90*time.Second)
-						if perr != nil {
-							return perr
-						}
-						if apply {
-							if err := applyFstabMerge(ctx, logger, currentRaw, currentFstab, analysis.ProposedMounts, dryRun); err != nil {
-								logger.Warning("Smart Fstab Merge failed: %v", err)
-							}
-						} else {
-							logger.Info("Fstab merge skipped by user.")
-						}
-					}
-				}
-			}
-		}
-	}
-
-	logger.Info("Restore completed successfully.")
-	return nil
-}
-
 func promptYesNoTUI(title, configPath, buildSig, message, yesLabel, noLabel string) (bool, error) {
 	app := newTUIApp()
 	var result bool
diff --git a/internal/orchestrator/restore_tui_test.go b/internal/orchestrator/restore_tui_test.go
index ac8fb42..d7f1523 100644
--- a/internal/orchestrator/restore_tui_test.go
+++ b/internal/orchestrator/restore_tui_test.go
@@ -4,13 +4,8 @@ import (
 	"errors"
 	"strings"
 	"testing"
-	"time"
 
 	"github.com/rivo/tview"
-
-	"github.com/tis24dev/proxsave/internal/backup"
-	"github.com/tis24dev/proxsave/internal/tui"
-	"github.com/tis24dev/proxsave/internal/tui/components"
 )
 
 func TestFilterAndSortCategoriesForSystem(t *testing.T) {
@@ -169,85 +164,6 @@ func TestConfirmOverwriteTUI(t *testing.T) {
 	}
 }
 
-func TestShowRestoreErrorModalAddsWizardPage(t *testing.T) {
-	app := tui.NewApp()
-	pages := tview.NewPages()
-
-	showRestoreErrorModal(app, pages, "cfg", "sig", "boom", nil)
-
-	if !pages.HasPage(restoreErrorModalPage) {
-		t.Fatalf("expected %q page to be present", restoreErrorModalPage)
-	}
-	page := pages.GetPage(restoreErrorModalPage)
-	flex, ok := page.(*tview.Flex)
-	if !ok {
-		t.Fatalf("expected *tview.Flex, got %T", page)
-	}
-	content := flex.GetItem(3)
-	modal, ok := content.(*tview.Modal)
-	if !ok {
-		t.Fatalf("expected *tview.Modal content, got %T", content)
-	}
-	if modal.GetTitle() != " Restore Error " {
-		t.Fatalf("modal title=%q; want %q", modal.GetTitle(), " Restore Error ")
-	}
-}
-
-func TestShowRestoreCandidatePageAddsCandidatesPageWithItems(t *testing.T) {
-	app := tui.NewApp()
-	pages := tview.NewPages()
-
-	now := time.Unix(1700000000, 0)
-	candidates := []*decryptCandidate{
-		{
-			Manifest: &backup.Manifest{
-				CreatedAt:       now,
-				EncryptionMode:  "age",
-				ProxmoxTargets:  []string{"pve"},
-				ProxmoxVersion:  "8.1",
-				CompressionType: "zstd",
-				ClusterMode:     "standalone",
-				ScriptVersion:   "1.0.0",
-			},
-		},
-		{
-			Manifest: &backup.Manifest{
-				CreatedAt:       now.Add(-time.Hour),
-				EncryptionMode:  "age",
-				ProxmoxTargets:  []string{"pbs"},
-				CompressionType: "xz",
-				ScriptVersion:   "1.0.0",
-			},
-		},
-	}
-
-	showRestoreCandidatePage(app, pages, candidates, "cfg", "sig", func(*decryptCandidate) {}, func() {})
-
-	if !pages.HasPage("candidates") {
-		t.Fatalf("expected candidates page to be present")
-	}
-	page := pages.GetPage("candidates")
-	flex, ok := page.(*tview.Flex)
-	if !ok {
-		t.Fatalf("expected *tview.Flex, got %T", page)
-	}
-	content := flex.GetItem(3)
-	form, ok := content.(*tview.Form)
-	if !ok {
-		t.Fatalf("expected *tview.Form content, got %T", content)
-	}
-	if form.GetFormItemCount() != 1 {
-		t.Fatalf("form items=%d; want 1", form.GetFormItemCount())
-	}
-	listItem, ok := form.GetFormItem(0).(*components.ListFormItem)
-	if !ok {
-		t.Fatalf("expected *components.ListFormItem, got %T", form.GetFormItem(0))
-	}
-	if got := listItem.GetItemCount(); got != len(candidates) {
-		t.Fatalf("list items=%d; want %d", got, len(candidates))
-	}
-}
-
 func stubPromptYesNo(fn func(title, configPath, buildSig, message, yesLabel, noLabel string) (bool, error)) func() {
 	orig := promptYesNoTUIFunc
 	promptYesNoTUIFunc = fn
diff --git a/internal/orchestrator/restore_workflow_abort_test.go b/internal/orchestrator/restore_workflow_abort_test.go
index 329daa1..5a1fed1 100644
--- a/internal/orchestrator/restore_workflow_abort_test.go
+++ b/internal/orchestrator/restore_workflow_abort_test.go
@@ -1,7 +1,6 @@
 package orchestrator
 
 import (
-	"bufio"
 	"context"
 	"os"
 	"path/filepath"
@@ -10,6 +9,7 @@ import (
 
 	"github.com/tis24dev/proxsave/internal/backup"
 	"github.com/tis24dev/proxsave/internal/config"
+	"github.com/tis24dev/proxsave/internal/input"
 	"github.com/tis24dev/proxsave/internal/logging"
 	"github.com/tis24dev/proxsave/internal/types"
 )
@@ -17,21 +17,19 @@ import (
 func TestRunRestoreWorkflow_FstabPromptInputAborted_AbortsWorkflow(t *testing.T) {
 	origRestoreFS := restoreFS
 	origRestoreCmd := restoreCmd
-	origRestorePrompter := restorePrompter
 	origRestoreSystem := restoreSystem
 	origRestoreTime := restoreTime
 	origCompatFS := compatFS
-	origPrepare := prepareDecryptedBackupFunc
+	origPrepare := prepareRestoreBundleFunc
 	origSafetyFS := safetyFS
 	origSafetyNow := safetyNow
 	t.Cleanup(func() {
 		restoreFS = origRestoreFS
 		restoreCmd = origRestoreCmd
-		restorePrompter = origRestorePrompter
 		restoreSystem = origRestoreSystem
 		restoreTime = origRestoreTime
 		compatFS = origCompatFS
-		prepareDecryptedBackupFunc = origPrepare
+		prepareRestoreBundleFunc = origPrepare
 		safetyFS = origSafetyFS
 		safetyNow = origSafetyNow
 	})
@@ -74,13 +72,7 @@ func TestRunRestoreWorkflow_FstabPromptInputAborted_AbortsWorkflow(t *testing.T)
 		t.Fatalf("fakeFS.WriteFile(/bundle.tar): %v", err)
 	}
 
-	restorePrompter = fakeRestorePrompter{
-		mode:       RestoreModeCustom,
-		categories: []Category{mustCategoryByID(t, "filesystem")},
-		confirmed:  true,
-	}
-
-	prepareDecryptedBackupFunc = func(ctx context.Context, reader *bufio.Reader, cfg *config.Config, logger *logging.Logger, version string, requireEncrypted bool) (*decryptCandidate, *preparedBundle, error) {
+	prepareRestoreBundleFunc = func(ctx context.Context, cfg *config.Config, logger *logging.Logger, version string, ui RestoreWorkflowUI) (*decryptCandidate, *preparedBundle, error) {
 		cand := &decryptCandidate{
 			DisplayBase: "test",
 			Manifest: &backup.Manifest{
@@ -98,46 +90,17 @@ func TestRunRestoreWorkflow_FstabPromptInputAborted_AbortsWorkflow(t *testing.T)
 		return cand, prepared, nil
 	}
 
-	// Simulate Ctrl+C behavior: stdin closed -> input.ErrInputAborted during the fstab prompt.
-	oldIn := os.Stdin
-	oldOut := os.Stdout
-	oldErr := os.Stderr
-	t.Cleanup(func() {
-		os.Stdin = oldIn
-		os.Stdout = oldOut
-		os.Stderr = oldErr
-	})
-	inR, inW, err := os.Pipe()
-	if err != nil {
-		t.Fatalf("os.Pipe: %v", err)
-	}
-	out, err := os.OpenFile(os.DevNull, os.O_WRONLY, 0o666)
-	if err != nil {
-		_ = inR.Close()
-		_ = inW.Close()
-		t.Fatalf("OpenFile(%s): %v", os.DevNull, err)
-	}
-	errOut, err := os.OpenFile(os.DevNull, os.O_WRONLY, 0o666)
-	if err != nil {
-		_ = inR.Close()
-		_ = inW.Close()
-		_ = out.Close()
-		t.Fatalf("OpenFile(%s): %v", os.DevNull, err)
-	}
-	os.Stdin = inR
-	os.Stdout = out
-	os.Stderr = errOut
-	t.Cleanup(func() {
-		_ = inR.Close()
-		_ = out.Close()
-		_ = errOut.Close()
-	})
-	_ = inW.Close()
-
 	logger := logging.New(types.LogLevelError, false)
 	cfg := &config.Config{BaseDir: "/base"}
+	ui := &fakeRestoreWorkflowUI{
+		mode:              RestoreModeCustom,
+		categories:        []Category{mustCategoryByID(t, "filesystem")},
+		confirmRestore:    true,
+		confirmFstabMerge: false,
+		confirmFstabMergeErr: input.ErrInputAborted,
+	}
 
-	if err := RunRestoreWorkflow(context.Background(), cfg, logger, "vtest"); err != ErrRestoreAborted {
+	if err := runRestoreWorkflowWithUI(context.Background(), cfg, logger, "vtest", ui); err != ErrRestoreAborted {
 		t.Fatalf("err=%v; want %v", err, ErrRestoreAborted)
 	}
 }
diff --git a/internal/orchestrator/restore_workflow_more_test.go b/internal/orchestrator/restore_workflow_more_test.go
index d9d4bff..41fa569 100644
--- a/internal/orchestrator/restore_workflow_more_test.go
+++ b/internal/orchestrator/restore_workflow_more_test.go
@@ -1,7 +1,6 @@
 package orchestrator
 
 import (
-	"bufio"
 	"context"
 	"errors"
 	"os"
@@ -30,21 +29,19 @@ func mustCategoryByID(t *testing.T, id string) Category {
 func TestRunRestoreWorkflow_ClusterBackupSafeMode_ExportsClusterAndRestoresNetwork(t *testing.T) {
 	origRestoreFS := restoreFS
 	origRestoreCmd := restoreCmd
-	origRestorePrompter := restorePrompter
 	origRestoreSystem := restoreSystem
 	origRestoreTime := restoreTime
 	origCompatFS := compatFS
-	origPrepare := prepareDecryptedBackupFunc
+	origPrepare := prepareRestoreBundleFunc
 	origSafetyFS := safetyFS
 	origSafetyNow := safetyNow
 	t.Cleanup(func() {
 		restoreFS = origRestoreFS
 		restoreCmd = origRestoreCmd
-		restorePrompter = origRestorePrompter
 		restoreSystem = origRestoreSystem
 		restoreTime = origRestoreTime
 		compatFS = origCompatFS
-		prepareDecryptedBackupFunc = origPrepare
+		prepareRestoreBundleFunc = origPrepare
 		safetyFS = origSafetyFS
 		safetyNow = origSafetyNow
 	})
@@ -84,17 +81,7 @@ func TestRunRestoreWorkflow_ClusterBackupSafeMode_ExportsClusterAndRestoresNetwo
 		t.Fatalf("fakeFS.WriteFile: %v", err)
 	}
 
-	restorePrompter = fakeRestorePrompter{
-		mode: RestoreModeCustom,
-		categories: []Category{
-			mustCategoryByID(t, "network"),
-			mustCategoryByID(t, "pve_cluster"),
-			mustCategoryByID(t, "pve_config_export"),
-		},
-		confirmed: true,
-	}
-
-	prepareDecryptedBackupFunc = func(ctx context.Context, reader *bufio.Reader, cfg *config.Config, logger *logging.Logger, version string, requireEncrypted bool) (*decryptCandidate, *preparedBundle, error) {
+	prepareRestoreBundleFunc = func(ctx context.Context, cfg *config.Config, logger *logging.Logger, version string, ui RestoreWorkflowUI) (*decryptCandidate, *preparedBundle, error) {
 		cand := &decryptCandidate{
 			DisplayBase: "test",
 			Manifest: &backup.Manifest{
@@ -112,42 +99,23 @@ func TestRunRestoreWorkflow_ClusterBackupSafeMode_ExportsClusterAndRestoresNetwo
 		return cand, prepared, nil
 	}
 
-	oldIn := os.Stdin
-	oldOut := os.Stdout
-	t.Cleanup(func() {
-		os.Stdin = oldIn
-		os.Stdout = oldOut
-	})
-	inR, inW, err := os.Pipe()
-	if err != nil {
-		t.Fatalf("os.Pipe: %v", err)
-	}
-	out, err := os.OpenFile(os.DevNull, os.O_WRONLY, 0o666)
-	if err != nil {
-		_ = inR.Close()
-		_ = inW.Close()
-		t.Fatalf("OpenFile(%s): %v", os.DevNull, err)
-	}
-	os.Stdin = inR
-	os.Stdout = out
-	t.Cleanup(func() {
-		_ = inR.Close()
-		_ = out.Close()
-	})
-
-	// Cluster restore prompt -> SAFE mode.
-	if _, err := inW.WriteString("1\n"); err != nil {
-		t.Fatalf("WriteString: %v", err)
-	}
-	_ = inW.Close()
-
 	t.Setenv("PATH", "") // ensure pvesh is not found for SAFE apply
 
 	logger := logging.New(types.LogLevelError, false)
 	cfg := &config.Config{BaseDir: "/base"}
+	ui := &fakeRestoreWorkflowUI{
+		mode: RestoreModeCustom,
+		categories: []Category{
+			mustCategoryByID(t, "network"),
+			mustCategoryByID(t, "pve_cluster"),
+			mustCategoryByID(t, "pve_config_export"),
+		},
+		confirmRestore: true,
+		clusterMode:    ClusterRestoreSafe,
+	}
 
-	if err := RunRestoreWorkflow(context.Background(), cfg, logger, "vtest"); err != nil {
-		t.Fatalf("RunRestoreWorkflow error: %v", err)
+	if err := runRestoreWorkflowWithUI(context.Background(), cfg, logger, "vtest", ui); err != nil {
+		t.Fatalf("runRestoreWorkflowWithUI error: %v", err)
 	}
 
 	hosts, err := fakeFS.ReadFile("/etc/hosts")
@@ -173,21 +141,19 @@ func TestRunRestoreWorkflow_ClusterBackupSafeMode_ExportsClusterAndRestoresNetwo
 func TestRunRestoreWorkflow_PBSStopsServicesAndChecksZFSWhenSelected(t *testing.T) {
 	origRestoreFS := restoreFS
 	origRestoreCmd := restoreCmd
-	origRestorePrompter := restorePrompter
 	origRestoreSystem := restoreSystem
 	origRestoreTime := restoreTime
 	origCompatFS := compatFS
-	origPrepare := prepareDecryptedBackupFunc
+	origPrepare := prepareRestoreBundleFunc
 	origSafetyFS := safetyFS
 	origSafetyNow := safetyNow
 	t.Cleanup(func() {
 		restoreFS = origRestoreFS
 		restoreCmd = origRestoreCmd
-		restorePrompter = origRestorePrompter
 		restoreSystem = origRestoreSystem
 		restoreTime = origRestoreTime
 		compatFS = origCompatFS
-		prepareDecryptedBackupFunc = origPrepare
+		prepareRestoreBundleFunc = origPrepare
 		safetyFS = origSafetyFS
 		safetyNow = origSafetyNow
 	})
@@ -240,16 +206,7 @@ func TestRunRestoreWorkflow_PBSStopsServicesAndChecksZFSWhenSelected(t *testing.
 		t.Fatalf("fakeFS.WriteFile: %v", err)
 	}
 
-	restorePrompter = fakeRestorePrompter{
-		mode: RestoreModeCustom,
-		categories: []Category{
-			mustCategoryByID(t, "pbs_jobs"),
-			mustCategoryByID(t, "zfs"),
-		},
-		confirmed: true,
-	}
-
-	prepareDecryptedBackupFunc = func(ctx context.Context, reader *bufio.Reader, cfg *config.Config, logger *logging.Logger, version string, requireEncrypted bool) (*decryptCandidate, *preparedBundle, error) {
+	prepareRestoreBundleFunc = func(ctx context.Context, cfg *config.Config, logger *logging.Logger, version string, ui RestoreWorkflowUI) (*decryptCandidate, *preparedBundle, error) {
 		cand := &decryptCandidate{
 			DisplayBase: "test",
 			Manifest: &backup.Manifest{
@@ -269,9 +226,17 @@ func TestRunRestoreWorkflow_PBSStopsServicesAndChecksZFSWhenSelected(t *testing.
 
 	logger := logging.New(types.LogLevelError, false)
 	cfg := &config.Config{BaseDir: "/base"}
+	ui := &fakeRestoreWorkflowUI{
+		mode: RestoreModeCustom,
+		categories: []Category{
+			mustCategoryByID(t, "pbs_jobs"),
+			mustCategoryByID(t, "zfs"),
+		},
+		confirmRestore: true,
+	}
 
-	if err := RunRestoreWorkflow(context.Background(), cfg, logger, "vtest"); err != nil {
-		t.Fatalf("RunRestoreWorkflow error: %v", err)
+	if err := runRestoreWorkflowWithUI(context.Background(), cfg, logger, "vtest", ui); err != nil {
+		t.Fatalf("runRestoreWorkflowWithUI error: %v", err)
 	}
 
 	if _, err := fakeFS.ReadFile("/etc/proxmox-backup/sync.cfg"); err != nil {
@@ -314,21 +279,19 @@ func TestRunRestoreWorkflow_IncompatibilityAndSafetyBackupFailureCanContinue(t *
 
 	origRestoreFS := restoreFS
 	origRestoreCmd := restoreCmd
-	origRestorePrompter := restorePrompter
 	origRestoreSystem := restoreSystem
 	origRestoreTime := restoreTime
 	origCompatFS := compatFS
-	origPrepare := prepareDecryptedBackupFunc
+	origPrepare := prepareRestoreBundleFunc
 	origSafetyFS := safetyFS
 	origSafetyNow := safetyNow
 	t.Cleanup(func() {
 		restoreFS = origRestoreFS
 		restoreCmd = origRestoreCmd
-		restorePrompter = origRestorePrompter
 		restoreSystem = origRestoreSystem
 		restoreTime = origRestoreTime
 		compatFS = origCompatFS
-		prepareDecryptedBackupFunc = origPrepare
+		prepareRestoreBundleFunc = origPrepare
 		safetyFS = origSafetyFS
 		safetyNow = origSafetyNow
 	})
@@ -370,15 +333,7 @@ func TestRunRestoreWorkflow_IncompatibilityAndSafetyBackupFailureCanContinue(t *
 		t.Fatalf("restoreSandbox.WriteFile: %v", err)
 	}
 
-	restorePrompter = fakeRestorePrompter{
-		mode: RestoreModeCustom,
-		categories: []Category{
-			mustCategoryByID(t, "network"),
-		},
-		confirmed: true,
-	}
-
-	prepareDecryptedBackupFunc = func(ctx context.Context, reader *bufio.Reader, cfg *config.Config, logger *logging.Logger, version string, requireEncrypted bool) (*decryptCandidate, *preparedBundle, error) {
+	prepareRestoreBundleFunc = func(ctx context.Context, cfg *config.Config, logger *logging.Logger, version string, ui RestoreWorkflowUI) (*decryptCandidate, *preparedBundle, error) {
 		cand := &decryptCandidate{
 			DisplayBase: "test",
 			Manifest: &backup.Manifest{
@@ -396,40 +351,18 @@ func TestRunRestoreWorkflow_IncompatibilityAndSafetyBackupFailureCanContinue(t *
 		return cand, prepared, nil
 	}
 
-	oldIn := os.Stdin
-	oldOut := os.Stdout
-	t.Cleanup(func() {
-		os.Stdin = oldIn
-		os.Stdout = oldOut
-	})
-	inR, inW, err := os.Pipe()
-	if err != nil {
-		t.Fatalf("os.Pipe: %v", err)
-	}
-	out, err := os.OpenFile(os.DevNull, os.O_WRONLY, 0o666)
-	if err != nil {
-		_ = inR.Close()
-		_ = inW.Close()
-		t.Fatalf("OpenFile(%s): %v", os.DevNull, err)
-	}
-	os.Stdin = inR
-	os.Stdout = out
-	t.Cleanup(func() {
-		_ = inR.Close()
-		_ = out.Close()
-	})
-
-	// Compatibility prompt -> continue; safety backup failure prompt -> continue.
-	if _, err := inW.WriteString("yes\nyes\n"); err != nil {
-		t.Fatalf("WriteString: %v", err)
-	}
-	_ = inW.Close()
-
 	logger := logging.New(types.LogLevelError, false)
 	cfg := &config.Config{BaseDir: "/base"}
+	ui := &fakeRestoreWorkflowUI{
+		mode:              RestoreModeCustom,
+		categories:        []Category{mustCategoryByID(t, "network")},
+		confirmRestore:    true,
+		confirmCompatible: true,
+		continueNoSafety:  true,
+	}
 
-	if err := RunRestoreWorkflow(context.Background(), cfg, logger, "vtest"); err != nil {
-		t.Fatalf("RunRestoreWorkflow error: %v", err)
+	if err := runRestoreWorkflowWithUI(context.Background(), cfg, logger, "vtest", ui); err != nil {
+		t.Fatalf("runRestoreWorkflowWithUI error: %v", err)
 	}
 
 	if _, err := restoreSandbox.ReadFile("/etc/hosts"); err != nil {
@@ -440,21 +373,19 @@ func TestRunRestoreWorkflow_IncompatibilityAndSafetyBackupFailureCanContinue(t *
 func TestRunRestoreWorkflow_ClusterRecoveryModeStopsAndRestartsServices(t *testing.T) {
 	origRestoreFS := restoreFS
 	origRestoreCmd := restoreCmd
-	origRestorePrompter := restorePrompter
 	origRestoreSystem := restoreSystem
 	origRestoreTime := restoreTime
 	origCompatFS := compatFS
-	origPrepare := prepareDecryptedBackupFunc
+	origPrepare := prepareRestoreBundleFunc
 	origSafetyFS := safetyFS
 	origSafetyNow := safetyNow
 	t.Cleanup(func() {
 		restoreFS = origRestoreFS
 		restoreCmd = origRestoreCmd
-		restorePrompter = origRestorePrompter
 		restoreSystem = origRestoreSystem
 		restoreTime = origRestoreTime
 		compatFS = origCompatFS
-		prepareDecryptedBackupFunc = origPrepare
+		prepareRestoreBundleFunc = origPrepare
 		safetyFS = origSafetyFS
 		safetyNow = origSafetyNow
 	})
@@ -506,16 +437,7 @@ func TestRunRestoreWorkflow_ClusterRecoveryModeStopsAndRestartsServices(t *testi
 		t.Fatalf("fakeFS.WriteFile: %v", err)
 	}
 
-	restorePrompter = fakeRestorePrompter{
-		mode: RestoreModeCustom,
-		categories: []Category{
-			mustCategoryByID(t, "network"),
-			mustCategoryByID(t, "pve_cluster"),
-		},
-		confirmed: true,
-	}
-
-	prepareDecryptedBackupFunc = func(ctx context.Context, reader *bufio.Reader, cfg *config.Config, logger *logging.Logger, version string, requireEncrypted bool) (*decryptCandidate, *preparedBundle, error) {
+	prepareRestoreBundleFunc = func(ctx context.Context, cfg *config.Config, logger *logging.Logger, version string, ui RestoreWorkflowUI) (*decryptCandidate, *preparedBundle, error) {
 		cand := &decryptCandidate{
 			DisplayBase: "test",
 			Manifest: &backup.Manifest{
@@ -533,40 +455,20 @@ func TestRunRestoreWorkflow_ClusterRecoveryModeStopsAndRestartsServices(t *testi
 		return cand, prepared, nil
 	}
 
-	oldIn := os.Stdin
-	oldOut := os.Stdout
-	t.Cleanup(func() {
-		os.Stdin = oldIn
-		os.Stdout = oldOut
-	})
-	inR, inW, err := os.Pipe()
-	if err != nil {
-		t.Fatalf("os.Pipe: %v", err)
-	}
-	out, err := os.OpenFile(os.DevNull, os.O_WRONLY, 0o666)
-	if err != nil {
-		_ = inR.Close()
-		_ = inW.Close()
-		t.Fatalf("OpenFile(%s): %v", os.DevNull, err)
-	}
-	os.Stdin = inR
-	os.Stdout = out
-	t.Cleanup(func() {
-		_ = inR.Close()
-		_ = out.Close()
-	})
-
-	// Cluster restore prompt -> RECOVERY mode.
-	if _, err := inW.WriteString("2\n"); err != nil {
-		t.Fatalf("WriteString: %v", err)
-	}
-	_ = inW.Close()
-
 	logger := logging.New(types.LogLevelError, false)
 	cfg := &config.Config{BaseDir: "/base"}
+	ui := &fakeRestoreWorkflowUI{
+		mode: RestoreModeCustom,
+		categories: []Category{
+			mustCategoryByID(t, "network"),
+			mustCategoryByID(t, "pve_cluster"),
+		},
+		confirmRestore: true,
+		clusterMode:    ClusterRestoreRecovery,
+	}
 
-	if err := RunRestoreWorkflow(context.Background(), cfg, logger, "vtest"); err != nil {
-		t.Fatalf("RunRestoreWorkflow error: %v", err)
+	if err := runRestoreWorkflowWithUI(context.Background(), cfg, logger, "vtest", ui); err != nil {
+		t.Fatalf("runRestoreWorkflowWithUI error: %v", err)
 	}
 
 	for _, want := range []string{
diff --git a/internal/orchestrator/restore_workflow_test.go b/internal/orchestrator/restore_workflow_test.go
index 6358cb9..e6d836f 100644
--- a/internal/orchestrator/restore_workflow_test.go
+++ b/internal/orchestrator/restore_workflow_test.go
@@ -2,7 +2,6 @@ package orchestrator
 
 import (
 	"archive/tar"
-	"bufio"
 	"context"
 	"os"
 	"path/filepath"
@@ -20,28 +19,6 @@ type fakeSystemDetector struct {
 
 func (f fakeSystemDetector) DetectCurrentSystem() SystemType { return f.systemType }
 
-type fakeRestorePrompter struct {
-	mode       RestoreMode
-	categories []Category
-	confirmed  bool
-
-	modeErr       error
-	categoriesErr error
-	confirmErr    error
-}
-
-func (f fakeRestorePrompter) SelectRestoreMode(ctx context.Context, logger *logging.Logger, systemType SystemType) (RestoreMode, error) {
-	return f.mode, f.modeErr
-}
-
-func (f fakeRestorePrompter) SelectCategories(ctx context.Context, logger *logging.Logger, available []Category, systemType SystemType) ([]Category, error) {
-	return f.categories, f.categoriesErr
-}
-
-func (f fakeRestorePrompter) ConfirmRestore(ctx context.Context, logger *logging.Logger) (bool, error) {
-	return f.confirmed, f.confirmErr
-}
-
 func writeMinimalTar(t *testing.T, dir string) string {
 	t.Helper()
 
@@ -77,14 +54,12 @@ func writeMinimalTar(t *testing.T, dir string) string {
 
 func TestRunRestoreWorkflow_CustomModeNoCategories_Succeeds(t *testing.T) {
 	origCompatFS := compatFS
-	origPrompter := restorePrompter
 	origSystem := restoreSystem
-	origPrepare := prepareDecryptedBackupFunc
+	origPrepare := prepareRestoreBundleFunc
 	t.Cleanup(func() {
 		compatFS = origCompatFS
-		restorePrompter = origPrompter
 		restoreSystem = origSystem
-		prepareDecryptedBackupFunc = origPrepare
+		prepareRestoreBundleFunc = origPrepare
 	})
 
 	fakeCompat := NewFakeFS()
@@ -95,15 +70,10 @@ func TestRunRestoreWorkflow_CustomModeNoCategories_Succeeds(t *testing.T) {
 	compatFS = fakeCompat
 
 	restoreSystem = fakeSystemDetector{systemType: SystemTypePVE}
-	restorePrompter = fakeRestorePrompter{
-		mode:       RestoreModeCustom,
-		categories: nil,
-		confirmed:  true,
-	}
 
 	tmp := t.TempDir()
 	archivePath := writeMinimalTar(t, tmp)
-	prepareDecryptedBackupFunc = func(ctx context.Context, reader *bufio.Reader, cfg *config.Config, logger *logging.Logger, version string, requireEncrypted bool) (*decryptCandidate, *preparedBundle, error) {
+	prepareRestoreBundleFunc = func(ctx context.Context, cfg *config.Config, logger *logging.Logger, version string, ui RestoreWorkflowUI) (*decryptCandidate, *preparedBundle, error) {
 		cand := &decryptCandidate{
 			DisplayBase: "test",
 			Manifest: &backup.Manifest{
@@ -122,22 +92,25 @@ func TestRunRestoreWorkflow_CustomModeNoCategories_Succeeds(t *testing.T) {
 
 	logger := logging.New(logging.GetDefaultLogger().GetLevel(), false)
 	cfg := &config.Config{BaseDir: tmp}
+	ui := &fakeRestoreWorkflowUI{
+		mode:           RestoreModeCustom,
+		categories:     nil,
+		confirmRestore: true,
+	}
 
-	if err := RunRestoreWorkflow(context.Background(), cfg, logger, "vtest"); err != nil {
-		t.Fatalf("RunRestoreWorkflow error: %v", err)
+	if err := runRestoreWorkflowWithUI(context.Background(), cfg, logger, "vtest", ui); err != nil {
+		t.Fatalf("runRestoreWorkflowWithUI error: %v", err)
 	}
 }
 
 func TestRunRestoreWorkflow_ConfirmFalseAborts(t *testing.T) {
 	origCompatFS := compatFS
-	origPrompter := restorePrompter
 	origSystem := restoreSystem
-	origPrepare := prepareDecryptedBackupFunc
+	origPrepare := prepareRestoreBundleFunc
 	t.Cleanup(func() {
 		compatFS = origCompatFS
-		restorePrompter = origPrompter
 		restoreSystem = origSystem
-		prepareDecryptedBackupFunc = origPrepare
+		prepareRestoreBundleFunc = origPrepare
 	})
 
 	fakeCompat := NewFakeFS()
@@ -148,15 +121,10 @@ func TestRunRestoreWorkflow_ConfirmFalseAborts(t *testing.T) {
 	compatFS = fakeCompat
 
 	restoreSystem = fakeSystemDetector{systemType: SystemTypePVE}
-	restorePrompter = fakeRestorePrompter{
-		mode:       RestoreModeCustom,
-		categories: nil,
-		confirmed:  false,
-	}
 
 	tmp := t.TempDir()
 	archivePath := writeMinimalTar(t, tmp)
-	prepareDecryptedBackupFunc = func(ctx context.Context, reader *bufio.Reader, cfg *config.Config, logger *logging.Logger, version string, requireEncrypted bool) (*decryptCandidate, *preparedBundle, error) {
+	prepareRestoreBundleFunc = func(ctx context.Context, cfg *config.Config, logger *logging.Logger, version string, ui RestoreWorkflowUI) (*decryptCandidate, *preparedBundle, error) {
 		cand := &decryptCandidate{
 			DisplayBase: "test",
 			Manifest: &backup.Manifest{
@@ -175,8 +143,13 @@ func TestRunRestoreWorkflow_ConfirmFalseAborts(t *testing.T) {
 
 	logger := logging.New(logging.GetDefaultLogger().GetLevel(), false)
 	cfg := &config.Config{BaseDir: tmp}
+	ui := &fakeRestoreWorkflowUI{
+		mode:           RestoreModeCustom,
+		categories:     nil,
+		confirmRestore: false,
+	}
 
-	err := RunRestoreWorkflow(context.Background(), cfg, logger, "vtest")
+	err := runRestoreWorkflowWithUI(context.Background(), cfg, logger, "vtest", ui)
 	if err != ErrRestoreAborted {
 		t.Fatalf("err=%v; want %v", err, ErrRestoreAborted)
 	}
diff --git a/internal/orchestrator/restore_workflow_warnings_test.go b/internal/orchestrator/restore_workflow_warnings_test.go
index b7aeb1e..3da4b6b 100644
--- a/internal/orchestrator/restore_workflow_warnings_test.go
+++ b/internal/orchestrator/restore_workflow_warnings_test.go
@@ -1,7 +1,6 @@
 package orchestrator
 
 import (
-	"bufio"
 	"context"
 	"errors"
 	"io/fs"
@@ -35,21 +34,19 @@ func (f failWritePathFS) WriteFile(path string, data []byte, perm fs.FileMode) e
 func TestRunRestoreWorkflow_FstabMergeFails_ContinuesWithWarnings(t *testing.T) {
 	origRestoreFS := restoreFS
 	origRestoreCmd := restoreCmd
-	origRestorePrompter := restorePrompter
 	origRestoreSystem := restoreSystem
 	origRestoreTime := restoreTime
 	origCompatFS := compatFS
-	origPrepare := prepareDecryptedBackupFunc
+	origPrepare := prepareRestoreBundleFunc
 	origSafetyFS := safetyFS
 	origSafetyNow := safetyNow
 	t.Cleanup(func() {
 		restoreFS = origRestoreFS
 		restoreCmd = origRestoreCmd
-		restorePrompter = origRestorePrompter
 		restoreSystem = origRestoreSystem
 		restoreTime = origRestoreTime
 		compatFS = origCompatFS
-		prepareDecryptedBackupFunc = origPrepare
+		prepareRestoreBundleFunc = origPrepare
 		safetyFS = origSafetyFS
 		safetyNow = origSafetyNow
 	})
@@ -92,13 +89,7 @@ func TestRunRestoreWorkflow_FstabMergeFails_ContinuesWithWarnings(t *testing.T)
 		t.Fatalf("fakeFS.WriteFile(/bundle.tar): %v", err)
 	}
 
-	restorePrompter = fakeRestorePrompter{
-		mode:       RestoreModeCustom,
-		categories: []Category{mustCategoryByID(t, "filesystem")},
-		confirmed:  true,
-	}
-
-	prepareDecryptedBackupFunc = func(ctx context.Context, reader *bufio.Reader, cfg *config.Config, logger *logging.Logger, version string, requireEncrypted bool) (*decryptCandidate, *preparedBundle, error) {
+	prepareRestoreBundleFunc = func(ctx context.Context, cfg *config.Config, logger *logging.Logger, version string, ui RestoreWorkflowUI) (*decryptCandidate, *preparedBundle, error) {
 		cand := &decryptCandidate{
 			DisplayBase: "test",
 			Manifest: &backup.Manifest{
@@ -123,50 +114,17 @@ func TestRunRestoreWorkflow_FstabMergeFails_ContinuesWithWarnings(t *testing.T)
 		failErr:  errors.New("disk full"),
 	}
 
-	// Provide input to accept defaultYes (blank line).
-	oldIn := os.Stdin
-	oldOut := os.Stdout
-	oldErr := os.Stderr
-	t.Cleanup(func() {
-		os.Stdin = oldIn
-		os.Stdout = oldOut
-		os.Stderr = oldErr
-	})
-	inR, inW, err := os.Pipe()
-	if err != nil {
-		t.Fatalf("os.Pipe: %v", err)
-	}
-	out, err := os.OpenFile(os.DevNull, os.O_WRONLY, 0o666)
-	if err != nil {
-		_ = inR.Close()
-		_ = inW.Close()
-		t.Fatalf("OpenFile(%s): %v", os.DevNull, err)
-	}
-	errOut, err := os.OpenFile(os.DevNull, os.O_WRONLY, 0o666)
-	if err != nil {
-		_ = inR.Close()
-		_ = inW.Close()
-		_ = out.Close()
-		t.Fatalf("OpenFile(%s): %v", os.DevNull, err)
-	}
-	os.Stdin = inR
-	os.Stdout = out
-	os.Stderr = errOut
-	t.Cleanup(func() {
-		_ = inR.Close()
-		_ = out.Close()
-		_ = errOut.Close()
-	})
-	if _, err := inW.WriteString("\n"); err != nil {
-		t.Fatalf("WriteString: %v", err)
-	}
-	_ = inW.Close()
-
 	logger := logging.New(types.LogLevelWarning, false)
 	cfg := &config.Config{BaseDir: "/base"}
+	ui := &fakeRestoreWorkflowUI{
+		mode:              RestoreModeCustom,
+		categories:        []Category{mustCategoryByID(t, "filesystem")},
+		confirmRestore:    true,
+		confirmFstabMerge: true,
+	}
 
-	if err := RunRestoreWorkflow(context.Background(), cfg, logger, "vtest"); err != nil {
-		t.Fatalf("RunRestoreWorkflow error: %v", err)
+	if err := runRestoreWorkflowWithUI(context.Background(), cfg, logger, "vtest", ui); err != nil {
+		t.Fatalf("runRestoreWorkflowWithUI error: %v", err)
 	}
 	if !logger.HasWarnings() {
 		t.Fatalf("expected warnings")
diff --git a/internal/orchestrator/selective.go b/internal/orchestrator/selective.go
index f46c96a..17c9fee 100644
--- a/internal/orchestrator/selective.go
+++ b/internal/orchestrator/selective.go
@@ -139,7 +139,13 @@ func pathMatchesPattern(archivePath, pattern string) bool {
 
 // ShowRestoreModeMenu displays the restore mode selection menu
 func ShowRestoreModeMenu(ctx context.Context, logger *logging.Logger, systemType SystemType) (RestoreMode, error) {
-	reader := bufio.NewReader(os.Stdin)
+	return ShowRestoreModeMenuWithReader(ctx, bufio.NewReader(os.Stdin), logger, systemType)
+}
+
+func ShowRestoreModeMenuWithReader(ctx context.Context, reader *bufio.Reader, logger *logging.Logger, systemType SystemType) (RestoreMode, error) {
+	if reader == nil {
+		reader = bufio.NewReader(os.Stdin)
+	}
 
 	fmt.Println()
 	fmt.Println("Select restore mode:")
@@ -187,7 +193,13 @@ func ShowRestoreModeMenu(ctx context.Context, logger *logging.Logger, systemType
 
 // ShowCategorySelectionMenu displays an interactive category selection menu
 func ShowCategorySelectionMenu(ctx context.Context, logger *logging.Logger, availableCategories []Category, systemType SystemType) ([]Category, error) {
-	reader := bufio.NewReader(os.Stdin)
+	return ShowCategorySelectionMenuWithReader(ctx, bufio.NewReader(os.Stdin), logger, availableCategories, systemType)
+}
+
+func ShowCategorySelectionMenuWithReader(ctx context.Context, reader *bufio.Reader, logger *logging.Logger, availableCategories []Category, systemType SystemType) ([]Category, error) {
+	if reader == nil {
+		reader = bufio.NewReader(os.Stdin)
+	}
 
 	// Filter categories by system type
 	relevantCategories := make([]Category, 0)
@@ -414,7 +426,13 @@ func ShowRestorePlan(logger *logging.Logger, config *SelectiveRestoreConfig) {
 
 // ConfirmRestoreOperation asks for user confirmation before proceeding
 func ConfirmRestoreOperation(ctx context.Context, logger *logging.Logger) (bool, error) {
-	reader := bufio.NewReader(os.Stdin)
+	return ConfirmRestoreOperationWithReader(ctx, bufio.NewReader(os.Stdin), logger)
+}
+
+func ConfirmRestoreOperationWithReader(ctx context.Context, reader *bufio.Reader, logger *logging.Logger) (bool, error) {
+	if reader == nil {
+		reader = bufio.NewReader(os.Stdin)
+	}
 	for {
 		fmt.Println("═══════════════════════════════════════════════════════════════")
 		fmt.Print("Type 'RESTORE' to proceed or 'cancel' to abort: ")
